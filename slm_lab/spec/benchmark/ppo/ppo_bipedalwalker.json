{
  "ppo_bipedalwalker_final": {
    "agent": {
      "name": "PPO",
      "algorithm": {
        "name": "PPO",
        "action_pdtype": "default",
        "action_policy": "default",
        "explore_var_spec": null,
        "gamma": 0.9875,
        "lam": 0.9592,
        "clip_eps_spec": {
          "name": "no_decay",
          "start_val": 0.1106,
          "end_val": 0.1106,
          "start_step": 0,
          "end_step": 0
        },
        "entropy_coef_spec": {
          "name": "no_decay",
          "start_val": 0.0058,
          "end_val": 0.0058,
          "start_step": 0,
          "end_step": 0
        },
        "val_loss_coef": 0.794,
        "time_horizon": 512,
        "minibatch_size": 4096,
        "training_epoch": 18
      },
      "memory": {
        "name": "OnPolicyBatchReplay"
      },
      "net": {
        "type": "MLPNet",
        "shared": false,
        "hid_layers": [
          512,
          256
        ],
        "hid_layers_activation": "relu",
        "init_fn": "orthogonal_",
        "normalize": true,
        "batch_norm": false,
        "clip_grad_val": 0.5,
        "use_same_optim": true,
        "loss_spec": {
          "name": "MSELoss"
        },
        "actor_optim_spec": {
          "name": "AdamW",
          "lr": 0.000896
        },
        "critic_optim_spec": {
          "name": "AdamW",
          "lr": 0.000744
        },
        "gpu": "auto"
      }
    },
    "env": {
      "name": "BipedalWalker-v3",
      "num_envs": 32,
      "max_t": null,
      "max_frame": 3000000
    },
    "meta": {
      "distributed": false,
      "log_frequency": 10000,
      "eval_frequency": 10000,
      "max_session": 1,
      "max_trial": 15,
      "search_scheduler": {
        "grace_period": 200000,
        "reduction_factor": 3
      }
    },
    "search": {
      "agent.algorithm.gamma__uniform": [
        0.9865,
        0.9885
      ],
      "agent.algorithm.lam__uniform": [
        0.957,
        0.963
      ],
      "agent.algorithm.clip_eps_spec.start_val__uniform": [
        0.105,
        0.115
      ],
      "agent.algorithm.entropy_coef_spec.start_val__uniform": [
        0.0055,
        0.0062
      ],
      "agent.algorithm.val_loss_coef__uniform": [
        0.78,
        0.81
      ],
      "agent.algorithm.training_epoch__choice": [
        17,
        18,
        19
      ],
      "agent.net.actor_optim_spec.lr__uniform": [
        0.00085,
        0.00093
      ],
      "agent.net.critic_optim_spec.lr__uniform": [
        0.0007,
        0.00078
      ]
    }
  },
  "ppo_bipedalwalker_refined2": {
    "agent": {
      "name": "PPO",
      "algorithm": {
        "name": "PPO",
        "action_pdtype": "default",
        "action_policy": "default",
        "explore_var_spec": null,
        "gamma": 0.9875,
        "lam": 0.96,
        "clip_eps_spec": {
          "name": "no_decay",
          "start_val": 0.11,
          "end_val": 0.11,
          "start_step": 0,
          "end_step": 0
        },
        "entropy_coef_spec": {
          "name": "no_decay",
          "start_val": 0.006,
          "end_val": 0.006,
          "start_step": 0,
          "end_step": 0
        },
        "val_loss_coef": 0.8,
        "time_horizon": 512,
        "minibatch_size": 4096,
        "training_epoch": 18
      },
      "memory": {
        "name": "OnPolicyBatchReplay"
      },
      "net": {
        "type": "MLPNet",
        "shared": false,
        "hid_layers": [
          512,
          256
        ],
        "hid_layers_activation": "relu",
        "init_fn": "orthogonal_",
        "normalize": true,
        "batch_norm": false,
        "clip_grad_val": 0.5,
        "use_same_optim": true,
        "loss_spec": {
          "name": "MSELoss"
        },
        "actor_optim_spec": {
          "name": "AdamW",
          "lr": 0.0009
        },
        "critic_optim_spec": {
          "name": "AdamW",
          "lr": 0.00074
        },
        "gpu": "auto"
      }
    },
    "env": {
      "name": "BipedalWalker-v3",
      "num_envs": 32,
      "max_t": null,
      "max_frame": 4000000
    },
    "meta": {
      "distributed": false,
      "log_frequency": 10000,
      "eval_frequency": 10000,
      "max_session": 1,
      "max_trial": 30,
      "search_scheduler": {
        "grace_period": 250000,
        "reduction_factor": 3
      }
    },
    "search": {
      "agent.algorithm.gamma__uniform": [
        0.985,
        0.99
      ],
      "agent.algorithm.lam__uniform": [
        0.95,
        0.97
      ],
      "agent.algorithm.clip_eps_spec.start_val__uniform": [
        0.1,
        0.13
      ],
      "agent.algorithm.entropy_coef_spec.start_val__uniform": [
        0.005,
        0.008
      ],
      "agent.algorithm.val_loss_coef__uniform": [
        0.75,
        0.85
      ],
      "agent.algorithm.training_epoch__choice": [
        15,
        18,
        20
      ],
      "agent.net.hid_layers__choice": [
        [
          512,
          256
        ],
        [
          768,
          384
        ]
      ],
      "agent.net.actor_optim_spec.lr__uniform": [
        0.0008,
        0.001
      ],
      "agent.net.critic_optim_spec.lr__uniform": [
        0.0007,
        0.0008
      ]
    }
  },
  "ppo_bipedalwalker_fast": {
    "agent": {
      "name": "PPO",
      "algorithm": {
        "name": "PPO",
        "action_pdtype": "default",
        "action_policy": "default",
        "explore_var_spec": null,
        "gamma": 0.99,
        "lam": 0.96,
        "clip_eps_spec": {
          "name": "no_decay",
          "start_val": 0.1,
          "end_val": 0.1,
          "start_step": 0,
          "end_step": 0
        },
        "entropy_coef_spec": {
          "name": "no_decay",
          "start_val": 0.006,
          "end_val": 0.006,
          "start_step": 0,
          "end_step": 0
        },
        "val_loss_coef": 0.8,
        "time_horizon": 512,
        "minibatch_size": 4096,
        "training_epoch": 15
      },
      "memory": {
        "name": "OnPolicyBatchReplay"
      },
      "net": {
        "type": "MLPNet",
        "shared": false,
        "hid_layers": [
          512,
          256
        ],
        "hid_layers_activation": "relu",
        "init_fn": "orthogonal_",
        "normalize": true,
        "batch_norm": false,
        "clip_grad_val": 0.5,
        "use_same_optim": true,
        "loss_spec": {
          "name": "MSELoss"
        },
        "actor_optim_spec": {
          "name": "AdamW",
          "lr": 0.00075
        },
        "critic_optim_spec": {
          "name": "AdamW",
          "lr": 0.00056
        },
        "gpu": "auto"
      }
    },
    "env": {
      "name": "BipedalWalker-v3",
      "num_envs": 32,
      "max_t": null,
      "max_frame": 4000000
    },
    "meta": {
      "distributed": false,
      "log_frequency": 10000,
      "eval_frequency": 10000,
      "max_session": 1,
      "max_trial": 15,
      "search_scheduler": {
        "grace_period": 250000,
        "reduction_factor": 3
      }
    },
    "search": {
      "agent.algorithm.gamma__uniform": [
        0.985,
        0.995
      ],
      "agent.algorithm.lam__uniform": [
        0.955,
        0.97
      ],
      "agent.algorithm.clip_eps_spec.start_val__uniform": [
        0.08,
        0.13
      ],
      "agent.algorithm.entropy_coef_spec.start_val__uniform": [
        0.004,
        0.009
      ],
      "agent.algorithm.val_loss_coef__uniform": [
        0.65,
        0.95
      ],
      "agent.algorithm.training_epoch__choice": [
        12,
        15,
        18
      ],
      "agent.net.hid_layers__choice": [
        [
          512,
          256
        ],
        [
          512,
          512
        ],
        [
          768,
          384
        ]
      ],
      "agent.net.actor_optim_spec.lr__uniform": [
        0.0005,
        0.001
      ],
      "agent.net.critic_optim_spec.lr__uniform": [
        0.0004,
        0.0008
      ]
    }
  },
  "ppo_bipedalwalker_refined": {
    "agent": {
      "name": "PPO",
      "algorithm": {
        "name": "PPO",
        "action_pdtype": "default",
        "action_policy": "default",
        "explore_var_spec": null,
        "gamma": 0.99,
        "lam": 0.96,
        "clip_eps_spec": {
          "name": "no_decay",
          "start_val": 0.1,
          "end_val": 0.1,
          "start_step": 0,
          "end_step": 0
        },
        "entropy_coef_spec": {
          "name": "no_decay",
          "start_val": 0.006,
          "end_val": 0.006,
          "start_step": 0,
          "end_step": 0
        },
        "val_loss_coef": 0.8,
        "time_horizon": 512,
        "minibatch_size": 4096,
        "training_epoch": 15
      },
      "memory": {
        "name": "OnPolicyBatchReplay"
      },
      "net": {
        "type": "MLPNet",
        "shared": false,
        "hid_layers": [
          512,
          256
        ],
        "hid_layers_activation": "relu",
        "init_fn": "orthogonal_",
        "normalize": true,
        "batch_norm": false,
        "clip_grad_val": 0.5,
        "use_same_optim": true,
        "loss_spec": {
          "name": "MSELoss"
        },
        "actor_optim_spec": {
          "name": "AdamW",
          "lr": 0.00075
        },
        "critic_optim_spec": {
          "name": "AdamW",
          "lr": 0.00056
        },
        "gpu": "auto"
      }
    },
    "env": {
      "name": "BipedalWalker-v3",
      "num_envs": 16,
      "max_t": null,
      "max_frame": 5000000
    },
    "meta": {
      "distributed": false,
      "log_frequency": 10000,
      "eval_frequency": 10000,
      "max_session": 1,
      "max_trial": 20,
      "search_scheduler": {
        "grace_period": 2000000,
        "reduction_factor": 3
      }
    },
    "search": {
      "agent.algorithm.gamma__uniform": [
        0.988,
        0.993
      ],
      "agent.algorithm.lam__uniform": [
        0.920,
        0.940
      ],
      "agent.algorithm.clip_eps_spec.start_val__uniform": [
        0.14,
        0.25
      ],
      "agent.algorithm.entropy_coef_spec.start_val__loguniform": [
        0.005,
        0.020
      ],
      "agent.net.hid_layers__choice": [
        [
          256,
          128
        ],
        [
          512,
          256
        ]
      ],
      "agent.net.actor_optim_spec.lr__loguniform": [
        0.0001,
        0.0008
      ],
      "agent.net.critic_optim_spec.lr__loguniform": [
        0.0001,
        0.0008
      ],
      "env.num_envs__choice": [
        8,
        16
      ]
    }
  },
  "ppo_bipedalwalker": {
    "agent": {
      "name": "PPO",
      "algorithm": {
        "name": "PPO",
        "action_pdtype": "default",
        "action_policy": "default",
        "explore_var_spec": null,
        "gamma": 0.99,
        "lam": 0.95,
        "clip_eps_spec": {
          "name": "no_decay",
          "start_val": 0.2,
          "end_val": 0.0,
          "start_step": 10000,
          "end_step": 1000000
        },
        "entropy_coef_spec": {
          "name": "no_decay",
          "start_val": 0.01,
          "end_val": 0.01,
          "start_step": 0,
          "end_step": 0
        },
        "val_loss_coef": 0.5,
        "time_horizon": 512,
        "minibatch_size": 4096,
        "training_epoch": 15
      },
      "memory": {
        "name": "OnPolicyBatchReplay"
      },
      "net": {
        "type": "MLPNet",
        "shared": false,
        "hid_layers": [
          256,
          128
        ],
        "hid_layers_activation": "relu",
        "init_fn": "orthogonal_",
        "normalize": true,
        "batch_norm": false,
        "clip_grad_val": 0.5,
        "use_same_optim": true,
        "loss_spec": {
          "name": "MSELoss"
        },
        "actor_optim_spec": {
          "name": "AdamW",
          "lr": 0.0003
        },
        "critic_optim_spec": {
          "name": "AdamW",
          "lr": 0.0003
        },
        "gpu": "auto"
      }
    },
    "env": {
      "name": "BipedalWalker-v3",
      "num_envs": 32,
      "max_t": null,
      "max_frame": 4000000.0
    },
    "meta": {
      "distributed": false,
      "log_frequency": 1600,
      "eval_frequency": 10000,
      "max_session": 1,
      "max_trial": 50,
      "search_scheduler": {
        "grace_period": 200000,
        "reduction_factor": 3
      }
    },
    "search": {
      "agent": {
        "algorithm": {
          "gamma__uniform": [
            0.98,
            0.999
          ],
          "lam__uniform": [
            0.92,
            0.98
          ],
          "clip_eps_spec": {
            "start_val__uniform": [
              0.1,
              0.3
            ]
          },
          "entropy_coef_spec": {
            "start_val__loguniform": [
              0.0001,
              0.01
            ]
          },
          "val_loss_coef__uniform": [
            0.2,
            2.0
          ],
          "training_epoch__choice": [
            10,
            15,
            20
          ]
        },
        "net": {
          "hid_layers__choice": [
            [
              256,
              128
            ],
            [
              256,
              256
            ],
            [
              512,
              256
            ]
          ],
          "actor_optim_spec": {
            "lr__loguniform": [
              0.0001,
              0.001
            ]
          },
          "critic_optim_spec": {
            "lr__loguniform": [
              0.0001,
              0.001
            ]
          }
        }
      }
    }
  },
  "ppo_bipedalwalker_iter1": {
    "agent": {
      "name": "PPO",
      "algorithm": {
        "name": "PPO",
        "action_pdtype": "default",
        "action_policy": "default",
        "explore_var_spec": null,
        "gamma": 0.99,
        "lam": 0.95,
        "clip_eps_spec": {
          "name": "linear_decay",
          "start_val": 0.2,
          "end_val": 0.1,
          "start_step": 0,
          "end_step": 2000000
        },
        "entropy_coef_spec": {
          "name": "linear_decay",
          "start_val": 0.01,
          "end_val": 0.001,
          "start_step": 0,
          "end_step": 2000000
        },
        "val_loss_coef": 0.5,
        "time_horizon": 2048,
        "minibatch_size": 256,
        "training_epoch": 10
      },
      "memory": {
        "name": "OnPolicyBatchReplay"
      },
      "net": {
        "type": "MLPNet",
        "shared": false,
        "hid_layers": [
          256,
          256
        ],
        "hid_layers_activation": "tanh",
        "init_fn": "orthogonal_",
        "clip_grad_val": 1.0,
        "use_same_optim": false,
        "loss_spec": {
          "name": "MSELoss"
        },
        "actor_optim_spec": {
          "name": "Adam",
          "lr": 0.0003
        },
        "critic_optim_spec": {
          "name": "Adam",
          "lr": 0.001
        },
        "gpu": "auto"
      }
    },
    "env": {
      "name": "BipedalWalker-v3",
      "num_envs": 16,
      "max_t": null,
      "max_frame": 2000000.0
    },
    "meta": {
      "distributed": false,
      "log_frequency": 10000,
      "eval_frequency": 10000,
      "max_session": 1,
      "max_trial": 1
    }
  },
  "ppo_bipedalwalker_iter2": {
    "agent": {
      "name": "PPO",
      "algorithm": {
        "name": "PPO",
        "action_pdtype": "default",
        "action_policy": "default",
        "explore_var_spec": null,
        "gamma": 0.99,
        "lam": 0.95,
        "clip_eps_spec": {
          "name": "linear_decay",
          "start_val": 0.2,
          "end_val": 0.1,
          "start_step": 0,
          "end_step": 2000000
        },
        "entropy_coef_spec": {
          "name": "linear_decay",
          "start_val": 0.005,
          "end_val": 0.001,
          "start_step": 0,
          "end_step": 2000000
        },
        "val_loss_coef": 0.5,
        "time_horizon": 2048,
        "minibatch_size": 256,
        "training_epoch": 10
      },
      "memory": {
        "name": "OnPolicyBatchReplay"
      },
      "net": {
        "type": "MLPNet",
        "shared": false,
        "hid_layers": [
          256,
          256
        ],
        "hid_layers_activation": "tanh",
        "init_fn": "orthogonal_",
        "normalize": true,
        "clip_grad_val": 0.5,
        "use_same_optim": false,
        "loss_spec": {
          "name": "MSELoss"
        },
        "actor_optim_spec": {
          "name": "Adam",
          "lr": 0.0001
        },
        "critic_optim_spec": {
          "name": "Adam",
          "lr": 0.0005
        },
        "gpu": "auto"
      }
    },
    "env": {
      "name": "BipedalWalker-v3",
      "num_envs": 16,
      "max_t": null,
      "max_frame": 2000000.0
    },
    "meta": {
      "distributed": false,
      "log_frequency": 10000,
      "eval_frequency": 10000,
      "max_session": 1,
      "max_trial": 1
    }
  },
  "ppo_bipedalwalker_asha_best": {
    "agent": {
      "name": "PPO",
      "algorithm": {
        "name": "PPO",
        "action_pdtype": "default",
        "action_policy": "default",
        "explore_var_spec": null,
        "gamma": 0.9805,
        "lam": 0.9644,
        "clip_eps_spec": {
          "name": "no_decay",
          "start_val": 0.1633,
          "end_val": 0.1633,
          "start_step": 0,
          "end_step": 0
        },
        "entropy_coef_spec": {
          "name": "no_decay",
          "start_val": 0.0065,
          "end_val": 0.0065,
          "start_step": 0,
          "end_step": 0
        },
        "val_loss_coef": 1.47,
        "time_horizon": 2048,
        "minibatch_size": 256,
        "training_epoch": 20
      },
      "memory": {
        "name": "OnPolicyBatchReplay"
      },
      "net": {
        "type": "MLPNet",
        "shared": false,
        "hid_layers": [
          256,
          128
        ],
        "hid_layers_activation": "tanh",
        "init_fn": "orthogonal_",
        "clip_grad_val": 1.0,
        "use_same_optim": false,
        "loss_spec": {
          "name": "MSELoss"
        },
        "actor_optim_spec": {
          "name": "Adam",
          "lr": 0.00042435
        },
        "critic_optim_spec": {
          "name": "Adam",
          "lr": 0.00011458
        },
        "gpu": "auto"
      }
    },
    "env": {
      "name": "BipedalWalker-v3",
      "num_envs": 16,
      "max_t": null,
      "max_frame": 3000000.0
    },
    "meta": {
      "distributed": false,
      "log_frequency": 10000,
      "eval_frequency": 10000,
      "max_session": 1,
      "max_trial": 1
    }
  },
  "ppo_bipedalwalker_stage2_search": {
    "agent": {
      "name": "PPO",
      "algorithm": {
        "name": "PPO",
        "action_pdtype": "default",
        "action_policy": "default",
        "explore_var_spec": null,
        "gamma": 0.98,
        "lam": 0.96,
        "clip_eps_spec": {
          "name": "no_decay",
          "start_val": 0.16,
          "end_val": 0.16,
          "start_step": 0,
          "end_step": 0
        },
        "entropy_coef_spec": {
          "name": "no_decay",
          "start_val": 0.006,
          "end_val": 0.006,
          "start_step": 0,
          "end_step": 0
        },
        "val_loss_coef": 1.4,
        "time_horizon": 2048,
        "minibatch_size": 256,
        "training_epoch": 20
      },
      "memory": {
        "name": "OnPolicyBatchReplay"
      },
      "net": {
        "type": "MLPNet",
        "shared": false,
        "hid_layers": [
          256,
          128
        ],
        "hid_layers_activation": "tanh",
        "init_fn": "orthogonal_",
        "clip_grad_val": 1.0,
        "use_same_optim": false,
        "loss_spec": {
          "name": "MSELoss"
        },
        "actor_optim_spec": {
          "name": "Adam",
          "lr": 0.0004
        },
        "critic_optim_spec": {
          "name": "Adam",
          "lr": 0.0001
        },
        "gpu": "auto"
      }
    },
    "env": {
      "name": "BipedalWalker-v3",
      "num_envs": 16,
      "max_t": null,
      "max_frame": 2000000.0
    },
    "meta": {
      "distributed": false,
      "log_frequency": 10000,
      "eval_frequency": 10000,
      "max_session": 4,
      "max_trial": 10
    },
    "search": {
      "agent.algorithm.gamma__choice": [
        0.975,
        0.98,
        0.985
      ],
      "agent.algorithm.lam__choice": [
        0.955,
        0.964,
        0.975
      ],
      "agent.algorithm.clip_eps_spec.start_val__choice": [
        0.15,
        0.163,
        0.18
      ],
      "agent.algorithm.entropy_coef_spec.start_val__choice": [
        0.005,
        0.0065,
        0.008
      ],
      "agent.algorithm.val_loss_coef__choice": [
        1.3,
        1.47,
        1.6
      ],
      "agent.algorithm.training_epoch__choice": [
        18,
        20,
        22
      ],
      "agent.net.hid_layers__choice": [
        [
          256,
          128
        ],
        [
          256,
          256
        ],
        [
          384,
          192
        ]
      ],
      "agent.net.actor_optim_spec.lr__choice": [
        0.0003,
        0.000424,
        0.0005
      ],
      "agent.net.critic_optim_spec.lr__choice": [
        8e-05,
        0.000115,
        0.00015
      ]
    }
  },
  "ppo_bipedalwalker_refined_asha": {
    "agent": {
      "name": "PPO",
      "algorithm": {
        "name": "PPO",
        "action_pdtype": "default",
        "action_policy": "default",
        "explore_var_spec": null,
        "gamma": 0.99,
        "lam": 0.95,
        "clip_eps_spec": {
          "name": "no_decay",
          "start_val": 0.2,
          "end_val": 0.2,
          "start_step": 0,
          "end_step": 0
        },
        "entropy_coef_spec": {
          "name": "no_decay",
          "start_val": 0.01,
          "end_val": 0.01,
          "start_step": 0,
          "end_step": 0
        },
        "val_loss_coef": 0.5,
        "time_horizon": 2048,
        "minibatch_size": 64,
        "training_epoch": 10
      },
      "memory": {
        "name": "OnPolicyBatchReplay"
      },
      "net": {
        "type": "MLPNet",
        "shared": false,
        "hid_layers": [
          64,
          64
        ],
        "hid_layers_activation": "tanh",
        "init_fn": "orthogonal_",
        "clip_grad_val": 0.5,
        "use_same_optim": false,
        "loss_spec": {
          "name": "MSELoss"
        },
        "actor_optim_spec": {
          "name": "Adam",
          "lr": 0.0003
        },
        "critic_optim_spec": {
          "name": "Adam",
          "lr": 0.001
        },
        "gpu": "auto"
      }
    },
    "env": {
      "name": "BipedalWalker-v3",
      "num_envs": 16,
      "max_t": null,
      "max_frame": 3000000.0
    },
    "meta": {
      "distributed": false,
      "log_frequency": 10000,
      "eval_frequency": 10000,
      "max_session": 1,
      "max_trial": 25,
      "search_scheduler": {
        "grace_period": 300000,
        "reduction_factor": 3
      }
    },
    "search": {
      "agent.algorithm.gamma__uniform": [
        0.95,
        0.995
      ],
      "agent.algorithm.lam__uniform": [
        0.9,
        0.98
      ],
      "agent.algorithm.clip_eps_spec.start_val__uniform": [
        0.1,
        0.3
      ],
      "agent.algorithm.entropy_coef_spec.start_val__loguniform": [
        0.001,
        0.02
      ],
      "agent.algorithm.val_loss_coef__uniform": [
        0.3,
        2.0
      ],
      "agent.algorithm.training_epoch__choice": [
        10,
        15,
        20
      ],
      "agent.algorithm.minibatch_size__choice": [
        64,
        128,
        256
      ],
      "agent.net.hid_layers__choice": [
        [
          64,
          64
        ],
        [
          128,
          128
        ],
        [
          256,
          128
        ],
        [
          256,
          256
        ]
      ],
      "agent.net.clip_grad_val__choice": [
        0.5,
        1.0,
        2.0
      ],
      "agent.net.actor_optim_spec.lr__loguniform": [
        5e-05,
        0.001
      ],
      "agent.net.critic_optim_spec.lr__loguniform": [
        5e-05,
        0.002
      ]
    }
  },
  "ppo_bipedalwalker_search": {
    "agent": {
      "name": "PPO",
      "algorithm": {
        "name": "PPO",
        "action_pdtype": "default",
        "action_policy": "default",
        "explore_var_spec": null,
        "gamma": 0.99,
        "lam": 0.95,
        "clip_eps_spec": {
          "name": "no_decay",
          "start_val": 0.2,
          "end_val": 0.2,
          "start_step": 0,
          "end_step": 0
        },
        "entropy_coef_spec": {
          "name": "no_decay",
          "start_val": 0.01,
          "end_val": 0.01,
          "start_step": 0,
          "end_step": 0
        },
        "val_loss_coef": 0.5,
        "time_horizon": 2048,
        "minibatch_size": 64,
        "training_epoch": 10
      },
      "memory": {
        "name": "OnPolicyBatchReplay"
      },
      "net": {
        "type": "MLPNet",
        "shared": false,
        "hid_layers": [
          256,
          256
        ],
        "hid_layers_activation": "relu",
        "init_fn": "orthogonal_",
        "normalize": true,
        "batch_norm": false,
        "clip_grad_val": 0.5,
        "use_same_optim": true,
        "loss_spec": {
          "name": "MSELoss"
        },
        "actor_optim_spec": {
          "name": "Adam",
          "lr": 0.0003
        },
        "critic_optim_spec": {
          "name": "Adam",
          "lr": 0.0003
        },
        "gpu": "auto"
      }
    },
    "env": {
      "name": "BipedalWalker-v3",
      "num_envs": 16,
      "max_t": null,
      "max_frame": 4000000
    },
    "meta": {
      "distributed": false,
      "log_frequency": 10000,
      "eval_frequency": 10000,
      "max_session": 1,
      "max_trial": 30,
      "search_scheduler": {
        "grace_period": 300000,
        "reduction_factor": 3
      }
    },
    "search": {
      "agent.algorithm.gamma__uniform": [
        0.985,
        0.999
      ],
      "agent.algorithm.lam__uniform": [
        0.92,
        0.98
      ],
      "agent.algorithm.clip_eps_spec.start_val__uniform": [
        0.1,
        0.3
      ],
      "agent.algorithm.entropy_coef_spec.start_val__loguniform": [
        0.001,
        0.02
      ],
      "agent.algorithm.training_epoch__qrandint": [
        8,
        15,
        1
      ],
      "agent.net.hid_layers__choice": [
        [
          256,
          256
        ],
        [
          512,
          256
        ],
        [
          256,
          128
        ]
      ],
      "agent.net.actor_optim_spec.lr__loguniform": [
        0.0001,
        0.001
      ],
      "agent.net.critic_optim_spec.lr__loguniform": [
        0.0001,
        0.001
      ],
      "env.num_envs__choice": [
        16,
        32
      ]
    }
  },
  "ppo_bipedalwalker_validation": {
    "agent": {
      "name": "PPO",
      "algorithm": {
        "name": "PPO",
        "action_pdtype": "default",
        "action_policy": "default",
        "explore_var_spec": null,
        "gamma": 0.99,
        "lam": 0.95,
        "clip_eps_spec": {
          "name": "no_decay",
          "start_val": 0.2,
          "end_val": 0.2,
          "start_step": 0,
          "end_step": 0
        },
        "entropy_coef_spec": {
          "name": "no_decay",
          "start_val": 0.01,
          "end_val": 0.01,
          "start_step": 0,
          "end_step": 0
        },
        "val_loss_coef": 0.5,
        "time_horizon": 2048,
        "minibatch_size": 64,
        "training_epoch": 10
      },
      "memory": {
        "name": "OnPolicyBatchReplay"
      },
      "net": {
        "type": "MLPNet",
        "shared": false,
        "hid_layers": [
          256,
          256
        ],
        "hid_layers_activation": "relu",
        "init_fn": "orthogonal_",
        "normalize": true,
        "batch_norm": false,
        "clip_grad_val": 0.5,
        "use_same_optim": false,
        "loss_spec": {
          "name": "MSELoss"
        },
        "actor_optim_spec": {
          "name": "Adam",
          "lr": 0.0003
        },
        "critic_optim_spec": {
          "name": "Adam",
          "lr": 0.0003
        },
        "gpu": "auto"
      }
    },
    "env": {
      "name": "BipedalWalker-v3",
      "num_envs": 16,
      "max_t": null,
      "max_frame": 2000000
    },
    "meta": {
      "distributed": false,
      "log_frequency": 10000,
      "eval_frequency": 10000,
      "max_session": 1,
      "max_trial": 1
    }
  },
  "ppo_bipedalwalker_asha": {
    "agent": {
      "name": "PPO",
      "algorithm": {
        "name": "PPO",
        "action_pdtype": "default",
        "action_policy": "default",
        "explore_var_spec": null,
        "gamma": 0.99,
        "lam": 0.95,
        "clip_eps_spec": {
          "name": "no_decay",
          "start_val": 0.2,
          "end_val": 0.2,
          "start_step": 0,
          "end_step": 0
        },
        "entropy_coef_spec": {
          "name": "no_decay",
          "start_val": 0.01,
          "end_val": 0.01,
          "start_step": 0,
          "end_step": 0
        },
        "val_loss_coef": 0.5,
        "time_horizon": 2048,
        "minibatch_size": 64,
        "training_epoch": 10
      },
      "memory": {
        "name": "OnPolicyBatchReplay"
      },
      "net": {
        "type": "MLPNet",
        "shared": false,
        "hid_layers": [
          256,
          256
        ],
        "hid_layers_activation": "relu",
        "init_fn": "orthogonal_",
        "normalize": true,
        "batch_norm": false,
        "clip_grad_val": 0.5,
        "use_same_optim": false,
        "loss_spec": {
          "name": "MSELoss"
        },
        "actor_optim_spec": {
          "name": "Adam",
          "lr": 0.0003
        },
        "critic_optim_spec": {
          "name": "Adam",
          "lr": 0.0003
        },
        "gpu": "auto"
      }
    },
    "env": {
      "name": "BipedalWalker-v3",
      "num_envs": 16,
      "max_t": null,
      "max_frame": 3000000
    },
    "meta": {
      "distributed": false,
      "log_frequency": 10000,
      "eval_frequency": 10000,
      "max_session": 1,
      "max_trial": 20,
      "search_scheduler": {
        "grace_period": 1000000,
        "reduction_factor": 3
      }
    },
    "search": {
      "agent.algorithm.gamma__uniform": [
        0.985,
        0.999
      ],
      "agent.algorithm.lam__uniform": [
        0.92,
        0.98
      ],
      "agent.algorithm.clip_eps_spec.start_val__uniform": [
        0.15,
        0.25
      ],
      "agent.algorithm.entropy_coef_spec.start_val__loguniform": [
        0.001,
        0.02
      ],
      "agent.net.hid_layers__choice": [
        [
          256,
          256
        ],
        [
          512,
          256
        ],
        [
          256,
          128
        ]
      ],
      "agent.net.actor_optim_spec.lr__loguniform": [
        0.0001,
        0.001
      ],
      "agent.net.critic_optim_spec.lr__loguniform": [
        0.0001,
        0.001
      ],
      "env.num_envs__choice": [
        8,
        16,
        32
      ]
    }
  }
}