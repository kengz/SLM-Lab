{
  "ipd_base_rf":{
    "world":{
      "name":"DefaultMultiAgentWorld"
    },
    "agent":[
      {
        "observing_other_agents":{
          "name":"FullyObservable"
        },
        "welfare_function":"default_welfare",
        "name":"DoubleDQN",
        "algorithm":{
          "name":"DoubleDQN",
          "action_pdtype":"Categorical",
          "action_policy":"boltzmann_on_cluster",
          "explore_var_spec":{
            "name":"linear_decay",
            "start_val":1.0,
            "end_val":0.1,
            "start_step":0,
            "end_step":3000
          },
          "gamma":0.5,
          "normalize_inputs":true,
          "training_batch_iter":1,
          "training_iter":4,
          "training_frequency":60,
          "training_start_step":60
        },
        "memory":{
          "name":"Replay",
          "batch_size":60,
          "max_size":4000,
          "use_cer":true
        },
        "net":{
          "type":"MLPNet",
          "hid_layers":[4],
          "hid_layers_activation":"LeakyReLU",
          "init_fn":"normal_mu_0_std_0.1",
          "clip_grad_val":1.0,
          "optim_spec":{
            "name":"SGD",
            "lr":0.04,
            "momentum":0.9
          },
          "lr_scheduler_spec":{
            "name":"LinearToZero",
            "frame":4000
          }
        }
      },
      {
        "copy_n":0
      }
    ],
    "env":[
      {
        "name":"IteratedPrisonersDilemma-v0",
        "max_t":null,
        "max_frame":4000,
        "num_envs":1
      }
    ],
    "body":{
      "product":"outer",
      "num":1
    },
    "meta":{
      "distributed":false,
      "eval_frequency":20,
      "log_frequency":20,
      "max_session":10,
      "max_trial":1
    }
  },
  "ipd_base_rf_util":{
    "world":{
      "name":"DefaultMultiAgentWorld"
    },
    "agent":[
      {
        "observing_other_agents":{
          "name":"FullyObservable"
        },
        "welfare_function":"utilitarian_welfare",
        "name":"DoubleDQN",
        "algorithm":{
          "name":"DoubleDQN",
          "action_pdtype":"Categorical",
          "action_policy":"boltzmann_on_cluster",
          "explore_var_spec":{
            "name":"linear_decay",
            "start_val":1.0,
            "end_val":0.1,
            "start_step":0,
            "end_step":3000
          },
          "gamma":0.5,
          "normalize_inputs":true,
          "training_batch_iter":1,
          "training_iter":4,
          "training_frequency":60,
          "training_start_step":60
        },
        "memory":{
          "name":"Replay",
          "batch_size":60,
          "max_size":4000,
          "use_cer":true
        },
        "net":{
          "type":"MLPNet",
          "hid_layers":[4],
          "hid_layers_activation":"LeakyReLU",
          "init_fn":"normal_mu_0_std_0.1",
          "clip_grad_val":1.0,
          "optim_spec":{
            "name":"SGD",
            "lr":0.04,
            "momentum":0.9
          },
          "lr_scheduler_spec":{
            "name":"LinearToZero",
            "frame":4000
          }
        }
      },
      {
        "copy_n":0
      }
    ],
    "env":[
      {
        "name":"IteratedPrisonersDilemma-v0",
        "max_t":null,
        "max_frame":4000,
        "num_envs":1
      }
    ],
    "body":{
      "product":"outer",
      "num":1
    },
    "meta":{
      "distributed":false,
      "eval_frequency":20,
      "log_frequency":20,
      "max_session":10,
      "max_trial":1
    }
  },
  "ipd_ppm_le_self_play":{
    "world":{
      "name":"DefaultMultiAgentWorld",
      "deterministic":true
    },
    "agent":[
      {
        "name":"LE",
        "memory":null,
        "net":null,
        "welfare_function":"utilitarian_welfare",
        "observing_other_agents":{
          "name":"FullyObservable"
        },
        "algorithm":{
          "name":"LE",
          "punishement_time":1,
          "min_coop_time":0,
          "defection_detection_mode":"network_weights",
          "defection_carac_threshold":0.01,
          "average_d_carac":true,
          "average_d_carac_len":20,
          "same_init_weights":true,
          "coop_net_ent_diff_as_lr":false,
          "use_sl_for_simu_coop":false,
          "use_strat_4":false,
          "use_strat_5":false,
          "strat_5_coeff":10.0,
          "use_strat_2":false,
          "block_len":4,
          "use_last_steps_for_search":true,
          "use_bolzmann_search":true,
          "meta_algo_memory":{
            "name":"Replay",
            "batch_size":1,
            "max_size":-1
          },
          "meta_algo_loss":{
            "reduction":"none",
            "name":"CrossEntropyLoss"
          },
          "contained_algorithms":[
            {
              "name":"DoubleDQN",
              "algorithm":{
                "name":"DoubleDQN",
                "action_pdtype":"Categorical",
                "action_policy":"boltzmann_on_cluster",
                "explore_var_spec":{
                  "name":"linear_decay",
                  "start_val":1.0,
                  "end_val":0.1,
                  "start_step":0,
                  "end_step":3000
                },
                "gamma":0.5,
                "normalize_inputs":true,
                "training_batch_iter":1,
                "training_iter":4,
                "training_frequency":60,
                "training_start_step":60
              },
              "memory":{
                "name":"Replay",
                "batch_size":60,
                "max_size":4000,
                "use_cer":true
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "clip_grad_val":1.0,
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.04,
                  "momentum":0.9
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            },
            {
              "copy_n":0
            },
            {
              "copy_n":0
            }
          ]
        }
      },
      {
        "copy_n":0
      }
    ],
    "env":[
      {
        "name":"IteratedPrisonersDilemma-v0",
        "max_t":null,
        "max_frame":4000,
        "num_envs":1
      }
    ],
    "body":{
      "product":"outer",
      "num":1
    },
    "meta":{
      "distributed":false,
      "eval_frequency":20,
      "log_frequency":20,
      "max_session":10,
      "max_trial":1
    }
  },
  "ipd_ppm_le_vs_naive_opp":{
    "world":{
      "name":"DefaultMultiAgentWorld",
      "deterministic":true
    },
    "agent":[
      {
        "name":"LE",
        "memory":null,
        "net":null,
        "welfare_function":"utilitarian_welfare",
        "observing_other_agents":{
          "name":"FullyObservable"
        },
        "algorithm":{
          "name":"LE",
          "punishement_time":1,
          "min_coop_time":0,
          "defection_detection_mode":"network_weights",
          "defection_carac_threshold":0.01,
          "average_d_carac":true,
          "average_d_carac_len":20,
          "same_init_weights":true,
          "coop_net_ent_diff_as_lr":false,
          "use_sl_for_simu_coop":false,
          "use_strat_4":false,
          "use_strat_5":false,
          "strat_5_coeff":10.0,
          "use_strat_2":false,
          "block_len":4,
          "use_last_steps_for_search":true,
          "use_bolzmann_search":true,
          "meta_algo_memory":{
            "name":"Replay",
            "batch_size":1,
            "max_size":-1
          },
          "meta_algo_loss":{
            "reduction":"none",
            "name":"CrossEntropyLoss"
          },
          "contained_algorithms":[
            {
              "name":"DoubleDQN",
              "algorithm":{
                "name":"DoubleDQN",
                "action_pdtype":"Categorical",
                "action_policy":"boltzmann_on_cluster",
                "explore_var_spec":{
                  "name":"linear_decay",
                  "start_val":1.0,
                  "end_val":0.1,
                  "start_step":0,
                  "end_step":3000
                },
                "gamma":0.5,
                "normalize_inputs":true,
                "training_batch_iter":1,
                "training_iter":4,
                "training_frequency":60,
                "training_start_step":60
              },
              "memory":{
                "name":"Replay",
                "batch_size":60,
                "max_size":4000,
                "use_cer":true
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "clip_grad_val":1.0,
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.04,
                  "momentum":0.9
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            },
            {
              "copy_n":0
            },
            {
              "copy_n":0
            }
          ]
        }
      },
      {
        "observing_other_agents":{
          "name":"FullyObservable"
        },
        "name":"DoubleDQN",
        "algorithm":{
          "name":"DoubleDQN",
          "action_pdtype":"Categorical",
          "action_policy":"boltzmann_on_cluster",
          "explore_var_spec":{
            "name":"linear_decay",
            "start_val":1.0,
            "end_val":0.1,
            "start_step":0,
            "end_step":3000
          },
          "gamma":0.5,
          "normalize_inputs":true,
          "training_batch_iter":1,
          "training_iter":4,
          "training_frequency":60,
          "training_start_step":60
        },
        "memory":{
          "name":"Replay",
          "batch_size":60,
          "max_size":4000,
          "use_cer":true
        },
        "net":{
          "type":"MLPNet",
          "hid_layers":[4],
          "hid_layers_activation":"LeakyReLU",
          "init_fn":"normal_mu_0_std_0.1",
          "clip_grad_val":1.0,
          "optim_spec":{
            "name":"SGD",
            "lr":0.04,
            "momentum":0.9
          },
          "lr_scheduler_spec":{
            "name":"LinearToZero",
            "frame":4000
          }
        }
      }
    ],
    "env":[
      {
        "name":"IteratedPrisonersDilemma-v0",
        "max_t":null,
        "max_frame":4000,
        "num_envs":1
      }
    ],
    "body":{
      "product":"outer",
      "num":1
    },
    "meta":{
      "distributed":false,
      "eval_frequency":20,
      "log_frequency":20,
      "max_session":10,
      "max_trial":1
    }
  },

  "ipd_ipm_le_self_play_no_strat_temp_1":{
    "world":{
      "name":"DefaultMultiAgentWorld",
      "deterministic":false
    },
    "agent":[
      {
        "name":"LE",
        "memory":null,
        "net":null,
        "welfare_function":"utilitarian_welfare",
        "observing_other_agents":{
          "name":"FullyObservable"
        },
        "algorithm":{
          "name":"LE",
          "punishement_time":1,
          "min_coop_time":0,
          "defection_detection_mode":"spl_observed_actions",
          "defection_carac_threshold":0.0,
          "average_d_carac":true,
          "average_d_carac_len":20,
          "same_init_weights":true,
          "coop_net_ent_diff_as_lr":false,
          "use_sl_for_simu_coop":false,
          "use_strat_4":false,
          "use_strat_5":false,
          "strat_5_coeff":10.0,
          "use_strat_2":false,
          "block_len":4,
          "use_last_steps_for_search":true,
          "use_bolzmann_search":true,
          "meta_algo_memory":{
            "name":"Replay",
            "batch_size":1,
            "max_size":-1
          },
          "meta_algo_loss":{
            "reduction":"none",
            "name":"CrossEntropyLoss"
          },
          "contained_algorithms":[
            {
              "name":"DoubleDQN",
              "algorithm":{
                "name":"DoubleDQN",
                "action_pdtype":"Categorical",
                "action_policy":"boltzmann_on_cluster",
                "explore_var_spec":{
                  "name":"linear_decay",
                  "start_val":1.0,
                  "end_val":0.1,
                  "start_step":0,
                  "end_step":3000
                },
                "gamma":0.5,
                "normalize_inputs":true,
                "training_batch_iter":1,
                "training_iter":4,
                "training_frequency":60,
                "training_start_step":60
              },
              "memory":{
                "name":"Replay",
                "batch_size":60,
                "max_size":4000,
                "use_cer":true
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "clip_grad_val":1.0,
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.04,
                  "momentum":0.9
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            },
            {
              "copy_n":0
            },
            {
              "copy_n":0
            },
            {
              "name":"SupervisedLAPolicy",
              "algorithm":{
                "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
                "entropy_coef_spec":{
                  "name":"linear_decay",
                  "start_val":0.0,
                  "end_val":0.0,
                  "start_step":0,
                  "end_step":500
                },
                "training_frequency":1,
                "normalize_inputs":true,
                "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "loss_spec":{
                  "name":"CrossEntropyLoss",
                  "reduction":"none"
                },
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.40,
                  "momentum":0.000
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            }
          ]
        }
      },
      {
        "copy_n":0
      }
    ],
    "env":[
      {
        "name":"IteratedPrisonersDilemma-v0",
        "max_t":null,
        "max_frame":4000,
        "num_envs":1
      }
    ],
    "body":{
      "product":"outer",
      "num":1
    },
    "meta":{
      "distributed":false,
      "eval_frequency":20,
      "log_frequency":20,
      "max_session":10,
      "max_concurrent_session":10,
      "max_trial":1
    }
  },
  "ipd_ipm_le_vs_naive_opp_no_strat_temp_1":{
    "world":{
      "name":"DefaultMultiAgentWorld",
      "deterministic":false
    },
    "agent":[
      {
        "name":"LE",
        "memory":null,
        "net":null,
        "welfare_function":"utilitarian_welfare",
        "observing_other_agents":{
          "name":"FullyObservable"
        },
        "algorithm":{
          "name":"LE",
          "punishement_time":1,
          "min_coop_time":0,
          "defection_detection_mode":"spl_observed_actions",
          "defection_carac_threshold":0.0,
          "average_d_carac":true,
          "average_d_carac_len":20,
          "same_init_weights":true,
          "coop_net_ent_diff_as_lr":false,
          "use_sl_for_simu_coop":false,
          "use_strat_4":false,
          "use_strat_5":false,
          "strat_5_coeff":10.0,
          "use_strat_2":false,
          "block_len":4,
          "use_last_steps_for_search":true,
          "use_bolzmann_search":true,
          "meta_algo_memory":{
            "name":"Replay",
            "batch_size":1,
            "max_size":-1
          },
          "meta_algo_loss":{
            "reduction":"none",
            "name":"CrossEntropyLoss"
          },
          "contained_algorithms":[
            {
              "name":"DoubleDQN",
              "algorithm":{
                "name":"DoubleDQN",
                "action_pdtype":"Categorical",
                "action_policy":"boltzmann_on_cluster",
                "explore_var_spec":{
                  "name":"linear_decay",
                  "start_val":1.0,
                  "end_val":0.1,
                  "start_step":0,
                  "end_step":3000
                },
                "gamma":0.5,
                "normalize_inputs":true,
                "training_batch_iter":1,
                "training_iter":4,
                "training_frequency":60,
                "training_start_step":60
              },
              "memory":{
                "name":"Replay",
                "batch_size":60,
                "max_size":4000,
                "use_cer":true
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "clip_grad_val":1.0,
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.04,
                  "momentum":0.9
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            },
            {
              "copy_n":0
            },
            {
              "copy_n":0
            },
            {
              "name":"SupervisedLAPolicy",
              "algorithm":{
                "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
                "entropy_coef_spec":{
                  "name":"linear_decay",
                  "start_val":0.0,
                  "end_val":0.0,
                  "start_step":0,
                  "end_step":500
                },
                "training_frequency":1,
                "normalize_inputs":true,
                "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "loss_spec":{
                  "name":"CrossEntropyLoss",
                  "reduction":"none"
                },
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.40,
                  "momentum":0.000
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            }
          ]
        }
      },
      {
        "name":"DoubleDQN",
        "algorithm":{
          "name":"DoubleDQN",
          "action_pdtype":"Categorical",
          "action_policy":"boltzmann_on_cluster",
          "explore_var_spec":{
            "name":"linear_decay",
            "start_val":1.0,
            "end_val":0.1,
            "start_step":0,
            "end_step":3000
          },
          "gamma":0.5,
          "normalize_inputs":true,
          "training_batch_iter":1,
          "training_iter":4,
          "training_frequency":60,
          "training_start_step":60
        },
        "memory":{
          "name":"Replay",
          "batch_size":60,
          "max_size":4000,
          "use_cer":true
        },
        "net":{
          "type":"MLPNet",
          "hid_layers":[4],
          "hid_layers_activation":"LeakyReLU",
          "init_fn":"normal_mu_0_std_0.1",
          "clip_grad_val":1.0,
          "optim_spec":{
            "name":"SGD",
            "lr":0.04,
            "momentum":0.9
          },
          "lr_scheduler_spec":{
            "name":"LinearToZero",
            "frame":4000
          }
        }
      }
    ],
    "env":[
      {
        "name":"IteratedPrisonersDilemma-v0",
        "max_t":null,
        "max_frame":4000,
        "num_envs":1
      }
    ],
    "body":{
      "product":"outer",
      "num":1
    },
    "meta":{
      "distributed":false,
      "eval_frequency":20,
      "log_frequency":20,
      "max_session":10,
      "max_concurrent_session":10,
      "max_trial":1
    }
  },
  "ipd_ipm_le_self_play_no_strat_temp_033":{
    "world":{
      "name":"DefaultMultiAgentWorld",
      "deterministic":false
    },
    "agent":[
      {
        "name":"LE",
        "memory":null,
        "net":null,
        "welfare_function":"utilitarian_welfare",
        "observing_other_agents":{
          "name":"FullyObservable"
        },
        "algorithm":{
          "name":"LE",
          "punishement_time":1,
          "min_coop_time":0,
          "defection_detection_mode":"spl_observed_actions",
          "defection_carac_threshold":0.0,
          "average_d_carac":true,
          "average_d_carac_len":20,
          "same_init_weights":true,
          "coop_net_ent_diff_as_lr":false,
          "use_sl_for_simu_coop":false,
          "use_strat_4":false,
          "use_strat_5":false,
          "strat_5_coeff":10.0,
          "use_strat_2":false,
          "block_len":4,
          "use_last_steps_for_search":true,
          "use_bolzmann_search":true,
          "meta_algo_memory":{
            "name":"Replay",
            "batch_size":1,
            "max_size":-1
          },
          "meta_algo_loss":{
            "reduction":"none",
            "name":"CrossEntropyLoss"
          },
          "contained_algorithms":[
            {
              "name":"DoubleDQN",
              "algorithm":{
                "name":"DoubleDQN",
                "action_pdtype":"Categorical",
                "action_policy":"boltzmann_on_cluster",
                "explore_var_spec":{
                  "name":"linear_decay",
                  "start_val":1.0,
                  "end_val":0.1,
                  "start_step":0,
                  "end_step":3000
                },
                "gamma":0.5,
                "normalize_inputs":true,
                "training_batch_iter":1,
                "training_iter":4,
                "training_frequency":60,
                "training_start_step":60
              },
              "memory":{
                "name":"Replay",
                "batch_size":60,
                "max_size":4000,
                "use_cer":true
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "clip_grad_val":1.0,
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.04,
                  "momentum":0.9
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            },
            {
              "copy_n":0
            },
            {
              "copy_n":0
            },
            {
              "name":"SupervisedLAPolicy",
              "algorithm":{
                "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
                "entropy_coef_spec":{
                  "name":"linear_decay",
                  "start_val":0.0,
                  "end_val":0.0,
                  "start_step":0,
                  "end_step":500
                },
                "training_frequency":1,
                "normalize_inputs":true,
                "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "loss_spec":{
                  "name":"CrossEntropyLoss",
                  "reduction":"none"
                },
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.40,
                  "momentum":0.000
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            }
          ]
        }
      },
      {
        "name":"LE",
        "memory":null,
        "net":null,
        "welfare_function":"utilitarian_welfare",
        "observing_other_agents":{
          "name":"FullyObservable"
        },
        "algorithm":{
          "name":"LE",
          "punishement_time":1,
          "min_coop_time":0,
          "defection_detection_mode":"spl_observed_actions",
          "defection_carac_threshold":0.0,
          "average_d_carac":true,
          "average_d_carac_len":20,
          "same_init_weights":true,
          "coop_net_ent_diff_as_lr":false,
          "use_sl_for_simu_coop":false,
          "use_strat_4":false,
          "use_strat_5":false,
          "strat_5_coeff":10.0,
          "use_strat_2":false,
          "block_len":4,
          "use_last_steps_for_search":true,
          "use_bolzmann_search":true,
          "meta_algo_memory":{
            "name":"Replay",
            "batch_size":1,
            "max_size":-1
          },
          "meta_algo_loss":{
            "reduction":"none",
            "name":"CrossEntropyLoss"
          },
          "contained_algorithms":[
            {
            "name":"DoubleDQN",
              "algorithm":{
                "name":"DoubleDQN",
                "action_pdtype":"Categorical",
                "action_policy":"boltzmann_on_cluster",
                "explore_var_spec":{
                  "name":"linear_decay",
                  "start_val":0.33,
                  "end_val":0.1,
                  "start_step":0,
                  "end_step":3000
                },
                "gamma":0.5,
                "normalize_inputs":true,
                "training_batch_iter":1,
                "training_iter":4,
                "training_frequency":60,
                "training_start_step":60
              },
              "memory":{
                "name":"Replay",
                "batch_size":60,
                "max_size":4000,
                "use_cer":true
              },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "clip_grad_val":1.0,
              "optim_spec":{
                "name":"SGD",
                "lr":0.04,
                "momentum":0.9
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }
          },
          {
            "copy_n":0
          },
          {
            "copy_n":0
          },
          {
            "name":"SupervisedLAPolicy",
            "algorithm":{
              "name":"SupervisedLAPolicy",
              "action_pdtype":  "default",
              "action_policy":  "default",
              "explore_var_spec":null,
              "entropy_coef_spec":{
                "name":"linear_decay",
                "start_val":0.0,
                "end_val":0.0,
                "start_step":0,
                "end_step":500
              },
              "training_frequency":1,
              "normalize_inputs":true,
              "training_batch_iter":1
            },
            "memory":{
              "name":"OnPolicyReplay"
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "loss_spec":{
                "name":"CrossEntropyLoss",
                "reduction":"none"
              },
              "optim_spec":{
                "name":"SGD",
                "lr":0.40,
                "momentum":0.000
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }
          }
        ]
      }
    }
    ],
    "env":[{
      "name":"IteratedPrisonersDilemma-v0",
      "max_t":null,
      "max_frame":4000,
      "num_envs":1
    }],
    "body":{
      "product":"outer",
      "num":1
    },
    "meta":{
      "distributed":false,
      "eval_frequency":20,
      "log_frequency":20,
      "max_session":10,
      "max_concurrent_session":10,
      "max_trial":1
    }
  },
  "ipd_ipm_le_vs_naive_opp_no_strat_temp_033":{
    "world":{"name":"DefaultMultiAgentWorld",
             "deterministic":false},
    "agent":[{
      "name":"LE",
      "memory":null,
      "net":null,
      "welfare_function":"utilitarian_welfare",
      "observing_other_agents":{
        "name":"FullyObservable"
      },
      "algorithm":{
        "name":"LE",
        "punishement_time":1,
        "min_coop_time":0,
        "defection_detection_mode":"spl_observed_actions",
        "defection_carac_threshold":0.0,
        "average_d_carac":true,
        "average_d_carac_len":20,
        "same_init_weights":true,
        "coop_net_ent_diff_as_lr":false,
        "use_sl_for_simu_coop":false,
        "use_strat_4":false,
        "use_strat_5":false,
        "strat_5_coeff":10.0,
        "use_strat_2":false,
        "block_len":4,
        "use_last_steps_for_search":true,
        "use_bolzmann_search":true,
        "meta_algo_memory":{
          "name":"Replay",
          "batch_size":1,
          "max_size":-1
        },
        "meta_algo_loss":{
          "reduction":"none",
          "name":"CrossEntropyLoss"
        },
        "contained_algorithms":[
          {
            "name":"DoubleDQN",
              "algorithm":{
                "name":"DoubleDQN",
                "action_pdtype":"Categorical",
                "action_policy":"boltzmann_on_cluster",
                "explore_var_spec":{
                  "name":"linear_decay",
                  "start_val":1.0,
                  "end_val":0.1,
                  "start_step":0,
                  "end_step":3000
                },
                "gamma":0.5,
                "normalize_inputs":true,
                "training_batch_iter":1,
                "training_iter":4,
                "training_frequency":60,
                "training_start_step":60
              },
              "memory":{
                "name":"Replay",
                "batch_size":60,
                "max_size":4000,
                "use_cer":true
              },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "clip_grad_val":1.0,
              "optim_spec":{
                "name":"SGD",
                "lr":0.04,
                "momentum":0.9
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }

          },
          {
            "copy_n":0
          },
          {
            "copy_n":0
          },
          {
            "name":"SupervisedLAPolicy",
            "algorithm":{
              "name":"SupervisedLAPolicy",
              "action_pdtype":  "default",
              "action_policy":  "default",
              "explore_var_spec":null,
             "entropy_coef_spec":{
                  "name":"linear_decay",
                  "start_val":0.0,
                  "end_val":0.0,
                  "start_step":0,
                  "end_step":500
             },
              "training_frequency":1,
              "normalize_inputs":true,
              "training_batch_iter":1
            },
            "memory":{
              "name":"OnPolicyReplay"
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "loss_spec":{
                "name":"CrossEntropyLoss",
                "reduction":"none"
              },
              "optim_spec":{
                "name":"SGD",
                "lr":0.40,
                "momentum":0.000
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }
          }
        ]

      }
    },
    {

      "observing_other_agents":{"name":"FullyObservable"},
      "name":"DoubleDQN",
      "algorithm":{
        "name":"DoubleDQN",
        "action_pdtype":"Categorical",
        "action_policy":"boltzmann_on_cluster",
        "explore_var_spec":{
          "name":"linear_decay",
          "start_val":0.33,
          "end_val":0.1,
          "start_step":0,
          "end_step":3000
        },
        "gamma":0.5,
        "normalize_inputs":true,
        "training_batch_iter":1,
        "training_iter":4,
        "training_frequency":60,
        "training_start_step":60
      },
      "memory":{
        "name":"Replay",
        "batch_size":60,
        "max_size":4000,
        "use_cer":true
      },


      "net":{
        "type":"MLPNet",
        "hid_layers":[4],
        "hid_layers_activation":"LeakyReLU",
        "init_fn":"normal_mu_0_std_0.1",
        "clip_grad_val":1.0,
        "optim_spec":{
          "name":"SGD",
          "lr":0.04,
          "momentum":0.9
        },
        "lr_scheduler_spec":{
          "name":"LinearToZero",
          "frame":4000
        }
      }
    }
    ],
    "env":[{
      "name":"IteratedPrisonersDilemma-v0",
      "max_t":null,
      "max_frame":4000,
      "num_envs":1
    }],
    "body":{
      "product":"outer",
      "num":1
    },
    "meta":{
      "distributed":false,
      "eval_frequency":20,
      "log_frequency":20,
      "max_session":10,
      "max_concurrent_session":10,
      "max_trial":1
    }
  },
  "ipd_ipm_le_self_play_no_strat_temp_3":{
    "world":{"name":"DefaultMultiAgentWorld",
             "deterministic":false},
    "agent":[{
      "name":"LE",
      "memory":null,
      "net":null,
      "welfare_function":"utilitarian_welfare",
      "observing_other_agents":{
        "name":"FullyObservable"
      },
      "algorithm":{
        "name":"LE",
        "punishement_time":1,
        "min_coop_time":0,
        "defection_detection_mode":"spl_observed_actions",
        "defection_carac_threshold":0.0,
        "average_d_carac":true,
        "average_d_carac_len":20,
        "same_init_weights":true,
        "coop_net_ent_diff_as_lr":false,
        "use_sl_for_simu_coop":false,
        "use_strat_4":false,
        "use_strat_5":false,
        "strat_5_coeff":10.0,
        "use_strat_2":false,
        "block_len":4,
        "use_last_steps_for_search":true,
        "use_bolzmann_search":true,
        "meta_algo_memory":{
          "name":"Replay",
          "batch_size":1,
          "max_size":-1
        },
        "meta_algo_loss":{
          "reduction":"none",
          "name":"CrossEntropyLoss"
        },
        "contained_algorithms":[
          {
            "name":"DoubleDQN",
            "algorithm":{
              "name":"DoubleDQN",
              "action_pdtype":"Categorical",
              "action_policy":"boltzmann_on_cluster",
              "explore_var_spec":{
                "name":"linear_decay",
                "start_val":1.0,
                "end_val":0.1,
                "start_step":0,
                "end_step":3000
              },
              "gamma":0.5,
              "normalize_inputs":true,
              "training_batch_iter":1,
              "training_iter":4,
              "training_frequency":60,
              "training_start_step":60
            },
            "memory":{
              "name":"Replay",
              "batch_size":60,
              "max_size":4000,
              "use_cer":true
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "clip_grad_val":1.0,
              "optim_spec":{
                "name":"SGD",
                "lr":0.04,
                "momentum":0.9
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }

          },
          {
            "copy_n":0
          },
          {
            "copy_n":0
          },
          {
            "name":"SupervisedLAPolicy",
            "algorithm":{
              "name":"SupervisedLAPolicy",
              "action_pdtype":  "default",
              "action_policy":  "default",
              "explore_var_spec":null,
             "entropy_coef_spec":{
                  "name":"linear_decay",
                  "start_val":0.0,
                  "end_val":0.0,
                  "start_step":0,
                  "end_step":500
             },
              "training_frequency":1,
              "normalize_inputs":true,
              "training_batch_iter":1
            },
            "memory":{
              "name":"OnPolicyReplay"
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "loss_spec":{
                "name":"CrossEntropyLoss",
                "reduction":"none"
              },
              "optim_spec":{
                "name":"SGD",
                "lr":0.40,
                "momentum":0.000
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }
          }
        ]

      }
    },
    {
      "name":"LE",
      "memory":null,
      "net":null,
      "welfare_function":"utilitarian_welfare",
      "observing_other_agents":{
        "name":"FullyObservable"
      },
      "algorithm":{
        "name":"LE",
        "punishement_time":1,
        "min_coop_time":0,
        "defection_detection_mode":"spl_observed_actions",
        "defection_carac_threshold":0.0,
        "average_d_carac":true,
        "average_d_carac_len":20,
        "same_init_weights":true,
        "coop_net_ent_diff_as_lr":false,
        "use_sl_for_simu_coop":false,
        "use_strat_4":false,
        "use_strat_5":false,
        "strat_5_coeff":10.0,
        "use_strat_2":false,
        "block_len":4,
        "use_last_steps_for_search":true,
        "use_bolzmann_search":true,
        "meta_algo_memory":{
          "name":"Replay",
          "batch_size":1,
          "max_size":-1
        },
        "meta_algo_loss":{
          "reduction":"none",
          "name":"CrossEntropyLoss"
        },
        "contained_algorithms":[
          {
            "name":"DoubleDQN",
            "algorithm":{
              "name":"DoubleDQN",
              "action_pdtype":"Categorical",
              "action_policy":"boltzmann_on_cluster",
              "explore_var_spec":{
                "name":"linear_decay",
                "start_val":3.0,
                "end_val":0.1,
                "start_step":0,
                "end_step":3000
              },
              "gamma":0.5,
              "normalize_inputs":true,
              "training_batch_iter":1,
              "training_iter":4,
              "training_frequency":60,
              "training_start_step":60
            },
            "memory":{
              "name":"Replay",
              "batch_size":60,
              "max_size":4000,
              "use_cer":true
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "clip_grad_val":1.0,
              "optim_spec":{
                "name":"SGD",
                "lr":0.04,
                "momentum":0.9
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }

          },
          {
            "copy_n":0
          },
          {
            "copy_n":0
          },
          {
            "name":"SupervisedLAPolicy",
            "algorithm":{
              "name":"SupervisedLAPolicy",
              "action_pdtype":  "default",
              "action_policy":  "default",
              "explore_var_spec":null,
             "entropy_coef_spec":{
                  "name":"linear_decay",
                  "start_val":0.0,
                  "end_val":0.0,
                  "start_step":0,
                  "end_step":500
             },
              "training_frequency":1,
              "normalize_inputs":true,
              "training_batch_iter":1
            },
            "memory":{
              "name":"OnPolicyReplay"
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "loss_spec":{
                "name":"CrossEntropyLoss",
                "reduction":"none"
              },
              "optim_spec":{
                "name":"SGD",
                "lr":0.40,
                "momentum":0.000
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }
          }
        ]

      }
    }
    ],
    "env":[{
      "name":"IteratedPrisonersDilemma-v0",
      "max_t":null,
      "max_frame":4000,
      "num_envs":1
    }],
    "body":{
      "product":"outer",
      "num":1
    },
    "meta":{
      "distributed":false,
      "eval_frequency":20,
      "log_frequency":20,
      "max_session":10,
      "max_concurrent_session":10,
      "max_trial":1
    }
  },
  "ipd_ipm_le_vs_naive_opp_no_strat_temp_3":{
    "world":{"name":"DefaultMultiAgentWorld",
             "deterministic":false},
    "agent":[{
      "name":"LE",
      "memory":null,
      "net":null,
      "welfare_function":"utilitarian_welfare",
      "observing_other_agents":{
        "name":"FullyObservable"
      },
      "algorithm":{
        "name":"LE",
        "punishement_time":1,
        "min_coop_time":0,
        "defection_detection_mode":"spl_observed_actions",
        "defection_carac_threshold":0.0,
        "average_d_carac":true,
        "average_d_carac_len":20,
        "same_init_weights":true,
        "coop_net_ent_diff_as_lr":false,
        "use_sl_for_simu_coop":false,
        "use_strat_4":false,
        "use_strat_5":false,
        "strat_5_coeff":10.0,
        "use_strat_2":false,
        "block_len":4,
        "use_last_steps_for_search":true,
        "use_bolzmann_search":true,
        "meta_algo_memory":{
          "name":"Replay",
          "batch_size":1,
          "max_size":-1
        },
        "meta_algo_loss":{
          "reduction":"none",
          "name":"CrossEntropyLoss"
        },
        "contained_algorithms":[
          {
            "name":"DoubleDQN",
            "algorithm":{
              "name":"DoubleDQN",
              "action_pdtype":"Categorical",
              "action_policy":"boltzmann_on_cluster",
              "explore_var_spec":{
                "name":"linear_decay",
                "start_val":1.0,
                "end_val":0.1,
                "start_step":0,
                "end_step":3000
              },
              "gamma":0.5,
              "normalize_inputs":true,
              "training_batch_iter":1,
              "training_iter":4,
              "training_frequency":60,
              "training_start_step":60
            },
            "memory":{
              "name":"Replay",
              "batch_size":60,
              "max_size":4000,
              "use_cer":true
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "clip_grad_val":1.0,
              "optim_spec":{
                "name":"SGD",
                "lr":0.04,
                "momentum":0.9
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }

          },
          {
            "copy_n":0
          },
          {
            "copy_n":0
          },
          {
            "name":"SupervisedLAPolicy",
            "algorithm":{
              "name":"SupervisedLAPolicy",
              "action_pdtype":  "default",
              "action_policy":  "default",
              "explore_var_spec":null,
             "entropy_coef_spec":{
                  "name":"linear_decay",
                  "start_val":0.0,
                  "end_val":0.0,
                  "start_step":0,
                  "end_step":500
             },
              "training_frequency":1,
              "normalize_inputs":true,
              "training_batch_iter":1
            },
            "memory":{
              "name":"OnPolicyReplay"
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "loss_spec":{
                "name":"CrossEntropyLoss",
                "reduction":"none"
              },
              "optim_spec":{
                "name":"SGD",
                "lr":0.40,
                "momentum":0.000
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }
          }
        ]

      }
    },
    {
      "observing_other_agents":{"name":"FullyObservable"},
      "name":"DoubleDQN",
      "algorithm":{
        "name":"DoubleDQN",
        "action_pdtype":"Categorical",
        "action_policy":"boltzmann_on_cluster",
        "explore_var_spec":{
          "name":"linear_decay",
          "start_val":3.0,
          "end_val":0.1,
          "start_step":0,
          "end_step":3000
        },
        "gamma":0.5,
        "normalize_inputs":true,
        "training_batch_iter":1,
        "training_iter":4,
        "training_frequency":60,
        "training_start_step":60
      },
      "memory":{
        "name":"Replay",
        "batch_size":60,
        "max_size":4000,
        "use_cer":true
      },


      "net":{
        "type":"MLPNet",
        "hid_layers":[4],
        "hid_layers_activation":"LeakyReLU",
        "init_fn":"normal_mu_0_std_0.1",
        "clip_grad_val":1.0,
        "optim_spec":{
          "name":"SGD",
          "lr":0.04,
          "momentum":0.9
        },
        "lr_scheduler_spec":{
          "name":"LinearToZero",
          "frame":4000
        }
      }
    }
    ],
    "env":[{
      "name":"IteratedPrisonersDilemma-v0",
      "max_t":null,
      "max_frame":4000,
      "num_envs":1
    }],
    "body":{
      "product":"outer",
      "num":1
    },
    "meta":{
      "distributed":false,
      "eval_frequency":20,
      "log_frequency":20,
      "max_session":10,
      "max_concurrent_session":10,
      "max_trial":1
    }
  },

  "ipd_ipm_le_self_play_strat_2_temp_1":{
    "world":{"name":"DefaultMultiAgentWorld",
             "deterministic":false},
    "agent":[{
      "name":"LE",
      "memory":null,
      "net":null,
      "welfare_function":"utilitarian_welfare",
      "observing_other_agents":{
        "name":"FullyObservable"
      },
      "algorithm":{
        "name":"LE",
        "punishement_time":1,
        "min_coop_time":0,
        "defection_detection_mode":"spl_observed_actions",
        "defection_carac_threshold":0.0,
        "average_d_carac":true,
        "average_d_carac_len":20,
        "same_init_weights":true,
        "coop_net_ent_diff_as_lr":false,
        "use_sl_for_simu_coop":false,
        "use_strat_4":false,
        "use_strat_5":false,
        "strat_5_coeff":10.0,
        "use_strat_2":true,
        "block_len":4,
        "use_last_steps_for_search":true,
        "use_bolzmann_search":true,
        "meta_algo_memory":{
          "name":"Replay",
          "batch_size":1,
          "max_size":-1
        },
        "meta_algo_loss":{
          "reduction":"none",
          "name":"CrossEntropyLoss"
        },
        "contained_algorithms":[
          {
            "name":"DoubleDQN",
            "algorithm":{
              "name":"DoubleDQN",
              "action_pdtype":"Categorical",
              "action_policy":"boltzmann_on_cluster",
              "explore_var_spec":{
                "name":"linear_decay",
                "start_val":1.0,
                "end_val":0.1,
                "start_step":0,
                "end_step":3000
              },
              "gamma":0.5,
              "normalize_inputs":true,
              "training_batch_iter":1,
              "training_iter":4,
              "training_frequency":60,
              "training_start_step":60
            },
            "memory":{
              "name":"Replay",
              "batch_size":60,
              "max_size":4000,
              "use_cer":true
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "clip_grad_val":1.0,
              "optim_spec":{
                "name":"SGD",
                "lr":0.04,
                "momentum":0.9
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }

          },
          {
            "copy_n":0
          },
          {
            "copy_n":0
          },
          {
            "name":"SupervisedLAPolicy",
            "algorithm":{
              "name":"SupervisedLAPolicy",
              "action_pdtype":  "default",
              "action_policy":  "default",
              "explore_var_spec":null,
               "entropy_coef_spec":{
                    "name":"linear_decay",
                    "start_val":0.0,
                    "end_val":0.0,
                    "start_step":0,
                    "end_step":500
               },
              "training_frequency":1,
              "normalize_inputs":true,
              "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "loss_spec":{
                "name":"CrossEntropyLoss",
                "reduction":"none"
              },
              "optim_spec":{
                "name":"SGD",
                "lr":0.40,
                "momentum":0.000
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }
          }
        ]

      }
    },
    {
      "copy_n":0
    }
    ],
    "env":[{
      "name":"IteratedPrisonersDilemma-v0",
      "max_t":null,
      "max_frame":4000,
      "num_envs":1
    }],
    "body":{
      "product":"outer",
      "num":1
    },
    "meta":{
      "distributed":false,
      "eval_frequency":20,
      "log_frequency":20,
      "max_session":10,
      "max_concurrent_session":10,
      "max_trial":1
    }
  },
  "ipd_ipm_le_self_play_strat_2_temp_033":{
    "world":{"name":"DefaultMultiAgentWorld",
             "deterministic":false},
    "agent":[{
      "name":"LE",
      "memory":null,
      "net":null,
      "welfare_function":"utilitarian_welfare",
      "observing_other_agents":{
        "name":"FullyObservable"
      },
      "algorithm":{
        "name":"LE",
        "punishement_time":1,
        "min_coop_time":0,
        "defection_detection_mode":"spl_observed_actions",
        "defection_carac_threshold":0.0,
        "average_d_carac":true,
        "average_d_carac_len":20,
        "same_init_weights":true,
        "coop_net_ent_diff_as_lr":false,
        "use_sl_for_simu_coop":false,
        "use_strat_4":false,
        "use_strat_5":false,
        "strat_5_coeff":10.0,
        "use_strat_2":true,
        "block_len":4,
        "use_last_steps_for_search":true,
        "use_bolzmann_search":true,
        "meta_algo_memory":{
          "name":"Replay",
          "batch_size":1,
          "max_size":-1
        },
        "meta_algo_loss":{
          "reduction":"none",
          "name":"CrossEntropyLoss"
        },
        "contained_algorithms":[
          {
            "name":"DoubleDQN",
            "algorithm":{
              "name":"DoubleDQN",
              "action_pdtype":"Categorical",
              "action_policy":"boltzmann_on_cluster",
              "explore_var_spec":{
                "name":"linear_decay",
                "start_val":1.0,
                "end_val":0.1,
                "start_step":0,
                "end_step":3000
              },
              "gamma":0.5,
              "normalize_inputs":true,
              "training_batch_iter":1,
              "training_iter":4,
              "training_frequency":60,
              "training_start_step":60
            },
            "memory":{
              "name":"Replay",
              "batch_size":60,
              "max_size":4000,
              "use_cer":true
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "clip_grad_val":1.0,
              "optim_spec":{
                "name":"SGD",
                "lr":0.04,
                "momentum":0.9
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }

          },
          {
            "copy_n":0
          },
          {
            "copy_n":0
          },
          {
            "name":"SupervisedLAPolicy",
            "algorithm":{
              "name":"SupervisedLAPolicy",
              "action_pdtype":  "default",
              "action_policy":  "default",
              "explore_var_spec":null,
             "entropy_coef_spec":{
                  "name":"linear_decay",
                  "start_val":0.0,
                  "end_val":0.0,
                  "start_step":0,
                  "end_step":500
             },
              "training_frequency":1,
              "normalize_inputs":true,
              "training_batch_iter":1
            },
            "memory":{
              "name":"OnPolicyReplay"
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "loss_spec":{
                "name":"CrossEntropyLoss",
                "reduction":"none"
              },
              "optim_spec":{
                "name":"SGD",
                "lr":0.40,
                "momentum":0.000
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }
          }
        ]

      }
    },
      {
      "name":"LE",
      "memory":null,
      "net":null,
      "welfare_function":"utilitarian_welfare",
      "observing_other_agents":{
        "name":"FullyObservable"
      },
      "algorithm":{
        "name":"LE",
        "punishement_time":1,
        "min_coop_time":0,
        "defection_detection_mode":"spl_observed_actions",
        "defection_carac_threshold":0.0,
        "average_d_carac":true,
        "average_d_carac_len":20,
        "same_init_weights":true,
        "coop_net_ent_diff_as_lr":false,
        "use_sl_for_simu_coop":false,
        "use_strat_4":false,
        "use_strat_5":false,
        "strat_5_coeff":10.0,
        "use_strat_2":true,
        "block_len":4,
        "use_last_steps_for_search":true,
        "use_bolzmann_search":true,
        "meta_algo_memory":{
          "name":"Replay",
          "batch_size":1,
          "max_size":-1
        },
        "meta_algo_loss":{
          "reduction":"none",
          "name":"CrossEntropyLoss"
        },
        "contained_algorithms":[
          {
            "name":"DoubleDQN",
            "algorithm":{
              "name":"DoubleDQN",
              "action_pdtype":"Categorical",
              "action_policy":"boltzmann_on_cluster",
              "explore_var_spec":{
                "name":"linear_decay",
                "start_val":0.33,
                "end_val":0.1,
                "start_step":0,
                "end_step":3000
              },
              "gamma":0.5,
              "normalize_inputs":true,
              "training_batch_iter":1,
              "training_iter":4,
              "training_frequency":60,
              "training_start_step":60
            },
            "memory":{
              "name":"Replay",
              "batch_size":60,
              "max_size":4000,
              "use_cer":true
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "optim_spec":{
                "name":"SGD",
                "lr":0.04,
                "momentum":0.9
              },
              "clip_grad_val":1.0,
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }

          },
          {
            "copy_n":0
          },
          {
            "copy_n":0
          },
          {
            "name":"SupervisedLAPolicy",
            "algorithm":{
              "name":"SupervisedLAPolicy",
              "action_pdtype":  "default",
              "action_policy":  "default",
              "explore_var_spec":null,
             "entropy_coef_spec":{
                  "name":"linear_decay",
                  "start_val":0.0,
                  "end_val":0.0,
                  "start_step":0,
                  "end_step":500
             },
              "training_frequency":1,
              "normalize_inputs":true,
              "training_batch_iter":1
            },
            "memory":{
              "name":"OnPolicyReplay"
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "loss_spec":{
                "name":"CrossEntropyLoss"
              },
              "optim_spec":{
                "name":"SGD",
                "lr":0.40,
                "momentum":0.000
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }
          }
        ]

      }
    }
    ],
    "env":[{
      "name":"IteratedPrisonersDilemma-v0",
      "max_t":null,
      "max_frame":4000,
      "num_envs":1
    }],
    "body":{
      "product":"outer",
      "num":1
    },
    "meta":{
      "distributed":false,
      "eval_frequency":20,
      "log_frequency":20,
      "max_session":10,
      "max_concurrent_session":10,
      "max_trial":1
    }
  },
  "ipd_ipm_le_self_play_strat_2_temp_3":{
    "world":{"name":"DefaultMultiAgentWorld",
             "deterministic":false},
    "agent":[{
      "name":"LE",
      "memory":null,
      "net":null,
      "welfare_function":"utilitarian_welfare",
      "observing_other_agents":{
        "name":"FullyObservable"
      },
      "algorithm":{
        "name":"LE",
        "punishement_time":1,
        "min_coop_time":0,
        "defection_detection_mode":"spl_observed_actions",
        "defection_carac_threshold":0.0,
        "average_d_carac":true,
        "average_d_carac_len":20,
        "same_init_weights":true,
        "coop_net_ent_diff_as_lr":false,
        "use_sl_for_simu_coop":false,
        "use_strat_4":false,
        "use_strat_5":false,
        "strat_5_coeff":10.0,
        "use_strat_2":true,
        "block_len":4,
        "use_last_steps_for_search":true,
        "use_bolzmann_search":true,
        "meta_algo_memory":{
          "name":"Replay",
          "batch_size":1,
          "max_size":-1
        },
        "meta_algo_loss":{
          "reduction":"none",
          "name":"CrossEntropyLoss"
        },
        "contained_algorithms":[
          {
            "name":"DoubleDQN",
            "algorithm":{
              "name":"DoubleDQN",
              "action_pdtype":"Categorical",
              "action_policy":"boltzmann_on_cluster",
              "explore_var_spec":{
                "name":"linear_decay",
                "start_val":1.0,
                "end_val":0.1,
                "start_step":0,
                "end_step":3000
              },
              "gamma":0.5,
              "normalize_inputs":true,
              "training_batch_iter":1,
              "training_iter":4,
              "training_frequency":60,
              "training_start_step":60
            },
            "memory":{
              "name":"Replay",
              "batch_size":60,
              "max_size":4000,
              "use_cer":true
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "clip_grad_val":1.0,
              "optim_spec":{
                "name":"SGD",
                "lr":0.04,
                "momentum":0.9
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }

          },
          {
            "copy_n":0
          },
          {
            "copy_n":0
          },
          {
            "name":"SupervisedLAPolicy",
            "algorithm":{
              "name":"SupervisedLAPolicy",
              "action_pdtype":  "default",
              "action_policy":  "default",
              "explore_var_spec":null,
             "entropy_coef_spec":{
                  "name":"linear_decay",
                  "start_val":0.0,
                  "end_val":0.0,
                  "start_step":0,
                  "end_step":500
             },
              "training_frequency":1,
              "normalize_inputs":true,
              "training_batch_iter":1
            },
            "memory":{
              "name":"OnPolicyReplay"
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "loss_spec":{
                "name":"CrossEntropyLoss",
                "reduction":"none"
              },
              "optim_spec":{
                "name":"SGD",
                "lr":0.40,
                "momentum":0.000
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }
          }
        ]

      }
    },
      {
      "name":"LE",
      "memory":null,
      "net":null,
      "welfare_function":"utilitarian_welfare",
      "observing_other_agents":{
        "name":"FullyObservable"
      },
      "algorithm":{
        "name":"LE",
        "punishement_time":1,
        "min_coop_time":0,
        "defection_detection_mode":"spl_observed_actions",
        "defection_carac_threshold":0.0,
        "average_d_carac":true,
        "average_d_carac_len":20,
        "same_init_weights":true,
        "coop_net_ent_diff_as_lr":false,
        "use_sl_for_simu_coop":false,
        "use_strat_4":false,
        "use_strat_5":false,
        "strat_5_coeff":10.0,
        "use_strat_2":true,
        "block_len":4,
        "use_last_steps_for_search":true,
        "use_bolzmann_search":true,
        "meta_algo_memory":{
          "name":"Replay",
          "batch_size":1,
          "max_size":-1
        },
        "meta_algo_loss":{
          "reduction":"none",
          "name":"CrossEntropyLoss"
        },
        "contained_algorithms":[
          {
            "name":"DoubleDQN",
            "algorithm":{
              "name":"DoubleDQN",
              "action_pdtype":"Categorical",
              "action_policy":"boltzmann_on_cluster",
              "explore_var_spec":{
                "name":"linear_decay",
                "start_val":3.0,
                "end_val":0.1,
                "start_step":0,
                "end_step":3000
              },
              "gamma":0.5,
              "normalize_inputs":true,
              "training_batch_iter":1,
              "training_iter":4,
              "training_frequency":60,
              "training_start_step":60
            },
            "memory":{
              "name":"Replay",
              "batch_size":60,
              "max_size":4000,
              "use_cer":true
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "optim_spec":{
                "name":"SGD",
                "lr":0.04,
                "momentum":0.9
              },
              "clip_grad_val":1.0,
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }

          },
          {
            "copy_n":0
          },
          {
            "copy_n":0
          },
          {
            "name":"SupervisedLAPolicy",
            "algorithm":{
              "name":"SupervisedLAPolicy",
              "action_pdtype":  "default",
              "action_policy":  "default",
              "explore_var_spec":null,
             "entropy_coef_spec":{
                  "name":"linear_decay",
                  "start_val":0.0,
                  "end_val":0.0,
                  "start_step":0,
                  "end_step":500
             },
              "training_frequency":1,
              "normalize_inputs":true,
              "training_batch_iter":1
            },
            "memory":{
              "name":"OnPolicyReplay"
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "loss_spec":{
                "name":"CrossEntropyLoss"
              },
              "optim_spec":{
                "name":"SGD",
                "lr":0.40,
                "momentum":0.000
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }
          }
        ]

      }
    }
    ],
    "env":[{
      "name":"IteratedPrisonersDilemma-v0",
      "max_t":null,
      "max_frame":4000,
      "num_envs":1
    }],
    "body":{
      "product":"outer",
      "num":1
    },
    "meta":{
      "distributed":false,
      "eval_frequency":20,
      "log_frequency":20,
      "max_session":10,
      "max_concurrent_session":10,
      "max_trial":1
    }
  },
  "ipd_ipm_le_vs_naive_opp_strat_2_temp_1":{
    "world":{"name":"DefaultMultiAgentWorld",
             "deterministic":false},
    "agent":[{
      "name":"LE",
      "memory":null,
      "net":null,
      "welfare_function":"utilitarian_welfare",
      "observing_other_agents":{
        "name":"FullyObservable"
      },
      "algorithm":{
        "name":"LE",
        "punishement_time":1,
        "min_coop_time":0,
        "defection_detection_mode":"spl_observed_actions",
        "defection_carac_threshold":0.0,
        "average_d_carac":true,
        "average_d_carac_len":20,
        "same_init_weights":true,
        "coop_net_ent_diff_as_lr":false,
        "use_sl_for_simu_coop":false,
        "use_strat_4":false,
        "use_strat_5":false,
        "strat_5_coeff":10.0,
        "use_strat_2":true,
        "block_len":4,
        "use_last_steps_for_search":true,
        "use_bolzmann_search":true,
        "meta_algo_memory":{
          "name":"Replay",
          "batch_size":1,
          "max_size":-1
        },
        "meta_algo_loss":{
          "reduction":"none",
          "name":"CrossEntropyLoss"
        },
        "contained_algorithms":[
          {
            "name":"DoubleDQN",
            "algorithm":{
              "name":"DoubleDQN",
              "action_pdtype":"Categorical",
              "action_policy":"boltzmann_on_cluster",
              "explore_var_spec":{
                "name":"linear_decay",
                "start_val":1.0,
                "end_val":0.1,
                "start_step":0,
                "end_step":3000
              },
              "gamma":0.5,
              "normalize_inputs":true,
              "training_batch_iter":1,
              "training_iter":4,
              "training_frequency":60,
              "training_start_step":60
            },
            "memory":{
              "name":"Replay",
              "batch_size":60,
              "max_size":4000,
              "use_cer":true
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "clip_grad_val":1.0,
              "optim_spec":{
                "name":"SGD",
                "lr":0.04,
                "momentum":0.9
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }

          },
          {
            "copy_n":0
          },
          {
            "copy_n":0
          },
          {
            "name":"SupervisedLAPolicy",
            "algorithm":{
              "name":"SupervisedLAPolicy",
              "action_pdtype":  "default",
              "action_policy":  "default",
              "explore_var_spec":null,
             "entropy_coef_spec":{
                  "name":"linear_decay",
                  "start_val":0.0,
                  "end_val":0.0,
                  "start_step":0,
                  "end_step":500
             },
              "training_frequency":1,
              "normalize_inputs":true,
              "training_batch_iter":1
            },
            "memory":{
              "name":"OnPolicyReplay"
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "loss_spec":{
                "name":"CrossEntropyLoss",
                "reduction":"none"
              },
              "optim_spec":{
                "name":"SGD",
                "lr":0.40,
                "momentum":0.000
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }
          }
        ]

      }
    },
    {
      "observing_other_agents":{"name":"FullyObservable"},
      "name":"DoubleDQN",
      "algorithm":{
        "name":"DoubleDQN",
        "action_pdtype":"Categorical",
        "action_policy":"boltzmann_on_cluster",
        "explore_var_spec":{
          "name":"linear_decay",
          "start_val":1.0,
          "end_val":0.1,
          "start_step":0,
          "end_step":3000
        },
        "gamma":0.5,
        "normalize_inputs":true,
        "training_batch_iter":1,
        "training_iter":4,
        "training_frequency":60,
        "training_start_step":60
      },
      "memory":{
        "name":"Replay",
        "batch_size":60,
        "max_size":4000,
        "use_cer":true
      },


      "net":{
        "type":"MLPNet",
        "hid_layers":[4],
        "hid_layers_activation":"LeakyReLU",
        "init_fn":"normal_mu_0_std_0.1",
        "clip_grad_val":1.0,
        "optim_spec":{
          "name":"SGD",
          "lr":0.04,
          "momentum":0.9
        },
        "lr_scheduler_spec":{
          "name":"LinearToZero",
          "frame":4000
        }
      }
    }
    ],
    "env":[{
      "name":"IteratedPrisonersDilemma-v0",
      "max_t":null,
      "max_frame":4000,
      "num_envs":1
    }],
    "body":{
      "product":"outer",
      "num":1
    },
    "meta":{
      "distributed":false,
      "eval_frequency":20,
      "log_frequency":20,
      "max_session":10,
      "max_concurrent_session":10,
      "max_trial":1
    }
  },
  "ipd_ipm_le_vs_naive_opp_strat_2_temp_033":{
    "world":{"name":"DefaultMultiAgentWorld",
             "deterministic":false},
    "agent":[
    {
      "name":"LE",
      "memory":null,
      "net":null,
      "welfare_function":"utilitarian_welfare",
      "observing_other_agents":{
        "name":"FullyObservable"
      },
      "algorithm":{
        "name":"LE",
        "punishement_time":1,
        "min_coop_time":0,
        "defection_detection_mode":"spl_observed_actions",
        "defection_carac_threshold":0.0,
        "average_d_carac":true,
        "average_d_carac_len":20,
        "same_init_weights":true,
        "coop_net_ent_diff_as_lr":false,
        "use_sl_for_simu_coop":false,
        "use_strat_4":false,
        "use_strat_5":false,
        "strat_5_coeff":10.0,
        "use_strat_2":true,
        "block_len":4,
        "use_last_steps_for_search":true,
        "use_bolzmann_search":true,
        "meta_algo_memory":{
          "name":"Replay",
          "batch_size":1,
          "max_size":-1
        },
        "meta_algo_loss":{
          "reduction":"none",
          "name":"CrossEntropyLoss"
        },
        "contained_algorithms":[
          {
            "name":"DoubleDQN",
            "algorithm":{
              "name":"DoubleDQN",
              "action_pdtype":"Categorical",
              "action_policy":"boltzmann_on_cluster",
              "explore_var_spec":{
                "name":"linear_decay",
                "start_val":1.0,
                "end_val":0.1,
                "start_step":0,
                "end_step":3000
              },
              "gamma":0.5,
              "normalize_inputs":true,
              "training_batch_iter":1,
              "training_iter":4,
              "training_frequency":60,
              "training_start_step":60
            },
            "memory":{
              "name":"Replay",
              "batch_size":60,
              "max_size":4000,
              "use_cer":true
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "optim_spec":{
                "name":"SGD",
                "lr":0.04,
                "momentum":0.9
              },
              "clip_grad_val":1.0,
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }

          },
          {
            "copy_n":0
          },
          {
            "copy_n":0
          },
          {
            "name":"SupervisedLAPolicy",
            "algorithm":{
              "name":"SupervisedLAPolicy",
              "action_pdtype":  "default",
              "action_policy":  "default",
              "explore_var_spec":null,
             "entropy_coef_spec":{
                  "name":"linear_decay",
                  "start_val":0.0,
                  "end_val":0.0,
                  "start_step":0,
                  "end_step":500
             },
              "training_frequency":1,
              "normalize_inputs":true,
              "training_batch_iter":1
            },
            "memory":{
              "name":"OnPolicyReplay"
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "loss_spec":{
                "name":"CrossEntropyLoss"
              },
              "optim_spec":{
                "name":"SGD",
                "lr":0.40,
                "momentum":0.000
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }
          }
        ]

      }
    },
    {
      "observing_other_agents":{"name":"FullyObservable"},
      "name":"DoubleDQN",
      "algorithm":{
        "name":"DoubleDQN",
        "action_pdtype":"Categorical",
        "action_policy":"boltzmann_on_cluster",
        "explore_var_spec":{
          "name":"linear_decay",
          "start_val":0.33,
          "end_val":0.1,
          "start_step":0,
          "end_step":3000
        },
        "gamma":0.5,
        "normalize_inputs":true,
        "training_batch_iter":1,
        "training_iter":4,
        "training_frequency":60,
        "training_start_step":60
      },
      "memory":{
        "name":"Replay",
        "batch_size":60,
        "max_size":4000,
        "use_cer":true
      },
      "net":{
        "type":"MLPNet",
        "hid_layers":[4],
        "hid_layers_activation":"LeakyReLU",
        "init_fn":"normal_mu_0_std_0.1",
        "clip_grad_val":1.0,
        "optim_spec":{
          "name":"SGD",
          "lr":0.04,
          "momentum":0.9
        },
        "lr_scheduler_spec":{
          "name":"LinearToZero",
          "frame":4000
        }
      }
    }
    ],
    "env":[{
      "name":"IteratedPrisonersDilemma-v0",
      "max_t":null,
      "max_frame":4000,
      "num_envs":1
    }],
    "body":{
      "product":"outer",
      "num":1
    },
    "meta":{
      "distributed":false,
      "eval_frequency":20,
      "log_frequency":20,
      "max_session":10,
      "max_concurrent_session":10,
      "max_trial":1
    }
  },
  "ipd_ipm_le_vs_naive_opp_strat_2_temp_3":{
    "world":{"name":"DefaultMultiAgentWorld",
             "deterministic":false},
    "agent":[
    {
      "name":"LE",
      "memory":null,
      "net":null,
      "welfare_function":"utilitarian_welfare",
      "observing_other_agents":{
        "name":"FullyObservable"
      },
      "algorithm":{
        "name":"LE",
        "punishement_time":1,
        "min_coop_time":0,
        "defection_detection_mode":"spl_observed_actions",
        "defection_carac_threshold":0.0,
        "average_d_carac":true,
        "average_d_carac_len":20,
        "same_init_weights":true,
        "coop_net_ent_diff_as_lr":false,
        "use_sl_for_simu_coop":false,
        "use_strat_4":false,
        "use_strat_5":false,
        "strat_5_coeff":10.0,
        "use_strat_2":true,
        "block_len":4,
        "use_last_steps_for_search":true,
        "use_bolzmann_search":true,
        "meta_algo_memory":{
          "name":"Replay",
          "batch_size":1,
          "max_size":-1
        },
        "meta_algo_loss":{
          "reduction":"none",
          "name":"CrossEntropyLoss"
        },
        "contained_algorithms":[
          {
            "name":"DoubleDQN",
            "algorithm":{
              "name":"DoubleDQN",
              "action_pdtype":"Categorical",
              "action_policy":"boltzmann_on_cluster",
              "explore_var_spec":{
                "name":"linear_decay",
                "start_val":1.0,
                "end_val":0.1,
                "start_step":0,
                "end_step":3000
              },
              "gamma":0.5,
              "normalize_inputs":true,
              "training_batch_iter":1,
              "training_iter":4,
              "training_frequency":60,
              "training_start_step":60
            },
            "memory":{
              "name":"Replay",
              "batch_size":60,
              "max_size":4000,
              "use_cer":true
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "optim_spec":{
                "name":"SGD",
                "lr":0.04,
                "momentum":0.9
              },
              "clip_grad_val":1.0,
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }

          },
          {
            "copy_n":0
          },
          {
            "copy_n":0
          },
          {
            "name":"SupervisedLAPolicy",
            "algorithm":{
              "name":"SupervisedLAPolicy",
              "action_pdtype":  "default",
              "action_policy":  "default",
              "explore_var_spec":null,
             "entropy_coef_spec":{
                  "name":"linear_decay",
                  "start_val":0.0,
                  "end_val":0.0,
                  "start_step":0,
                  "end_step":500
             },
              "training_frequency":1,
              "normalize_inputs":true,
              "training_batch_iter":1
            },
            "memory":{
              "name":"OnPolicyReplay"
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "loss_spec":{
                "name":"CrossEntropyLoss"
              },
              "optim_spec":{
                "name":"SGD",
                "lr":0.40,
                "momentum":0.000
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }
          }
        ]

      }
    },

    {
      "observing_other_agents":{"name":"FullyObservable"},
      "name":"DoubleDQN",
      "algorithm":{
        "name":"DoubleDQN",
        "action_pdtype":"Categorical",
        "action_policy":"boltzmann_on_cluster",
        "explore_var_spec":{
          "name":"linear_decay",
          "start_val":3.0,
          "end_val":0.1,
          "start_step":0,
          "end_step":3000
        },
        "gamma":0.5,
        "normalize_inputs":true,
        "training_batch_iter":1,
        "training_iter":4,
        "training_frequency":60,
        "training_start_step":60
      },
      "memory":{
        "name":"Replay",
        "batch_size":60,
        "max_size":4000,
        "use_cer":true
      },


      "net":{
        "type":"MLPNet",
        "hid_layers":[4],
        "hid_layers_activation":"LeakyReLU",
        "init_fn":"normal_mu_0_std_0.1",
        "clip_grad_val":1.0,
        "optim_spec":{
          "name":"SGD",
          "lr":0.04,
          "momentum":0.9
        },
        "lr_scheduler_spec":{
          "name":"LinearToZero",
          "frame":4000
        }
      }
    }
    ],
    "env":[{
      "name":"IteratedPrisonersDilemma-v0",
      "max_t":null,
      "max_frame":4000,
      "num_envs":1
    }],
    "body":{
      "product":"outer",
      "num":1
    },
    "meta":{
      "distributed":false,
      "eval_frequency":20,
      "log_frequency":20,
      "max_session":10,
      "max_concurrent_session":10,
      "max_trial":1
    }
  },

  "ipd_ipm_le_vs_exploiter_no_strat_temp_1":{
    "world":{
      "name":"DefaultMultiAgentWorld",
      "deterministic":false
    },
    "agent":[
      {
        "name":"LE",
        "memory":null,
        "net":null,
        "welfare_function":"utilitarian_welfare",
        "observing_other_agents":{
          "name":"FullyObservable"
        },
        "algorithm":{
          "name":"LE",
          "punishement_time":1,
          "min_coop_time":0,
          "defection_detection_mode":"spl_observed_actions",
          "defection_carac_threshold":0.0,
          "average_d_carac":true,
          "average_d_carac_len":20,
          "same_init_weights":false,
          "coop_net_ent_diff_as_lr":false,
          "use_sl_for_simu_coop":false,
          "use_strat_4":false,
          "use_strat_5":false,
          "strat_5_coeff":10.0,
          "use_strat_2":false,
          "length_of_history":200,
          "block_len":4,
          "use_last_steps_for_search":true,
          "use_bolzmann_search":true,
          "meta_algo_memory":{
            "name":"Replay",
            "batch_size":1,
            "max_size":-1
          },
          "meta_algo_loss":{
            "reduction":"none",
            "name":"CrossEntropyLoss"
          },
          "contained_algorithms":[
            {
              "name":"DoubleDQN",
              "algorithm":{
                "name":"DoubleDQN",
                "action_pdtype":"Categorical",
                "action_policy":"boltzmann_on_cluster",
                "explore_var_spec":{
                  "name":"linear_decay",
                  "start_val":1.0,
                  "end_val":0.1,
                  "start_step":0,
                  "end_step":3000
                },
                "gamma":0.5,
                "normalize_inputs":true,
                "training_batch_iter":1,
                "training_iter":4,
                "training_frequency":60,
                "training_start_step":60
              },
              "memory":{
                "name":"Replay",
                "batch_size":60,
                "max_size":4000,
                "use_cer":true
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "clip_grad_val":1.0,
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.04,
                  "momentum":0.9
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            },
            {
              "copy_n":0
            },
            {
              "copy_n":0
            },
            {
              "name":"SupervisedLAPolicy",
              "algorithm":{
                "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
                "entropy_coef_spec":{
                  "name":"linear_decay",
                  "start_val":0.0,
                  "end_val":0.0,
                  "start_step":0,
                  "end_step":500
                },
                "training_frequency":1,
                "normalize_inputs":true,
                "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "loss_spec":{
                  "name":"CrossEntropyLoss",
                  "reduction":"none"
                },
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.40,
                  "momentum":0.000
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            }
          ]
        }
      },
      {
        "name":"LEExploiter",
        "memory":null,
        "net":null,
        "welfare_function":"default_welfare",
        "observing_other_agents":{
          "name":"FullyObservable"
        },
        "algorithm":{
          "name":"LEExploiter",
          "punishement_time":1,
          "min_coop_time":0,
          "defection_detection_mode":"spl_observed_actions",
          "defection_carac_threshold":0.0,
          "average_d_carac":true,
          "average_d_carac_len":20,
          "same_init_weights":false,
          "coop_net_ent_diff_as_lr":false,
          "use_sl_for_simu_coop":false,
          "use_strat_4":false,
          "use_strat_5":false,
          "strat_5_coeff":10.0,
          "use_strat_2":false,
          "length_of_history":200,
          "block_len":4,
          "use_last_steps_for_search":true,
          "use_bolzmann_search":true,
          "meta_algo_memory":{
            "name":"Replay",
            "batch_size":1,
            "max_size":-1
          },
          "meta_algo_loss":{
            "reduction":"none",
            "name":"CrossEntropyLoss"
          },
          "contained_algorithms":[
            {
              "name":"DoubleDQN",
              "algorithm":{
                "name":"DoubleDQN",
                "action_pdtype":"Categorical",
                "action_policy":"boltzmann_on_cluster",
                "explore_var_spec":{
                  "name":"linear_decay",
                  "start_val":1.0,
                  "end_val":0.1,
                  "start_step":0,
                  "end_step":3000
                },
                "gamma":0.5,
                "normalize_inputs":true,
                "training_batch_iter":1,
                "training_iter":4,
                "training_frequency":60,
                "training_start_step":60
              },
              "memory":{
                "name":"Replay",
                "batch_size":60,
                "max_size":4000,
                "use_cer":true
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "clip_grad_val":1.0,
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.04,
                  "momentum":0.9
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            },
            {
              "copy_n":0
            },
            {
              "copy_n":0
            },
            {
              "name":"SupervisedLAPolicy",
              "algorithm":{
                "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
                "entropy_coef_spec":{
                  "name":"linear_decay",
                  "start_val":0.0,
                  "end_val":0.0,
                  "start_step":0,
                  "end_step":500
                },
                "training_frequency":1,
                "normalize_inputs":true,
                "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "loss_spec":{
                  "name":"CrossEntropyLoss",
                  "reduction":"none"
                },
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.40,
                  "momentum":0.000
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            }
          ]
        }
      }
    ],
    "env":[
      {
        "name":"IteratedPrisonersDilemma-v0",
        "max_t":null,
        "max_frame":4000,
        "num_envs":1
      }
    ],
    "body":{
      "product":"outer",
      "num":1
    },
    "meta":{
      "distributed":false,
      "eval_frequency":20,
      "log_frequency":20,
      "max_session":10,
      "max_concurrent_session":10,
      "max_trial":1
    }
  },
  "ipd_ipm_le_vs_exploiter_strat_2_temp_1":{
    "world":{
      "name":"DefaultMultiAgentWorld",
      "deterministic":false
    },
    "agent":[
      {
        "name":"LE",
        "memory":null,
        "net":null,
        "welfare_function":"utilitarian_welfare",
        "observing_other_agents":{
          "name":"FullyObservable"
        },
        "algorithm":{
          "name":"LE",
          "punishement_time":1,
          "min_coop_time":0,
          "defection_detection_mode":"spl_observed_actions",
          "defection_carac_threshold":0.0,
          "average_d_carac":true,
          "average_d_carac_len":20,
          "same_init_weights":false,
          "coop_net_ent_diff_as_lr":false,
          "use_sl_for_simu_coop":false,
          "use_strat_4":false,
          "use_strat_5":false,
          "strat_5_coeff":10.0,
          "use_strat_2":true,
          "length_of_history":200,
          "block_len":4,
          "use_last_steps_for_search":true,
          "use_bolzmann_search":true,
          "meta_algo_memory":{
            "name":"Replay",
            "batch_size":1,
            "max_size":-1
          },
          "meta_algo_loss":{
            "reduction":"none",
            "name":"CrossEntropyLoss"
          },
          "contained_algorithms":[
            {
              "name":"DoubleDQN",
              "algorithm":{
                "name":"DoubleDQN",
                "action_pdtype":"Categorical",
                "action_policy":"boltzmann_on_cluster",
                "explore_var_spec":{
                  "name":"linear_decay",
                  "start_val":1.0,
                  "end_val":0.1,
                  "start_step":0,
                  "end_step":3000
                },
                "gamma":0.5,
                "normalize_inputs":true,
                "training_batch_iter":1,
                "training_iter":4,
                "training_frequency":60,
                "training_start_step":60
              },
              "memory":{
                "name":"Replay",
                "batch_size":60,
                "max_size":4000,
                "use_cer":true
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "clip_grad_val":1.0,
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.04,
                  "momentum":0.9
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            },
            {
              "copy_n":0
            },
            {
              "copy_n":0
            },
            {
              "name":"SupervisedLAPolicy",
              "algorithm":{
                "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
                "entropy_coef_spec":{
                  "name":"linear_decay",
                  "start_val":0.0,
                  "end_val":0.0,
                  "start_step":0,
                  "end_step":500
                },
                "training_frequency":1,
                "normalize_inputs":true,
                "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "loss_spec":{
                  "name":"CrossEntropyLoss",
                  "reduction":"none"
                },
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.40,
                  "momentum":0.000
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            }
          ]
        }
      },
      {
        "name":"LEExploiter",
        "memory":null,
        "net":null,
        "welfare_function":"default_welfare",
        "observing_other_agents":{
          "name":"FullyObservable"
        },
        "algorithm":{
          "name":"LEExploiter",
          "punishement_time":1,
          "min_coop_time":0,
          "defection_detection_mode":"spl_observed_actions",
          "defection_carac_threshold":0.0,
          "average_d_carac":true,
          "average_d_carac_len":20,
          "same_init_weights":false,
          "coop_net_ent_diff_as_lr":false,
          "use_sl_for_simu_coop":false,
          "use_strat_4":false,
          "use_strat_5":false,
          "strat_5_coeff":10.0,
          "use_strat_2":true,
          "length_of_history":200,
          "block_len":4,
          "use_last_steps_for_search":true,
          "use_bolzmann_search":true,
          "meta_algo_memory":{
            "name":"Replay",
            "batch_size":1,
            "max_size":-1
          },
          "meta_algo_loss":{
            "reduction":"none",
            "name":"CrossEntropyLoss"
          },
          "contained_algorithms":[
            {
              "name":"DoubleDQN",
              "algorithm":{
                "name":"DoubleDQN",
                "action_pdtype":"Categorical",
                "action_policy":"boltzmann_on_cluster",
                "explore_var_spec":{
                  "name":"linear_decay",
                  "start_val":1.0,
                  "end_val":0.1,
                  "start_step":0,
                  "end_step":3000
                },
                "gamma":0.5,
                "normalize_inputs":true,
                "training_batch_iter":1,
                "training_iter":4,
                "training_frequency":60,
                "training_start_step":60
              },
              "memory":{
                "name":"Replay",
                "batch_size":60,
                "max_size":4000,
                "use_cer":true
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "clip_grad_val":1.0,
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.04,
                  "momentum":0.9
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            },
            {
              "copy_n":0
            },
            {
              "copy_n":0
            },
            {
              "name":"SupervisedLAPolicy",
              "algorithm":{
                "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
                "entropy_coef_spec":{
                  "name":"linear_decay",
                  "start_val":0.0,
                  "end_val":0.0,
                  "start_step":0,
                  "end_step":500
                },
                "training_frequency":1,
                "normalize_inputs":true,
                "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "loss_spec":{
                  "name":"CrossEntropyLoss",
                  "reduction":"none"
                },
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.40,
                  "momentum":0.000
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            }
          ]
        }
      }
    ],
    "env":[
      {
        "name":"IteratedPrisonersDilemma-v0",
        "max_t":null,
        "max_frame":4000,
        "num_envs":1
      }
    ],
    "body":{
      "product":"outer",
      "num":1
    },
    "meta":{
      "distributed":false,
      "eval_frequency":20,
      "log_frequency":20,
      "max_session":10,
      "max_concurrent_session":10,
      "max_trial":1
    }
  },
  "ipd_ipm_le_vs_exploiter_no_strat_temp_033":{
    "world":{
      "name":"DefaultMultiAgentWorld",
      "deterministic":false
    },
    "agent":[
      {
        "name":"LE",
        "memory":null,
        "net":null,
        "welfare_function":"utilitarian_welfare",
        "observing_other_agents":{
          "name":"FullyObservable"
        },
        "algorithm":{
          "name":"LE",
          "punishement_time":1,
          "min_coop_time":0,
          "defection_detection_mode":"spl_observed_actions",
          "defection_carac_threshold":0.0,
          "average_d_carac":true,
          "average_d_carac_len":20,
          "same_init_weights":false,
          "coop_net_ent_diff_as_lr":false,
          "use_sl_for_simu_coop":false,
          "use_strat_4":false,
          "use_strat_5":false,
          "strat_5_coeff":10.0,
          "use_strat_2":false,
          "length_of_history":200,
          "block_len":4,
          "use_last_steps_for_search":true,
          "use_bolzmann_search":true,
          "meta_algo_memory":{
            "name":"Replay",
            "batch_size":1,
            "max_size":-1
          },
          "meta_algo_loss":{
            "reduction":"none",
            "name":"CrossEntropyLoss"
          },
          "contained_algorithms":[
            {
              "name":"DoubleDQN",
              "algorithm":{
                "name":"DoubleDQN",
                "action_pdtype":"Categorical",
                "action_policy":"boltzmann_on_cluster",
                "explore_var_spec":{
                  "name":"linear_decay",
                  "start_val":1.0,
                  "end_val":0.1,
                  "start_step":0,
                  "end_step":3000
                },
                "gamma":0.5,
                "normalize_inputs":true,
                "training_batch_iter":1,
                "training_iter":4,
                "training_frequency":60,
                "training_start_step":60
              },
              "memory":{
                "name":"Replay",
                "batch_size":60,
                "max_size":4000,
                "use_cer":true
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "clip_grad_val":1.0,
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.04,
                  "momentum":0.9
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            },
            {
              "copy_n":0
            },
            {
              "copy_n":0
            },
            {
              "name":"SupervisedLAPolicy",
              "algorithm":{
                "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
                "entropy_coef_spec":{
                  "name":"linear_decay",
                  "start_val":0.0,
                  "end_val":0.0,
                  "start_step":0,
                  "end_step":500
                },
                "training_frequency":1,
                "normalize_inputs":true,
                "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "loss_spec":{
                  "name":"CrossEntropyLoss",
                  "reduction":"none"
                },
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.40,
                  "momentum":0.000
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            }
          ]
        }
      },
      {
        "name":"LEExploiter",
        "memory":null,
        "net":null,
        "welfare_function":"default_welfare",
        "observing_other_agents":{
          "name":"FullyObservable"
        },
        "algorithm":{
          "name":"LEExploiter",
          "punishement_time":1,
          "min_coop_time":0,
          "defection_detection_mode":"spl_observed_actions",
          "defection_carac_threshold":0.0,
          "average_d_carac":true,
          "average_d_carac_len":20,
          "same_init_weights":false,
          "coop_net_ent_diff_as_lr":false,
          "use_sl_for_simu_coop":false,
          "use_strat_4":false,
          "use_strat_5":false,
          "strat_5_coeff":10.0,
          "use_strat_2":false,
          "length_of_history":200,
          "block_len":4,
          "use_last_steps_for_search":true,
          "use_bolzmann_search":true,
          "meta_algo_memory":{
            "name":"Replay",
            "batch_size":1,
            "max_size":-1
          },
          "meta_algo_loss":{
            "reduction":"none",
            "name":"CrossEntropyLoss"
          },
          "contained_algorithms":[
            {
              "name":"DoubleDQN",
              "algorithm":{
                "name":"DoubleDQN",
                "action_pdtype":"Categorical",
                "action_policy":"boltzmann_on_cluster",
                "explore_var_spec":{
                  "name":"linear_decay",
                  "start_val":0.33,
                  "end_val":0.1,
                  "start_step":0,
                  "end_step":3000
                },
                "gamma":0.5,
                "normalize_inputs":true,
                "training_batch_iter":1,
                "training_iter":4,
                "training_frequency":60,
                "training_start_step":60
              },
              "memory":{
                "name":"Replay",
                "batch_size":60,
                "max_size":4000,
                "use_cer":true
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "clip_grad_val":1.0,
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.04,
                  "momentum":0.9
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            },
            {
              "copy_n":0
            },
            {
              "copy_n":0
            },
            {
              "name":"SupervisedLAPolicy",
              "algorithm":{
                "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
                "entropy_coef_spec":{
                  "name":"linear_decay",
                  "start_val":0.0,
                  "end_val":0.0,
                  "start_step":0,
                  "end_step":500
                },
                "training_frequency":1,
                "normalize_inputs":true,
                "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "loss_spec":{
                  "name":"CrossEntropyLoss",
                  "reduction":"none"
                },
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.40,
                  "momentum":0.000
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            }
          ]
        }
      }
    ],
    "env":[
      {
        "name":"IteratedPrisonersDilemma-v0",
        "max_t":null,
        "max_frame":4000,
        "num_envs":1
      }
    ],
    "body":{
      "product":"outer",
      "num":1
    },
    "meta":{
      "distributed":false,
      "eval_frequency":20,
      "log_frequency":20,
      "max_session":10,
      "max_concurrent_session":10,
      "max_trial":1
    }
  },
  "ipd_ipm_le_vs_exploiter_strat_2_temp_033":{
    "world":{
      "name":"DefaultMultiAgentWorld",
      "deterministic":false
    },
    "agent":[
      {
        "name":"LE",
        "memory":null,
        "net":null,
        "welfare_function":"utilitarian_welfare",
        "observing_other_agents":{
          "name":"FullyObservable"
        },
        "algorithm":{
          "name":"LE",
          "punishement_time":1,
          "min_coop_time":0,
          "defection_detection_mode":"spl_observed_actions",
          "defection_carac_threshold":0.0,
          "average_d_carac":true,
          "average_d_carac_len":20,
          "same_init_weights":false,
          "coop_net_ent_diff_as_lr":false,
          "use_sl_for_simu_coop":false,
          "use_strat_4":false,
          "use_strat_5":false,
          "strat_5_coeff":10.0,
          "use_strat_2":true,
          "length_of_history":200,
          "block_len":4,
          "use_last_steps_for_search":true,
          "use_bolzmann_search":true,
          "meta_algo_memory":{
            "name":"Replay",
            "batch_size":1,
            "max_size":-1
          },
          "meta_algo_loss":{
            "reduction":"none",
            "name":"CrossEntropyLoss"
          },
          "contained_algorithms":[
            {
              "name":"DoubleDQN",
              "algorithm":{
                "name":"DoubleDQN",
                "action_pdtype":"Categorical",
                "action_policy":"boltzmann_on_cluster",
                "explore_var_spec":{
                  "name":"linear_decay",
                  "start_val":1.0,
                  "end_val":0.1,
                  "start_step":0,
                  "end_step":3000
                },
                "gamma":0.5,
                "normalize_inputs":true,
                "training_batch_iter":1,
                "training_iter":4,
                "training_frequency":60,
                "training_start_step":60
              },
              "memory":{
                "name":"Replay",
                "batch_size":60,
                "max_size":4000,
                "use_cer":true
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "clip_grad_val":1.0,
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.04,
                  "momentum":0.9
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            },
            {
              "copy_n":0
            },
            {
              "copy_n":0
            },
            {
              "name":"SupervisedLAPolicy",
              "algorithm":{
                "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
                "entropy_coef_spec":{
                  "name":"linear_decay",
                  "start_val":0.0,
                  "end_val":0.0,
                  "start_step":0,
                  "end_step":500
                },
                "training_frequency":1,
                "normalize_inputs":true,
                "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "loss_spec":{
                  "name":"CrossEntropyLoss",
                  "reduction":"none"
                },
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.40,
                  "momentum":0.000
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            }
          ]
        }
      },
      {
        "name":"LEExploiter",
        "memory":null,
        "net":null,
        "welfare_function":"default_welfare",
        "observing_other_agents":{
          "name":"FullyObservable"
        },
        "algorithm":{
          "name":"LEExploiter",
          "punishement_time":1,
          "min_coop_time":0,
          "defection_detection_mode":"spl_observed_actions",
          "defection_carac_threshold":0.0,
          "average_d_carac":true,
          "average_d_carac_len":20,
          "same_init_weights":false,
          "coop_net_ent_diff_as_lr":false,
          "use_sl_for_simu_coop":false,
          "use_strat_4":false,
          "use_strat_5":false,
          "strat_5_coeff":10.0,
          "use_strat_2":true,
          "length_of_history":200,
          "block_len":4,
          "use_last_steps_for_search":true,
          "use_bolzmann_search":true,
          "meta_algo_memory":{
            "name":"Replay",
            "batch_size":1,
            "max_size":-1
          },
          "meta_algo_loss":{
            "reduction":"none",
            "name":"CrossEntropyLoss"
          },
          "contained_algorithms":[
            {
              "name":"DoubleDQN",
              "algorithm":{
                "name":"DoubleDQN",
                "action_pdtype":"Categorical",
                "action_policy":"boltzmann_on_cluster",
                "explore_var_spec":{
                  "name":"linear_decay",
                  "start_val":0.33,
                  "end_val":0.1,
                  "start_step":0,
                  "end_step":3000
                },
                "gamma":0.5,
                "normalize_inputs":true,
                "training_batch_iter":1,
                "training_iter":4,
                "training_frequency":60,
                "training_start_step":60
              },
              "memory":{
                "name":"Replay",
                "batch_size":60,
                "max_size":4000,
                "use_cer":true
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "clip_grad_val":1.0,
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.04,
                  "momentum":0.9
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            },
            {
              "copy_n":0
            },
            {
              "copy_n":0
            },
            {
              "name":"SupervisedLAPolicy",
              "algorithm":{
                "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
                "entropy_coef_spec":{
                  "name":"linear_decay",
                  "start_val":0.0,
                  "end_val":0.0,
                  "start_step":0,
                  "end_step":500
                },
                "training_frequency":1,
                "normalize_inputs":true,
                "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "loss_spec":{
                  "name":"CrossEntropyLoss",
                  "reduction":"none"
                },
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.40,
                  "momentum":0.000
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            }
          ]
        }
      }
    ],
    "env":[
      {
        "name":"IteratedPrisonersDilemma-v0",
        "max_t":null,
        "max_frame":4000,
        "num_envs":1
      }
    ],
    "body":{
      "product":"outer",
      "num":1
    },
    "meta":{
      "distributed":false,
      "eval_frequency":20,
      "log_frequency":20,
      "max_session":10,
      "max_concurrent_session":10,
      "max_trial":1
    }
  },
  "ipd_ipm_le_vs_exploiter_no_strat_temp_3":{
    "world":{
      "name":"DefaultMultiAgentWorld",
      "deterministic":false
    },
    "agent":[
      {
        "name":"LE",
        "memory":null,
        "net":null,
        "welfare_function":"utilitarian_welfare",
        "observing_other_agents":{
          "name":"FullyObservable"
        },
        "algorithm":{
          "name":"LE",
          "punishement_time":1,
          "min_coop_time":0,
          "defection_detection_mode":"spl_observed_actions",
          "defection_carac_threshold":0.0,
          "average_d_carac":true,
          "average_d_carac_len":20,
          "same_init_weights":false,
          "coop_net_ent_diff_as_lr":false,
          "use_sl_for_simu_coop":false,
          "use_strat_4":false,
          "use_strat_5":false,
          "strat_5_coeff":10.0,
          "use_strat_2":false,
          "length_of_history":200,
          "block_len":4,
          "use_last_steps_for_search":true,
          "use_bolzmann_search":true,
          "meta_algo_memory":{
            "name":"Replay",
            "batch_size":1,
            "max_size":-1
          },
          "meta_algo_loss":{
            "reduction":"none",
            "name":"CrossEntropyLoss"
          },
          "contained_algorithms":[
            {
              "name":"DoubleDQN",
              "algorithm":{
                "name":"DoubleDQN",
                "action_pdtype":"Categorical",
                "action_policy":"boltzmann_on_cluster",
                "explore_var_spec":{
                  "name":"linear_decay",
                  "start_val":1.0,
                  "end_val":0.1,
                  "start_step":0,
                  "end_step":3000
                },
                "gamma":0.5,
                "normalize_inputs":true,
                "training_batch_iter":1,
                "training_iter":4,
                "training_frequency":60,
                "training_start_step":60
              },
              "memory":{
                "name":"Replay",
                "batch_size":60,
                "max_size":4000,
                "use_cer":true
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "clip_grad_val":1.0,
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.04,
                  "momentum":0.9
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            },
            {
              "copy_n":0
            },
            {
              "copy_n":0
            },
            {
              "name":"SupervisedLAPolicy",
              "algorithm":{
                "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
                "entropy_coef_spec":{
                  "name":"linear_decay",
                  "start_val":0.0,
                  "end_val":0.0,
                  "start_step":0,
                  "end_step":500
                },
                "training_frequency":1,
                "normalize_inputs":true,
                "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "loss_spec":{
                  "name":"CrossEntropyLoss",
                  "reduction":"none"
                },
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.40,
                  "momentum":0.000
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            }
          ]
        }
      },
      {
        "name":"LEExploiter",
        "memory":null,
        "net":null,
        "welfare_function":"default_welfare",
        "observing_other_agents":{
          "name":"FullyObservable"
        },
        "algorithm":{
          "name":"LEExploiter",
          "punishement_time":1,
          "min_coop_time":0,
          "defection_detection_mode":"spl_observed_actions",
          "defection_carac_threshold":0.0,
          "average_d_carac":true,
          "average_d_carac_len":20,
          "same_init_weights":false,
          "coop_net_ent_diff_as_lr":false,
          "use_sl_for_simu_coop":false,
          "use_strat_4":false,
          "use_strat_5":false,
          "strat_5_coeff":10.0,
          "use_strat_2":false,
          "length_of_history":200,
          "block_len":4,
          "use_last_steps_for_search":true,
          "use_bolzmann_search":true,
          "meta_algo_memory":{
            "name":"Replay",
            "batch_size":1,
            "max_size":-1
          },
          "meta_algo_loss":{
            "reduction":"none",
            "name":"CrossEntropyLoss"
          },
          "contained_algorithms":[
            {
              "name":"DoubleDQN",
              "algorithm":{
                "name":"DoubleDQN",
                "action_pdtype":"Categorical",
                "action_policy":"boltzmann_on_cluster",
                "explore_var_spec":{
                  "name":"linear_decay",
                  "start_val":3.0,
                  "end_val":0.1,
                  "start_step":0,
                  "end_step":3000
                },
                "gamma":0.5,
                "normalize_inputs":true,
                "training_batch_iter":1,
                "training_iter":4,
                "training_frequency":60,
                "training_start_step":60
              },
              "memory":{
                "name":"Replay",
                "batch_size":60,
                "max_size":4000,
                "use_cer":true
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "clip_grad_val":1.0,
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.04,
                  "momentum":0.9
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            },
            {
              "copy_n":0
            },
            {
              "copy_n":0
            },
            {
              "name":"SupervisedLAPolicy",
              "algorithm":{
                "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
                "entropy_coef_spec":{
                  "name":"linear_decay",
                  "start_val":0.0,
                  "end_val":0.0,
                  "start_step":0,
                  "end_step":500
                },
                "training_frequency":1,
                "normalize_inputs":true,
                "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "loss_spec":{
                  "name":"CrossEntropyLoss",
                  "reduction":"none"
                },
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.40,
                  "momentum":0.000
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            }
          ]
        }
      }
    ],
    "env":[
      {
        "name":"IteratedPrisonersDilemma-v0",
        "max_t":null,
        "max_frame":4000,
        "num_envs":1
      }
    ],
    "body":{
      "product":"outer",
      "num":1
    },
    "meta":{
      "distributed":false,
      "eval_frequency":20,
      "log_frequency":20,
      "max_session":10,
      "max_concurrent_session":10,
      "max_trial":1
    }
  },
  "ipd_ipm_le_vs_exploiter_strat_2_temp_3":{
    "world":{
      "name":"DefaultMultiAgentWorld",
      "deterministic":false
    },
    "agent":[
      {
        "name":"LE",
        "memory":null,
        "net":null,
        "welfare_function":"utilitarian_welfare",
        "observing_other_agents":{
          "name":"FullyObservable"
        },
        "algorithm":{
          "name":"LE",
          "punishement_time":1,
          "min_coop_time":0,
          "defection_detection_mode":"spl_observed_actions",
          "defection_carac_threshold":0.0,
          "average_d_carac":true,
          "average_d_carac_len":20,
          "same_init_weights":false,
          "coop_net_ent_diff_as_lr":false,
          "use_sl_for_simu_coop":false,
          "use_strat_4":false,
          "use_strat_5":false,
          "strat_5_coeff":10.0,
          "use_strat_2":true,
          "length_of_history":200,
          "block_len":4,
          "use_last_steps_for_search":true,
          "use_bolzmann_search":true,
          "meta_algo_memory":{
            "name":"Replay",
            "batch_size":1,
            "max_size":-1
          },
          "meta_algo_loss":{
            "reduction":"none",
            "name":"CrossEntropyLoss"
          },
          "contained_algorithms":[
            {
              "name":"DoubleDQN",
              "algorithm":{
                "name":"DoubleDQN",
                "action_pdtype":"Categorical",
                "action_policy":"boltzmann_on_cluster",
                "explore_var_spec":{
                  "name":"linear_decay",
                  "start_val":1.0,
                  "end_val":0.1,
                  "start_step":0,
                  "end_step":3000
                },
                "gamma":0.5,
                "normalize_inputs":true,
                "training_batch_iter":1,
                "training_iter":4,
                "training_frequency":60,
                "training_start_step":60
              },
              "memory":{
                "name":"Replay",
                "batch_size":60,
                "max_size":4000,
                "use_cer":true
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "clip_grad_val":1.0,
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.04,
                  "momentum":0.9
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            },
            {
              "copy_n":0
            },
            {
              "copy_n":0
            },
            {
              "name":"SupervisedLAPolicy",
              "algorithm":{
                "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
                "entropy_coef_spec":{
                  "name":"linear_decay",
                  "start_val":0.0,
                  "end_val":0.0,
                  "start_step":0,
                  "end_step":500
                },
                "training_frequency":1,
                "normalize_inputs":true,
                "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "loss_spec":{
                  "name":"CrossEntropyLoss",
                  "reduction":"none"
                },
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.40,
                  "momentum":0.000
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            }
          ]
        }
      },
      {
        "name":"LEExploiter",
        "memory":null,
        "net":null,
        "welfare_function":"default_welfare",
        "observing_other_agents":{
          "name":"FullyObservable"
        },
        "algorithm":{
          "name":"LEExploiter",
          "punishement_time":1,
          "min_coop_time":0,
          "defection_detection_mode":"spl_observed_actions",
          "defection_carac_threshold":0.0,
          "average_d_carac":true,
          "average_d_carac_len":20,
          "same_init_weights":false,
          "coop_net_ent_diff_as_lr":false,
          "use_sl_for_simu_coop":false,
          "use_strat_4":false,
          "use_strat_5":false,
          "strat_5_coeff":10.0,
          "use_strat_2":true,
          "length_of_history":200,
          "block_len":4,
          "use_last_steps_for_search":true,
          "use_bolzmann_search":true,
          "meta_algo_memory":{
            "name":"Replay",
            "batch_size":1,
            "max_size":-1
          },
          "meta_algo_loss":{
            "reduction":"none",
            "name":"CrossEntropyLoss"
          },
          "contained_algorithms":[
            {
              "name":"DoubleDQN",
              "algorithm":{
                "name":"DoubleDQN",
                "action_pdtype":"Categorical",
                "action_policy":"boltzmann_on_cluster",
                "explore_var_spec":{
                  "name":"linear_decay",
                  "start_val":3.0,
                  "end_val":0.1,
                  "start_step":0,
                  "end_step":3000
                },
                "gamma":0.5,
                "normalize_inputs":true,
                "training_batch_iter":1,
                "training_iter":4,
                "training_frequency":60,
                "training_start_step":60
              },
              "memory":{
                "name":"Replay",
                "batch_size":60,
                "max_size":4000,
                "use_cer":true
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "clip_grad_val":1.0,
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.04,
                  "momentum":0.9
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            },
            {
              "copy_n":0
            },
            {
              "copy_n":0
            },
            {
              "name":"SupervisedLAPolicy",
              "algorithm":{
                "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
                "entropy_coef_spec":{
                  "name":"linear_decay",
                  "start_val":0.0,
                  "end_val":0.0,
                  "start_step":0,
                  "end_step":500
                },
                "training_frequency":1,
                "normalize_inputs":true,
                "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "loss_spec":{
                  "name":"CrossEntropyLoss",
                  "reduction":"none"
                },
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.40,
                  "momentum":0.000
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            }
          ]
        }
      }
    ],
    "env":[
      {
        "name":"IteratedPrisonersDilemma-v0",
        "max_t":null,
        "max_frame":4000,
        "num_envs":1
      }
    ],
    "body":{
      "product":"outer",
      "num":1
    },
    "meta":{
      "distributed":false,
      "eval_frequency":20,
      "log_frequency":20,
      "max_session":10,
      "max_concurrent_session":10,
      "max_trial":1
    }
  }

}


























