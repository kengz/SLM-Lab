{

  "ipd_ipm_le_self_play_strat_2_temp_1_0.95_0.95":{
    "world":{"name":"DefaultMultiAgentWorld",
             "deterministic":false},
    "agent":[{
      "name":"LE",
      "memory":null,
      "net":null,
      "welfare_function":"utilitarian_welfare",
      "observing_other_agents":{
        "name":"FullyObservable"
      },
      "algorithm":{
        "name":"LE",
        "punishement_time":1,
        "min_coop_time":0,
        "defection_detection_mode":"spl_observed_actions",
        "defection_carac_threshold":0.0,
        "average_d_carac":true,
        "average_d_carac_len":20,
        "same_init_weights":true,
        "coop_net_ent_diff_as_lr":false,
        "use_sl_for_simu_coop":false,
        "use_strat_4":false,
        "use_strat_5":false,
        "strat_5_coeff":10.0,
        "use_strat_2":true,
        "block_len":4,
        "use_last_steps_for_search":true,
        "use_bolzmann_search":true,
        "PERCENTILE_FOR_LIKELIHOOD_TEST":95,
        "meta_algo_memory":{
          "name":"Replay",
          "batch_size":1,
          "max_size":-1
        },
        "meta_algo_loss":{
          "reduction":"none",
          "name":"CrossEntropyLoss"
        },
        "contained_algorithms":[
          {
            "name":"DoubleDQN",
            "algorithm":{
              "name":"DoubleDQN",
              "action_pdtype":"Categorical",
              "action_policy":"boltzmann_on_cluster",
              "explore_var_spec":{
                "name":"linear_decay",
                "start_val":1.0,
                "end_val":0.1,
                "start_step":0,
                "end_step":3000
              },
              "gamma":0.5,
              "normalize_inputs":true,
              "training_batch_iter":1,
              "training_iter":4,
              "training_frequency":60,
              "training_start_step":60
            },
            "memory":{
              "name":"Replay",
              "batch_size":60,
              "max_size":4000,
              "use_cer":true
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "clip_grad_val":1.0,
              "optim_spec":{
                "name":"SGD",
                "lr":0.04,
                "momentum":0.9
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }

          },
          {
            "copy_n":0
          },
          {
            "copy_n":0
          },
          {
            "name":"SupervisedLAPolicy",
            "algorithm":{
              "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
               "entropy_coef_spec":{
                    "name":"linear_decay",
                    "start_val":0.0,
                    "end_val":0.0,
                    "start_step":0,
                    "end_step":500
               },
              "training_frequency":1,
              "normalize_inputs":true,
              "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "loss_spec":{
                "name":"CrossEntropyLoss",
                "reduction":"none"
              },
              "optim_spec":{
                "name":"SGD",
                "lr":0.40,
                "momentum":0.000
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }
          }
        ]

      }
    },
    {
      "name":"LE",
      "memory":null,
      "net":null,
      "welfare_function":"utilitarian_welfare",
      "observing_other_agents":{
        "name":"FullyObservable"
      },
      "algorithm":{
        "name":"LE",
        "punishement_time":1,
        "min_coop_time":0,
        "defection_detection_mode":"spl_observed_actions",
        "defection_carac_threshold":0.0,
        "average_d_carac":true,
        "average_d_carac_len":20,
        "same_init_weights":true,
        "coop_net_ent_diff_as_lr":false,
        "use_sl_for_simu_coop":false,
        "use_strat_4":false,
        "use_strat_5":false,
        "strat_5_coeff":10.0,
        "use_strat_2":true,
        "block_len":4,
        "use_last_steps_for_search":true,
        "use_bolzmann_search":true,
        "PERCENTILE_FOR_LIKELIHOOD_TEST":95,
        "meta_algo_memory":{
          "name":"Replay",
          "batch_size":1,
          "max_size":-1
        },
        "meta_algo_loss":{
          "reduction":"none",
          "name":"CrossEntropyLoss"
        },
        "contained_algorithms":[
          {
            "name":"DoubleDQN",
            "algorithm":{
              "name":"DoubleDQN",
              "action_pdtype":"Categorical",
              "action_policy":"boltzmann_on_cluster",
              "explore_var_spec":{
                "name":"linear_decay",
                "start_val":1.0,
                "end_val":0.1,
                "start_step":0,
                "end_step":3000
              },
              "gamma":0.5,
              "normalize_inputs":true,
              "training_batch_iter":1,
              "training_iter":4,
              "training_frequency":60,
              "training_start_step":60
            },
            "memory":{
              "name":"Replay",
              "batch_size":60,
              "max_size":4000,
              "use_cer":true
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "clip_grad_val":1.0,
              "optim_spec":{
                "name":"SGD",
                "lr":0.04,
                "momentum":0.9
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }

          },
          {
            "copy_n":0
          },
          {
            "copy_n":0
          },
          {
            "name":"SupervisedLAPolicy",
            "algorithm":{
              "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
               "entropy_coef_spec":{
                    "name":"linear_decay",
                    "start_val":0.0,
                    "end_val":0.0,
                    "start_step":0,
                    "end_step":500
               },
              "training_frequency":1,
              "normalize_inputs":true,
              "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "loss_spec":{
                "name":"CrossEntropyLoss",
                "reduction":"none"
              },
              "optim_spec":{
                "name":"SGD",
                "lr":0.40,
                "momentum":0.000
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }
          }
        ]

      }
    }
    ],
    "env":[{
      "name":"IteratedPrisonersDilemma-v0",
      "max_t":null,
      "max_frame":4000,
      "num_envs":1
    }],
    "body":{
      "product":"outer",
      "num":1
    },
    "meta":{
      "distributed":false,
      "eval_frequency":20,
      "log_frequency":20,
      "max_session":10,
      "max_concurrent_session":10,
      "max_trial":1
    }
  },
  "ipd_ipm_le_self_play_strat_2_temp_1_0.95_0.85":{
    "world":{"name":"DefaultMultiAgentWorld",
             "deterministic":false},
    "agent":[{
      "name":"LE",
      "memory":null,
      "net":null,
      "welfare_function":"utilitarian_welfare",
      "observing_other_agents":{
        "name":"FullyObservable"
      },
      "algorithm":{
        "name":"LE",
        "punishement_time":1,
        "min_coop_time":0,
        "defection_detection_mode":"spl_observed_actions",
        "defection_carac_threshold":0.0,
        "average_d_carac":true,
        "average_d_carac_len":20,
        "same_init_weights":true,
        "coop_net_ent_diff_as_lr":false,
        "use_sl_for_simu_coop":false,
        "use_strat_4":false,
        "use_strat_5":false,
        "strat_5_coeff":10.0,
        "use_strat_2":true,
        "block_len":4,
        "use_last_steps_for_search":true,
        "use_bolzmann_search":true,
        "PERCENTILE_FOR_LIKELIHOOD_TEST":95,
        "meta_algo_memory":{
          "name":"Replay",
          "batch_size":1,
          "max_size":-1
        },
        "meta_algo_loss":{
          "reduction":"none",
          "name":"CrossEntropyLoss"
        },
        "contained_algorithms":[
          {
            "name":"DoubleDQN",
            "algorithm":{
              "name":"DoubleDQN",
              "action_pdtype":"Categorical",
              "action_policy":"boltzmann_on_cluster",
              "explore_var_spec":{
                "name":"linear_decay",
                "start_val":1.0,
                "end_val":0.1,
                "start_step":0,
                "end_step":3000
              },
              "gamma":0.5,
              "normalize_inputs":true,
              "training_batch_iter":1,
              "training_iter":4,
              "training_frequency":60,
              "training_start_step":60
            },
            "memory":{
              "name":"Replay",
              "batch_size":60,
              "max_size":4000,
              "use_cer":true
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "clip_grad_val":1.0,
              "optim_spec":{
                "name":"SGD",
                "lr":0.04,
                "momentum":0.9
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }

          },
          {
            "copy_n":0
          },
          {
            "copy_n":0
          },
          {
            "name":"SupervisedLAPolicy",
            "algorithm":{
              "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
               "entropy_coef_spec":{
                    "name":"linear_decay",
                    "start_val":0.0,
                    "end_val":0.0,
                    "start_step":0,
                    "end_step":500
               },
              "training_frequency":1,
              "normalize_inputs":true,
              "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "loss_spec":{
                "name":"CrossEntropyLoss",
                "reduction":"none"
              },
              "optim_spec":{
                "name":"SGD",
                "lr":0.40,
                "momentum":0.000
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }
          }
        ]

      }
    },
    {
      "name":"LE",
      "memory":null,
      "net":null,
      "welfare_function":"utilitarian_welfare",
      "observing_other_agents":{
        "name":"FullyObservable"
      },
      "algorithm":{
        "name":"LE",
        "punishement_time":1,
        "min_coop_time":0,
        "defection_detection_mode":"spl_observed_actions",
        "defection_carac_threshold":0.0,
        "average_d_carac":true,
        "average_d_carac_len":20,
        "same_init_weights":true,
        "coop_net_ent_diff_as_lr":false,
        "use_sl_for_simu_coop":false,
        "use_strat_4":false,
        "use_strat_5":false,
        "strat_5_coeff":10.0,
        "use_strat_2":true,
        "block_len":4,
        "use_last_steps_for_search":true,
        "use_bolzmann_search":true,
        "PERCENTILE_FOR_LIKELIHOOD_TEST":85,
        "meta_algo_memory":{
          "name":"Replay",
          "batch_size":1,
          "max_size":-1
        },
        "meta_algo_loss":{
          "reduction":"none",
          "name":"CrossEntropyLoss"
        },
        "contained_algorithms":[
          {
            "name":"DoubleDQN",
            "algorithm":{
              "name":"DoubleDQN",
              "action_pdtype":"Categorical",
              "action_policy":"boltzmann_on_cluster",
              "explore_var_spec":{
                "name":"linear_decay",
                "start_val":1.0,
                "end_val":0.1,
                "start_step":0,
                "end_step":3000
              },
              "gamma":0.5,
              "normalize_inputs":true,
              "training_batch_iter":1,
              "training_iter":4,
              "training_frequency":60,
              "training_start_step":60
            },
            "memory":{
              "name":"Replay",
              "batch_size":60,
              "max_size":4000,
              "use_cer":true
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "clip_grad_val":1.0,
              "optim_spec":{
                "name":"SGD",
                "lr":0.04,
                "momentum":0.9
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }

          },
          {
            "copy_n":0
          },
          {
            "copy_n":0
          },
          {
            "name":"SupervisedLAPolicy",
            "algorithm":{
              "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
               "entropy_coef_spec":{
                    "name":"linear_decay",
                    "start_val":0.0,
                    "end_val":0.0,
                    "start_step":0,
                    "end_step":500
               },
              "training_frequency":1,
              "normalize_inputs":true,
              "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "loss_spec":{
                "name":"CrossEntropyLoss",
                "reduction":"none"
              },
              "optim_spec":{
                "name":"SGD",
                "lr":0.40,
                "momentum":0.000
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }
          }
        ]

      }
    }
    ],
    "env":[{
      "name":"IteratedPrisonersDilemma-v0",
      "max_t":null,
      "max_frame":4000,
      "num_envs":1
    }],
    "body":{
      "product":"outer",
      "num":1
    },
    "meta":{
      "distributed":false,
      "eval_frequency":20,
      "log_frequency":20,
      "max_session":10,
      "max_concurrent_session":10,
      "max_trial":1
    }
  },
  "ipd_ipm_le_self_play_strat_2_temp_1_0.95_0.75":{
    "world":{"name":"DefaultMultiAgentWorld",
             "deterministic":false},
    "agent":[{
      "name":"LE",
      "memory":null,
      "net":null,
      "welfare_function":"utilitarian_welfare",
      "observing_other_agents":{
        "name":"FullyObservable"
      },
      "algorithm":{
        "name":"LE",
        "punishement_time":1,
        "min_coop_time":0,
        "defection_detection_mode":"spl_observed_actions",
        "defection_carac_threshold":0.0,
        "average_d_carac":true,
        "average_d_carac_len":20,
        "same_init_weights":true,
        "coop_net_ent_diff_as_lr":false,
        "use_sl_for_simu_coop":false,
        "use_strat_4":false,
        "use_strat_5":false,
        "strat_5_coeff":10.0,
        "use_strat_2":true,
        "block_len":4,
        "use_last_steps_for_search":true,
        "use_bolzmann_search":true,
        "PERCENTILE_FOR_LIKELIHOOD_TEST":95,
        "meta_algo_memory":{
          "name":"Replay",
          "batch_size":1,
          "max_size":-1
        },
        "meta_algo_loss":{
          "reduction":"none",
          "name":"CrossEntropyLoss"
        },
        "contained_algorithms":[
          {
            "name":"DoubleDQN",
            "algorithm":{
              "name":"DoubleDQN",
              "action_pdtype":"Categorical",
              "action_policy":"boltzmann_on_cluster",
              "explore_var_spec":{
                "name":"linear_decay",
                "start_val":1.0,
                "end_val":0.1,
                "start_step":0,
                "end_step":3000
              },
              "gamma":0.5,
              "normalize_inputs":true,
              "training_batch_iter":1,
              "training_iter":4,
              "training_frequency":60,
              "training_start_step":60
            },
            "memory":{
              "name":"Replay",
              "batch_size":60,
              "max_size":4000,
              "use_cer":true
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "clip_grad_val":1.0,
              "optim_spec":{
                "name":"SGD",
                "lr":0.04,
                "momentum":0.9
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }

          },
          {
            "copy_n":0
          },
          {
            "copy_n":0
          },
          {
            "name":"SupervisedLAPolicy",
            "algorithm":{
              "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
               "entropy_coef_spec":{
                    "name":"linear_decay",
                    "start_val":0.0,
                    "end_val":0.0,
                    "start_step":0,
                    "end_step":500
               },
              "training_frequency":1,
              "normalize_inputs":true,
              "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "loss_spec":{
                "name":"CrossEntropyLoss",
                "reduction":"none"
              },
              "optim_spec":{
                "name":"SGD",
                "lr":0.40,
                "momentum":0.000
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }
          }
        ]

      }
    },
    {
      "name":"LE",
      "memory":null,
      "net":null,
      "welfare_function":"utilitarian_welfare",
      "observing_other_agents":{
        "name":"FullyObservable"
      },
      "algorithm":{
        "name":"LE",
        "punishement_time":1,
        "min_coop_time":0,
        "defection_detection_mode":"spl_observed_actions",
        "defection_carac_threshold":0.0,
        "average_d_carac":true,
        "average_d_carac_len":20,
        "same_init_weights":true,
        "coop_net_ent_diff_as_lr":false,
        "use_sl_for_simu_coop":false,
        "use_strat_4":false,
        "use_strat_5":false,
        "strat_5_coeff":10.0,
        "use_strat_2":true,
        "block_len":4,
        "use_last_steps_for_search":true,
        "use_bolzmann_search":true,
        "PERCENTILE_FOR_LIKELIHOOD_TEST":75,
        "meta_algo_memory":{
          "name":"Replay",
          "batch_size":1,
          "max_size":-1
        },
        "meta_algo_loss":{
          "reduction":"none",
          "name":"CrossEntropyLoss"
        },
        "contained_algorithms":[
          {
            "name":"DoubleDQN",
            "algorithm":{
              "name":"DoubleDQN",
              "action_pdtype":"Categorical",
              "action_policy":"boltzmann_on_cluster",
              "explore_var_spec":{
                "name":"linear_decay",
                "start_val":1.0,
                "end_val":0.1,
                "start_step":0,
                "end_step":3000
              },
              "gamma":0.5,
              "normalize_inputs":true,
              "training_batch_iter":1,
              "training_iter":4,
              "training_frequency":60,
              "training_start_step":60
            },
            "memory":{
              "name":"Replay",
              "batch_size":60,
              "max_size":4000,
              "use_cer":true
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "clip_grad_val":1.0,
              "optim_spec":{
                "name":"SGD",
                "lr":0.04,
                "momentum":0.9
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }

          },
          {
            "copy_n":0
          },
          {
            "copy_n":0
          },
          {
            "name":"SupervisedLAPolicy",
            "algorithm":{
              "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
               "entropy_coef_spec":{
                    "name":"linear_decay",
                    "start_val":0.0,
                    "end_val":0.0,
                    "start_step":0,
                    "end_step":500
               },
              "training_frequency":1,
              "normalize_inputs":true,
              "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "loss_spec":{
                "name":"CrossEntropyLoss",
                "reduction":"none"
              },
              "optim_spec":{
                "name":"SGD",
                "lr":0.40,
                "momentum":0.000
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }
          }
        ]

      }
    }
    ],
    "env":[{
      "name":"IteratedPrisonersDilemma-v0",
      "max_t":null,
      "max_frame":4000,
      "num_envs":1
    }],
    "body":{
      "product":"outer",
      "num":1
    },
    "meta":{
      "distributed":false,
      "eval_frequency":20,
      "log_frequency":20,
      "max_session":10,
      "max_concurrent_session":10,
      "max_trial":1
    }
  },
  "ipd_ipm_le_self_play_strat_2_temp_1_0.95_0.65":{
    "world":{"name":"DefaultMultiAgentWorld",
             "deterministic":false},
    "agent":[{
      "name":"LE",
      "memory":null,
      "net":null,
      "welfare_function":"utilitarian_welfare",
      "observing_other_agents":{
        "name":"FullyObservable"
      },
      "algorithm":{
        "name":"LE",
        "punishement_time":1,
        "min_coop_time":0,
        "defection_detection_mode":"spl_observed_actions",
        "defection_carac_threshold":0.0,
        "average_d_carac":true,
        "average_d_carac_len":20,
        "same_init_weights":true,
        "coop_net_ent_diff_as_lr":false,
        "use_sl_for_simu_coop":false,
        "use_strat_4":false,
        "use_strat_5":false,
        "strat_5_coeff":10.0,
        "use_strat_2":true,
        "block_len":4,
        "use_last_steps_for_search":true,
        "use_bolzmann_search":true,
        "PERCENTILE_FOR_LIKELIHOOD_TEST":95,
        "meta_algo_memory":{
          "name":"Replay",
          "batch_size":1,
          "max_size":-1
        },
        "meta_algo_loss":{
          "reduction":"none",
          "name":"CrossEntropyLoss"
        },
        "contained_algorithms":[
          {
            "name":"DoubleDQN",
            "algorithm":{
              "name":"DoubleDQN",
              "action_pdtype":"Categorical",
              "action_policy":"boltzmann_on_cluster",
              "explore_var_spec":{
                "name":"linear_decay",
                "start_val":1.0,
                "end_val":0.1,
                "start_step":0,
                "end_step":3000
              },
              "gamma":0.5,
              "normalize_inputs":true,
              "training_batch_iter":1,
              "training_iter":4,
              "training_frequency":60,
              "training_start_step":60
            },
            "memory":{
              "name":"Replay",
              "batch_size":60,
              "max_size":4000,
              "use_cer":true
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "clip_grad_val":1.0,
              "optim_spec":{
                "name":"SGD",
                "lr":0.04,
                "momentum":0.9
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }

          },
          {
            "copy_n":0
          },
          {
            "copy_n":0
          },
          {
            "name":"SupervisedLAPolicy",
            "algorithm":{
              "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
               "entropy_coef_spec":{
                    "name":"linear_decay",
                    "start_val":0.0,
                    "end_val":0.0,
                    "start_step":0,
                    "end_step":500
               },
              "training_frequency":1,
              "normalize_inputs":true,
              "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "loss_spec":{
                "name":"CrossEntropyLoss",
                "reduction":"none"
              },
              "optim_spec":{
                "name":"SGD",
                "lr":0.40,
                "momentum":0.000
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }
          }
        ]

      }
    },
    {
      "name":"LE",
      "memory":null,
      "net":null,
      "welfare_function":"utilitarian_welfare",
      "observing_other_agents":{
        "name":"FullyObservable"
      },
      "algorithm":{
        "name":"LE",
        "punishement_time":1,
        "min_coop_time":0,
        "defection_detection_mode":"spl_observed_actions",
        "defection_carac_threshold":0.0,
        "average_d_carac":true,
        "average_d_carac_len":20,
        "same_init_weights":true,
        "coop_net_ent_diff_as_lr":false,
        "use_sl_for_simu_coop":false,
        "use_strat_4":false,
        "use_strat_5":false,
        "strat_5_coeff":10.0,
        "use_strat_2":true,
        "block_len":4,
        "use_last_steps_for_search":true,
        "use_bolzmann_search":true,
        "PERCENTILE_FOR_LIKELIHOOD_TEST":65,
        "meta_algo_memory":{
          "name":"Replay",
          "batch_size":1,
          "max_size":-1
        },
        "meta_algo_loss":{
          "reduction":"none",
          "name":"CrossEntropyLoss"
        },
        "contained_algorithms":[
          {
            "name":"DoubleDQN",
            "algorithm":{
              "name":"DoubleDQN",
              "action_pdtype":"Categorical",
              "action_policy":"boltzmann_on_cluster",
              "explore_var_spec":{
                "name":"linear_decay",
                "start_val":1.0,
                "end_val":0.1,
                "start_step":0,
                "end_step":3000
              },
              "gamma":0.5,
              "normalize_inputs":true,
              "training_batch_iter":1,
              "training_iter":4,
              "training_frequency":60,
              "training_start_step":60
            },
            "memory":{
              "name":"Replay",
              "batch_size":60,
              "max_size":4000,
              "use_cer":true
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "clip_grad_val":1.0,
              "optim_spec":{
                "name":"SGD",
                "lr":0.04,
                "momentum":0.9
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }

          },
          {
            "copy_n":0
          },
          {
            "copy_n":0
          },
          {
            "name":"SupervisedLAPolicy",
            "algorithm":{
              "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
               "entropy_coef_spec":{
                    "name":"linear_decay",
                    "start_val":0.0,
                    "end_val":0.0,
                    "start_step":0,
                    "end_step":500
               },
              "training_frequency":1,
              "normalize_inputs":true,
              "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "loss_spec":{
                "name":"CrossEntropyLoss",
                "reduction":"none"
              },
              "optim_spec":{
                "name":"SGD",
                "lr":0.40,
                "momentum":0.000
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }
          }
        ]

      }
    }
    ],
    "env":[{
      "name":"IteratedPrisonersDilemma-v0",
      "max_t":null,
      "max_frame":4000,
      "num_envs":1
    }],
    "body":{
      "product":"outer",
      "num":1
    },
    "meta":{
      "distributed":false,
      "eval_frequency":20,
      "log_frequency":20,
      "max_session":10,
      "max_concurrent_session":10,
      "max_trial":1
    }
  },
  "ipd_ipm_le_self_play_strat_2_temp_1_0.95_0.55":{
    "world":{"name":"DefaultMultiAgentWorld",
             "deterministic":false},
    "agent":[{
      "name":"LE",
      "memory":null,
      "net":null,
      "welfare_function":"utilitarian_welfare",
      "observing_other_agents":{
        "name":"FullyObservable"
      },
      "algorithm":{
        "name":"LE",
        "punishement_time":1,
        "min_coop_time":0,
        "defection_detection_mode":"spl_observed_actions",
        "defection_carac_threshold":0.0,
        "average_d_carac":true,
        "average_d_carac_len":20,
        "same_init_weights":true,
        "coop_net_ent_diff_as_lr":false,
        "use_sl_for_simu_coop":false,
        "use_strat_4":false,
        "use_strat_5":false,
        "strat_5_coeff":10.0,
        "use_strat_2":true,
        "block_len":4,
        "use_last_steps_for_search":true,
        "use_bolzmann_search":true,
        "PERCENTILE_FOR_LIKELIHOOD_TEST":95,
        "meta_algo_memory":{
          "name":"Replay",
          "batch_size":1,
          "max_size":-1
        },
        "meta_algo_loss":{
          "reduction":"none",
          "name":"CrossEntropyLoss"
        },
        "contained_algorithms":[
          {
            "name":"DoubleDQN",
            "algorithm":{
              "name":"DoubleDQN",
              "action_pdtype":"Categorical",
              "action_policy":"boltzmann_on_cluster",
              "explore_var_spec":{
                "name":"linear_decay",
                "start_val":1.0,
                "end_val":0.1,
                "start_step":0,
                "end_step":3000
              },
              "gamma":0.5,
              "normalize_inputs":true,
              "training_batch_iter":1,
              "training_iter":4,
              "training_frequency":60,
              "training_start_step":60
            },
            "memory":{
              "name":"Replay",
              "batch_size":60,
              "max_size":4000,
              "use_cer":true
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "clip_grad_val":1.0,
              "optim_spec":{
                "name":"SGD",
                "lr":0.04,
                "momentum":0.9
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }

          },
          {
            "copy_n":0
          },
          {
            "copy_n":0
          },
          {
            "name":"SupervisedLAPolicy",
            "algorithm":{
              "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
               "entropy_coef_spec":{
                    "name":"linear_decay",
                    "start_val":0.0,
                    "end_val":0.0,
                    "start_step":0,
                    "end_step":500
               },
              "training_frequency":1,
              "normalize_inputs":true,
              "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "loss_spec":{
                "name":"CrossEntropyLoss",
                "reduction":"none"
              },
              "optim_spec":{
                "name":"SGD",
                "lr":0.40,
                "momentum":0.000
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }
          }
        ]

      }
    },
    {
      "name":"LE",
      "memory":null,
      "net":null,
      "welfare_function":"utilitarian_welfare",
      "observing_other_agents":{
        "name":"FullyObservable"
      },
      "algorithm":{
        "name":"LE",
        "punishement_time":1,
        "min_coop_time":0,
        "defection_detection_mode":"spl_observed_actions",
        "defection_carac_threshold":0.0,
        "average_d_carac":true,
        "average_d_carac_len":20,
        "same_init_weights":true,
        "coop_net_ent_diff_as_lr":false,
        "use_sl_for_simu_coop":false,
        "use_strat_4":false,
        "use_strat_5":false,
        "strat_5_coeff":10.0,
        "use_strat_2":true,
        "block_len":4,
        "use_last_steps_for_search":true,
        "use_bolzmann_search":true,
        "PERCENTILE_FOR_LIKELIHOOD_TEST":55,
        "meta_algo_memory":{
          "name":"Replay",
          "batch_size":1,
          "max_size":-1
        },
        "meta_algo_loss":{
          "reduction":"none",
          "name":"CrossEntropyLoss"
        },
        "contained_algorithms":[
          {
            "name":"DoubleDQN",
            "algorithm":{
              "name":"DoubleDQN",
              "action_pdtype":"Categorical",
              "action_policy":"boltzmann_on_cluster",
              "explore_var_spec":{
                "name":"linear_decay",
                "start_val":1.0,
                "end_val":0.1,
                "start_step":0,
                "end_step":3000
              },
              "gamma":0.5,
              "normalize_inputs":true,
              "training_batch_iter":1,
              "training_iter":4,
              "training_frequency":60,
              "training_start_step":60
            },
            "memory":{
              "name":"Replay",
              "batch_size":60,
              "max_size":4000,
              "use_cer":true
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "clip_grad_val":1.0,
              "optim_spec":{
                "name":"SGD",
                "lr":0.04,
                "momentum":0.9
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }

          },
          {
            "copy_n":0
          },
          {
            "copy_n":0
          },
          {
            "name":"SupervisedLAPolicy",
            "algorithm":{
              "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
               "entropy_coef_spec":{
                    "name":"linear_decay",
                    "start_val":0.0,
                    "end_val":0.0,
                    "start_step":0,
                    "end_step":500
               },
              "training_frequency":1,
              "normalize_inputs":true,
              "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "loss_spec":{
                "name":"CrossEntropyLoss",
                "reduction":"none"
              },
              "optim_spec":{
                "name":"SGD",
                "lr":0.40,
                "momentum":0.000
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }
          }
        ]

      }
    }
    ],
    "env":[{
      "name":"IteratedPrisonersDilemma-v0",
      "max_t":null,
      "max_frame":4000,
      "num_envs":1
    }],
    "body":{
      "product":"outer",
      "num":1
    },
    "meta":{
      "distributed":false,
      "eval_frequency":20,
      "log_frequency":20,
      "max_session":10,
      "max_concurrent_session":10,
      "max_trial":1
    }
  },

  "ipd_ipm_le_self_play_strat_2_temp_1_0.85_0.95":{
    "world":{"name":"DefaultMultiAgentWorld",
             "deterministic":false},
    "agent":[{
      "name":"LE",
      "memory":null,
      "net":null,
      "welfare_function":"utilitarian_welfare",
      "observing_other_agents":{
        "name":"FullyObservable"
      },
      "algorithm":{
        "name":"LE",
        "punishement_time":1,
        "min_coop_time":0,
        "defection_detection_mode":"spl_observed_actions",
        "defection_carac_threshold":0.0,
        "average_d_carac":true,
        "average_d_carac_len":20,
        "same_init_weights":true,
        "coop_net_ent_diff_as_lr":false,
        "use_sl_for_simu_coop":false,
        "use_strat_4":false,
        "use_strat_5":false,
        "strat_5_coeff":10.0,
        "use_strat_2":true,
        "block_len":4,
        "use_last_steps_for_search":true,
        "use_bolzmann_search":true,
        "PERCENTILE_FOR_LIKELIHOOD_TEST":85,
        "meta_algo_memory":{
          "name":"Replay",
          "batch_size":1,
          "max_size":-1
        },
        "meta_algo_loss":{
          "reduction":"none",
          "name":"CrossEntropyLoss"
        },
        "contained_algorithms":[
          {
            "name":"DoubleDQN",
            "algorithm":{
              "name":"DoubleDQN",
              "action_pdtype":"Categorical",
              "action_policy":"boltzmann_on_cluster",
              "explore_var_spec":{
                "name":"linear_decay",
                "start_val":1.0,
                "end_val":0.1,
                "start_step":0,
                "end_step":3000
              },
              "gamma":0.5,
              "normalize_inputs":true,
              "training_batch_iter":1,
              "training_iter":4,
              "training_frequency":60,
              "training_start_step":60
            },
            "memory":{
              "name":"Replay",
              "batch_size":60,
              "max_size":4000,
              "use_cer":true
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "clip_grad_val":1.0,
              "optim_spec":{
                "name":"SGD",
                "lr":0.04,
                "momentum":0.9
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }

          },
          {
            "copy_n":0
          },
          {
            "copy_n":0
          },
          {
            "name":"SupervisedLAPolicy",
            "algorithm":{
              "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
               "entropy_coef_spec":{
                    "name":"linear_decay",
                    "start_val":0.0,
                    "end_val":0.0,
                    "start_step":0,
                    "end_step":500
               },
              "training_frequency":1,
              "normalize_inputs":true,
              "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "loss_spec":{
                "name":"CrossEntropyLoss",
                "reduction":"none"
              },
              "optim_spec":{
                "name":"SGD",
                "lr":0.40,
                "momentum":0.000
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }
          }
        ]

      }
    },
    {
      "name":"LE",
      "memory":null,
      "net":null,
      "welfare_function":"utilitarian_welfare",
      "observing_other_agents":{
        "name":"FullyObservable"
      },
      "algorithm":{
        "name":"LE",
        "punishement_time":1,
        "min_coop_time":0,
        "defection_detection_mode":"spl_observed_actions",
        "defection_carac_threshold":0.0,
        "average_d_carac":true,
        "average_d_carac_len":20,
        "same_init_weights":true,
        "coop_net_ent_diff_as_lr":false,
        "use_sl_for_simu_coop":false,
        "use_strat_4":false,
        "use_strat_5":false,
        "strat_5_coeff":10.0,
        "use_strat_2":true,
        "block_len":4,
        "use_last_steps_for_search":true,
        "use_bolzmann_search":true,
        "PERCENTILE_FOR_LIKELIHOOD_TEST":95,
        "meta_algo_memory":{
          "name":"Replay",
          "batch_size":1,
          "max_size":-1
        },
        "meta_algo_loss":{
          "reduction":"none",
          "name":"CrossEntropyLoss"
        },
        "contained_algorithms":[
          {
            "name":"DoubleDQN",
            "algorithm":{
              "name":"DoubleDQN",
              "action_pdtype":"Categorical",
              "action_policy":"boltzmann_on_cluster",
              "explore_var_spec":{
                "name":"linear_decay",
                "start_val":1.0,
                "end_val":0.1,
                "start_step":0,
                "end_step":3000
              },
              "gamma":0.5,
              "normalize_inputs":true,
              "training_batch_iter":1,
              "training_iter":4,
              "training_frequency":60,
              "training_start_step":60
            },
            "memory":{
              "name":"Replay",
              "batch_size":60,
              "max_size":4000,
              "use_cer":true
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "clip_grad_val":1.0,
              "optim_spec":{
                "name":"SGD",
                "lr":0.04,
                "momentum":0.9
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }

          },
          {
            "copy_n":0
          },
          {
            "copy_n":0
          },
          {
            "name":"SupervisedLAPolicy",
            "algorithm":{
              "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
               "entropy_coef_spec":{
                    "name":"linear_decay",
                    "start_val":0.0,
                    "end_val":0.0,
                    "start_step":0,
                    "end_step":500
               },
              "training_frequency":1,
              "normalize_inputs":true,
              "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "loss_spec":{
                "name":"CrossEntropyLoss",
                "reduction":"none"
              },
              "optim_spec":{
                "name":"SGD",
                "lr":0.40,
                "momentum":0.000
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }
          }
        ]

      }
    }
    ],
    "env":[{
      "name":"IteratedPrisonersDilemma-v0",
      "max_t":null,
      "max_frame":4000,
      "num_envs":1
    }],
    "body":{
      "product":"outer",
      "num":1
    },
    "meta":{
      "distributed":false,
      "eval_frequency":20,
      "log_frequency":20,
      "max_session":10,
      "max_concurrent_session":10,
      "max_trial":1
    }
  },
  "ipd_ipm_le_self_play_strat_2_temp_1_0.85_0.85":{
    "world":{"name":"DefaultMultiAgentWorld",
             "deterministic":false},
    "agent":[{
      "name":"LE",
      "memory":null,
      "net":null,
      "welfare_function":"utilitarian_welfare",
      "observing_other_agents":{
        "name":"FullyObservable"
      },
      "algorithm":{
        "name":"LE",
        "punishement_time":1,
        "min_coop_time":0,
        "defection_detection_mode":"spl_observed_actions",
        "defection_carac_threshold":0.0,
        "average_d_carac":true,
        "average_d_carac_len":20,
        "same_init_weights":true,
        "coop_net_ent_diff_as_lr":false,
        "use_sl_for_simu_coop":false,
        "use_strat_4":false,
        "use_strat_5":false,
        "strat_5_coeff":10.0,
        "use_strat_2":true,
        "block_len":4,
        "use_last_steps_for_search":true,
        "use_bolzmann_search":true,
        "PERCENTILE_FOR_LIKELIHOOD_TEST":85,
        "meta_algo_memory":{
          "name":"Replay",
          "batch_size":1,
          "max_size":-1
        },
        "meta_algo_loss":{
          "reduction":"none",
          "name":"CrossEntropyLoss"
        },
        "contained_algorithms":[
          {
            "name":"DoubleDQN",
            "algorithm":{
              "name":"DoubleDQN",
              "action_pdtype":"Categorical",
              "action_policy":"boltzmann_on_cluster",
              "explore_var_spec":{
                "name":"linear_decay",
                "start_val":1.0,
                "end_val":0.1,
                "start_step":0,
                "end_step":3000
              },
              "gamma":0.5,
              "normalize_inputs":true,
              "training_batch_iter":1,
              "training_iter":4,
              "training_frequency":60,
              "training_start_step":60
            },
            "memory":{
              "name":"Replay",
              "batch_size":60,
              "max_size":4000,
              "use_cer":true
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "clip_grad_val":1.0,
              "optim_spec":{
                "name":"SGD",
                "lr":0.04,
                "momentum":0.9
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }

          },
          {
            "copy_n":0
          },
          {
            "copy_n":0
          },
          {
            "name":"SupervisedLAPolicy",
            "algorithm":{
              "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
               "entropy_coef_spec":{
                    "name":"linear_decay",
                    "start_val":0.0,
                    "end_val":0.0,
                    "start_step":0,
                    "end_step":500
               },
              "training_frequency":1,
              "normalize_inputs":true,
              "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "loss_spec":{
                "name":"CrossEntropyLoss",
                "reduction":"none"
              },
              "optim_spec":{
                "name":"SGD",
                "lr":0.40,
                "momentum":0.000
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }
          }
        ]

      }
    },
    {
      "name":"LE",
      "memory":null,
      "net":null,
      "welfare_function":"utilitarian_welfare",
      "observing_other_agents":{
        "name":"FullyObservable"
      },
      "algorithm":{
        "name":"LE",
        "punishement_time":1,
        "min_coop_time":0,
        "defection_detection_mode":"spl_observed_actions",
        "defection_carac_threshold":0.0,
        "average_d_carac":true,
        "average_d_carac_len":20,
        "same_init_weights":true,
        "coop_net_ent_diff_as_lr":false,
        "use_sl_for_simu_coop":false,
        "use_strat_4":false,
        "use_strat_5":false,
        "strat_5_coeff":10.0,
        "use_strat_2":true,
        "block_len":4,
        "use_last_steps_for_search":true,
        "use_bolzmann_search":true,
        "PERCENTILE_FOR_LIKELIHOOD_TEST":85,
        "meta_algo_memory":{
          "name":"Replay",
          "batch_size":1,
          "max_size":-1
        },
        "meta_algo_loss":{
          "reduction":"none",
          "name":"CrossEntropyLoss"
        },
        "contained_algorithms":[
          {
            "name":"DoubleDQN",
            "algorithm":{
              "name":"DoubleDQN",
              "action_pdtype":"Categorical",
              "action_policy":"boltzmann_on_cluster",
              "explore_var_spec":{
                "name":"linear_decay",
                "start_val":1.0,
                "end_val":0.1,
                "start_step":0,
                "end_step":3000
              },
              "gamma":0.5,
              "normalize_inputs":true,
              "training_batch_iter":1,
              "training_iter":4,
              "training_frequency":60,
              "training_start_step":60
            },
            "memory":{
              "name":"Replay",
              "batch_size":60,
              "max_size":4000,
              "use_cer":true
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "clip_grad_val":1.0,
              "optim_spec":{
                "name":"SGD",
                "lr":0.04,
                "momentum":0.9
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }

          },
          {
            "copy_n":0
          },
          {
            "copy_n":0
          },
          {
            "name":"SupervisedLAPolicy",
            "algorithm":{
              "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
               "entropy_coef_spec":{
                    "name":"linear_decay",
                    "start_val":0.0,
                    "end_val":0.0,
                    "start_step":0,
                    "end_step":500
               },
              "training_frequency":1,
              "normalize_inputs":true,
              "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "loss_spec":{
                "name":"CrossEntropyLoss",
                "reduction":"none"
              },
              "optim_spec":{
                "name":"SGD",
                "lr":0.40,
                "momentum":0.000
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }
          }
        ]

      }
    }
    ],
    "env":[{
      "name":"IteratedPrisonersDilemma-v0",
      "max_t":null,
      "max_frame":4000,
      "num_envs":1
    }],
    "body":{
      "product":"outer",
      "num":1
    },
    "meta":{
      "distributed":false,
      "eval_frequency":20,
      "log_frequency":20,
      "max_session":10,
      "max_concurrent_session":10,
      "max_trial":1
    }
  },
  "ipd_ipm_le_self_play_strat_2_temp_1_0.85_0.75":{
    "world":{"name":"DefaultMultiAgentWorld",
             "deterministic":false},
    "agent":[{
      "name":"LE",
      "memory":null,
      "net":null,
      "welfare_function":"utilitarian_welfare",
      "observing_other_agents":{
        "name":"FullyObservable"
      },
      "algorithm":{
        "name":"LE",
        "punishement_time":1,
        "min_coop_time":0,
        "defection_detection_mode":"spl_observed_actions",
        "defection_carac_threshold":0.0,
        "average_d_carac":true,
        "average_d_carac_len":20,
        "same_init_weights":true,
        "coop_net_ent_diff_as_lr":false,
        "use_sl_for_simu_coop":false,
        "use_strat_4":false,
        "use_strat_5":false,
        "strat_5_coeff":10.0,
        "use_strat_2":true,
        "block_len":4,
        "use_last_steps_for_search":true,
        "use_bolzmann_search":true,
        "PERCENTILE_FOR_LIKELIHOOD_TEST":85,
        "meta_algo_memory":{
          "name":"Replay",
          "batch_size":1,
          "max_size":-1
        },
        "meta_algo_loss":{
          "reduction":"none",
          "name":"CrossEntropyLoss"
        },
        "contained_algorithms":[
          {
            "name":"DoubleDQN",
            "algorithm":{
              "name":"DoubleDQN",
              "action_pdtype":"Categorical",
              "action_policy":"boltzmann_on_cluster",
              "explore_var_spec":{
                "name":"linear_decay",
                "start_val":1.0,
                "end_val":0.1,
                "start_step":0,
                "end_step":3000
              },
              "gamma":0.5,
              "normalize_inputs":true,
              "training_batch_iter":1,
              "training_iter":4,
              "training_frequency":60,
              "training_start_step":60
            },
            "memory":{
              "name":"Replay",
              "batch_size":60,
              "max_size":4000,
              "use_cer":true
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "clip_grad_val":1.0,
              "optim_spec":{
                "name":"SGD",
                "lr":0.04,
                "momentum":0.9
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }

          },
          {
            "copy_n":0
          },
          {
            "copy_n":0
          },
          {
            "name":"SupervisedLAPolicy",
            "algorithm":{
              "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
               "entropy_coef_spec":{
                    "name":"linear_decay",
                    "start_val":0.0,
                    "end_val":0.0,
                    "start_step":0,
                    "end_step":500
               },
              "training_frequency":1,
              "normalize_inputs":true,
              "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "loss_spec":{
                "name":"CrossEntropyLoss",
                "reduction":"none"
              },
              "optim_spec":{
                "name":"SGD",
                "lr":0.40,
                "momentum":0.000
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }
          }
        ]

      }
    },
    {
      "name":"LE",
      "memory":null,
      "net":null,
      "welfare_function":"utilitarian_welfare",
      "observing_other_agents":{
        "name":"FullyObservable"
      },
      "algorithm":{
        "name":"LE",
        "punishement_time":1,
        "min_coop_time":0,
        "defection_detection_mode":"spl_observed_actions",
        "defection_carac_threshold":0.0,
        "average_d_carac":true,
        "average_d_carac_len":20,
        "same_init_weights":true,
        "coop_net_ent_diff_as_lr":false,
        "use_sl_for_simu_coop":false,
        "use_strat_4":false,
        "use_strat_5":false,
        "strat_5_coeff":10.0,
        "use_strat_2":true,
        "block_len":4,
        "use_last_steps_for_search":true,
        "use_bolzmann_search":true,
        "PERCENTILE_FOR_LIKELIHOOD_TEST":75,
        "meta_algo_memory":{
          "name":"Replay",
          "batch_size":1,
          "max_size":-1
        },
        "meta_algo_loss":{
          "reduction":"none",
          "name":"CrossEntropyLoss"
        },
        "contained_algorithms":[
          {
            "name":"DoubleDQN",
            "algorithm":{
              "name":"DoubleDQN",
              "action_pdtype":"Categorical",
              "action_policy":"boltzmann_on_cluster",
              "explore_var_spec":{
                "name":"linear_decay",
                "start_val":1.0,
                "end_val":0.1,
                "start_step":0,
                "end_step":3000
              },
              "gamma":0.5,
              "normalize_inputs":true,
              "training_batch_iter":1,
              "training_iter":4,
              "training_frequency":60,
              "training_start_step":60
            },
            "memory":{
              "name":"Replay",
              "batch_size":60,
              "max_size":4000,
              "use_cer":true
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "clip_grad_val":1.0,
              "optim_spec":{
                "name":"SGD",
                "lr":0.04,
                "momentum":0.9
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }

          },
          {
            "copy_n":0
          },
          {
            "copy_n":0
          },
          {
            "name":"SupervisedLAPolicy",
            "algorithm":{
              "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
               "entropy_coef_spec":{
                    "name":"linear_decay",
                    "start_val":0.0,
                    "end_val":0.0,
                    "start_step":0,
                    "end_step":500
               },
              "training_frequency":1,
              "normalize_inputs":true,
              "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "loss_spec":{
                "name":"CrossEntropyLoss",
                "reduction":"none"
              },
              "optim_spec":{
                "name":"SGD",
                "lr":0.40,
                "momentum":0.000
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }
          }
        ]

      }
    }
    ],
    "env":[{
      "name":"IteratedPrisonersDilemma-v0",
      "max_t":null,
      "max_frame":4000,
      "num_envs":1
    }],
    "body":{
      "product":"outer",
      "num":1
    },
    "meta":{
      "distributed":false,
      "eval_frequency":20,
      "log_frequency":20,
      "max_session":10,
      "max_concurrent_session":10,
      "max_trial":1
    }
  },
  "ipd_ipm_le_self_play_strat_2_temp_1_0.85_0.65":{
    "world":{"name":"DefaultMultiAgentWorld",
             "deterministic":false},
    "agent":[{
      "name":"LE",
      "memory":null,
      "net":null,
      "welfare_function":"utilitarian_welfare",
      "observing_other_agents":{
        "name":"FullyObservable"
      },
      "algorithm":{
        "name":"LE",
        "punishement_time":1,
        "min_coop_time":0,
        "defection_detection_mode":"spl_observed_actions",
        "defection_carac_threshold":0.0,
        "average_d_carac":true,
        "average_d_carac_len":20,
        "same_init_weights":true,
        "coop_net_ent_diff_as_lr":false,
        "use_sl_for_simu_coop":false,
        "use_strat_4":false,
        "use_strat_5":false,
        "strat_5_coeff":10.0,
        "use_strat_2":true,
        "block_len":4,
        "use_last_steps_for_search":true,
        "use_bolzmann_search":true,
        "PERCENTILE_FOR_LIKELIHOOD_TEST":85,
        "meta_algo_memory":{
          "name":"Replay",
          "batch_size":1,
          "max_size":-1
        },
        "meta_algo_loss":{
          "reduction":"none",
          "name":"CrossEntropyLoss"
        },
        "contained_algorithms":[
          {
            "name":"DoubleDQN",
            "algorithm":{
              "name":"DoubleDQN",
              "action_pdtype":"Categorical",
              "action_policy":"boltzmann_on_cluster",
              "explore_var_spec":{
                "name":"linear_decay",
                "start_val":1.0,
                "end_val":0.1,
                "start_step":0,
                "end_step":3000
              },
              "gamma":0.5,
              "normalize_inputs":true,
              "training_batch_iter":1,
              "training_iter":4,
              "training_frequency":60,
              "training_start_step":60
            },
            "memory":{
              "name":"Replay",
              "batch_size":60,
              "max_size":4000,
              "use_cer":true
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "clip_grad_val":1.0,
              "optim_spec":{
                "name":"SGD",
                "lr":0.04,
                "momentum":0.9
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }

          },
          {
            "copy_n":0
          },
          {
            "copy_n":0
          },
          {
            "name":"SupervisedLAPolicy",
            "algorithm":{
              "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
               "entropy_coef_spec":{
                    "name":"linear_decay",
                    "start_val":0.0,
                    "end_val":0.0,
                    "start_step":0,
                    "end_step":500
               },
              "training_frequency":1,
              "normalize_inputs":true,
              "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "loss_spec":{
                "name":"CrossEntropyLoss",
                "reduction":"none"
              },
              "optim_spec":{
                "name":"SGD",
                "lr":0.40,
                "momentum":0.000
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }
          }
        ]

      }
    },
    {
      "name":"LE",
      "memory":null,
      "net":null,
      "welfare_function":"utilitarian_welfare",
      "observing_other_agents":{
        "name":"FullyObservable"
      },
      "algorithm":{
        "name":"LE",
        "punishement_time":1,
        "min_coop_time":0,
        "defection_detection_mode":"spl_observed_actions",
        "defection_carac_threshold":0.0,
        "average_d_carac":true,
        "average_d_carac_len":20,
        "same_init_weights":true,
        "coop_net_ent_diff_as_lr":false,
        "use_sl_for_simu_coop":false,
        "use_strat_4":false,
        "use_strat_5":false,
        "strat_5_coeff":10.0,
        "use_strat_2":true,
        "block_len":4,
        "use_last_steps_for_search":true,
        "use_bolzmann_search":true,
        "PERCENTILE_FOR_LIKELIHOOD_TEST":65,
        "meta_algo_memory":{
          "name":"Replay",
          "batch_size":1,
          "max_size":-1
        },
        "meta_algo_loss":{
          "reduction":"none",
          "name":"CrossEntropyLoss"
        },
        "contained_algorithms":[
          {
            "name":"DoubleDQN",
            "algorithm":{
              "name":"DoubleDQN",
              "action_pdtype":"Categorical",
              "action_policy":"boltzmann_on_cluster",
              "explore_var_spec":{
                "name":"linear_decay",
                "start_val":1.0,
                "end_val":0.1,
                "start_step":0,
                "end_step":3000
              },
              "gamma":0.5,
              "normalize_inputs":true,
              "training_batch_iter":1,
              "training_iter":4,
              "training_frequency":60,
              "training_start_step":60
            },
            "memory":{
              "name":"Replay",
              "batch_size":60,
              "max_size":4000,
              "use_cer":true
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "clip_grad_val":1.0,
              "optim_spec":{
                "name":"SGD",
                "lr":0.04,
                "momentum":0.9
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }

          },
          {
            "copy_n":0
          },
          {
            "copy_n":0
          },
          {
            "name":"SupervisedLAPolicy",
            "algorithm":{
              "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
               "entropy_coef_spec":{
                    "name":"linear_decay",
                    "start_val":0.0,
                    "end_val":0.0,
                    "start_step":0,
                    "end_step":500
               },
              "training_frequency":1,
              "normalize_inputs":true,
              "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "loss_spec":{
                "name":"CrossEntropyLoss",
                "reduction":"none"
              },
              "optim_spec":{
                "name":"SGD",
                "lr":0.40,
                "momentum":0.000
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }
          }
        ]

      }
    }
    ],
    "env":[{
      "name":"IteratedPrisonersDilemma-v0",
      "max_t":null,
      "max_frame":4000,
      "num_envs":1
    }],
    "body":{
      "product":"outer",
      "num":1
    },
    "meta":{
      "distributed":false,
      "eval_frequency":20,
      "log_frequency":20,
      "max_session":10,
      "max_concurrent_session":10,
      "max_trial":1
    }
  },
  "ipd_ipm_le_self_play_strat_2_temp_1_0.85_0.55":{
    "world":{"name":"DefaultMultiAgentWorld",
             "deterministic":false},
    "agent":[{
      "name":"LE",
      "memory":null,
      "net":null,
      "welfare_function":"utilitarian_welfare",
      "observing_other_agents":{
        "name":"FullyObservable"
      },
      "algorithm":{
        "name":"LE",
        "punishement_time":1,
        "min_coop_time":0,
        "defection_detection_mode":"spl_observed_actions",
        "defection_carac_threshold":0.0,
        "average_d_carac":true,
        "average_d_carac_len":20,
        "same_init_weights":true,
        "coop_net_ent_diff_as_lr":false,
        "use_sl_for_simu_coop":false,
        "use_strat_4":false,
        "use_strat_5":false,
        "strat_5_coeff":10.0,
        "use_strat_2":true,
        "block_len":4,
        "use_last_steps_for_search":true,
        "use_bolzmann_search":true,
        "PERCENTILE_FOR_LIKELIHOOD_TEST":85,
        "meta_algo_memory":{
          "name":"Replay",
          "batch_size":1,
          "max_size":-1
        },
        "meta_algo_loss":{
          "reduction":"none",
          "name":"CrossEntropyLoss"
        },
        "contained_algorithms":[
          {
            "name":"DoubleDQN",
            "algorithm":{
              "name":"DoubleDQN",
              "action_pdtype":"Categorical",
              "action_policy":"boltzmann_on_cluster",
              "explore_var_spec":{
                "name":"linear_decay",
                "start_val":1.0,
                "end_val":0.1,
                "start_step":0,
                "end_step":3000
              },
              "gamma":0.5,
              "normalize_inputs":true,
              "training_batch_iter":1,
              "training_iter":4,
              "training_frequency":60,
              "training_start_step":60
            },
            "memory":{
              "name":"Replay",
              "batch_size":60,
              "max_size":4000,
              "use_cer":true
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "clip_grad_val":1.0,
              "optim_spec":{
                "name":"SGD",
                "lr":0.04,
                "momentum":0.9
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }

          },
          {
            "copy_n":0
          },
          {
            "copy_n":0
          },
          {
            "name":"SupervisedLAPolicy",
            "algorithm":{
              "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
               "entropy_coef_spec":{
                    "name":"linear_decay",
                    "start_val":0.0,
                    "end_val":0.0,
                    "start_step":0,
                    "end_step":500
               },
              "training_frequency":1,
              "normalize_inputs":true,
              "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "loss_spec":{
                "name":"CrossEntropyLoss",
                "reduction":"none"
              },
              "optim_spec":{
                "name":"SGD",
                "lr":0.40,
                "momentum":0.000
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }
          }
        ]

      }
    },
    {
      "name":"LE",
      "memory":null,
      "net":null,
      "welfare_function":"utilitarian_welfare",
      "observing_other_agents":{
        "name":"FullyObservable"
      },
      "algorithm":{
        "name":"LE",
        "punishement_time":1,
        "min_coop_time":0,
        "defection_detection_mode":"spl_observed_actions",
        "defection_carac_threshold":0.0,
        "average_d_carac":true,
        "average_d_carac_len":20,
        "same_init_weights":true,
        "coop_net_ent_diff_as_lr":false,
        "use_sl_for_simu_coop":false,
        "use_strat_4":false,
        "use_strat_5":false,
        "strat_5_coeff":10.0,
        "use_strat_2":true,
        "block_len":4,
        "use_last_steps_for_search":true,
        "use_bolzmann_search":true,
        "PERCENTILE_FOR_LIKELIHOOD_TEST":55,
        "meta_algo_memory":{
          "name":"Replay",
          "batch_size":1,
          "max_size":-1
        },
        "meta_algo_loss":{
          "reduction":"none",
          "name":"CrossEntropyLoss"
        },
        "contained_algorithms":[
          {
            "name":"DoubleDQN",
            "algorithm":{
              "name":"DoubleDQN",
              "action_pdtype":"Categorical",
              "action_policy":"boltzmann_on_cluster",
              "explore_var_spec":{
                "name":"linear_decay",
                "start_val":1.0,
                "end_val":0.1,
                "start_step":0,
                "end_step":3000
              },
              "gamma":0.5,
              "normalize_inputs":true,
              "training_batch_iter":1,
              "training_iter":4,
              "training_frequency":60,
              "training_start_step":60
            },
            "memory":{
              "name":"Replay",
              "batch_size":60,
              "max_size":4000,
              "use_cer":true
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "clip_grad_val":1.0,
              "optim_spec":{
                "name":"SGD",
                "lr":0.04,
                "momentum":0.9
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }

          },
          {
            "copy_n":0
          },
          {
            "copy_n":0
          },
          {
            "name":"SupervisedLAPolicy",
            "algorithm":{
              "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
               "entropy_coef_spec":{
                    "name":"linear_decay",
                    "start_val":0.0,
                    "end_val":0.0,
                    "start_step":0,
                    "end_step":500
               },
              "training_frequency":1,
              "normalize_inputs":true,
              "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "loss_spec":{
                "name":"CrossEntropyLoss",
                "reduction":"none"
              },
              "optim_spec":{
                "name":"SGD",
                "lr":0.40,
                "momentum":0.000
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }
          }
        ]

      }
    }
    ],
    "env":[{
      "name":"IteratedPrisonersDilemma-v0",
      "max_t":null,
      "max_frame":4000,
      "num_envs":1
    }],
    "body":{
      "product":"outer",
      "num":1
    },
    "meta":{
      "distributed":false,
      "eval_frequency":20,
      "log_frequency":20,
      "max_session":10,
      "max_concurrent_session":10,
      "max_trial":1
    }
  },

  "ipd_ipm_le_self_play_strat_2_temp_1_0.75_0.95":{
    "world":{"name":"DefaultMultiAgentWorld",
             "deterministic":false},
    "agent":[{
      "name":"LE",
      "memory":null,
      "net":null,
      "welfare_function":"utilitarian_welfare",
      "observing_other_agents":{
        "name":"FullyObservable"
      },
      "algorithm":{
        "name":"LE",
        "punishement_time":1,
        "min_coop_time":0,
        "defection_detection_mode":"spl_observed_actions",
        "defection_carac_threshold":0.0,
        "average_d_carac":true,
        "average_d_carac_len":20,
        "same_init_weights":true,
        "coop_net_ent_diff_as_lr":false,
        "use_sl_for_simu_coop":false,
        "use_strat_4":false,
        "use_strat_5":false,
        "strat_5_coeff":10.0,
        "use_strat_2":true,
        "block_len":4,
        "use_last_steps_for_search":true,
        "use_bolzmann_search":true,
        "PERCENTILE_FOR_LIKELIHOOD_TEST":75,
        "meta_algo_memory":{
          "name":"Replay",
          "batch_size":1,
          "max_size":-1
        },
        "meta_algo_loss":{
          "reduction":"none",
          "name":"CrossEntropyLoss"
        },
        "contained_algorithms":[
          {
            "name":"DoubleDQN",
            "algorithm":{
              "name":"DoubleDQN",
              "action_pdtype":"Categorical",
              "action_policy":"boltzmann_on_cluster",
              "explore_var_spec":{
                "name":"linear_decay",
                "start_val":1.0,
                "end_val":0.1,
                "start_step":0,
                "end_step":3000
              },
              "gamma":0.5,
              "normalize_inputs":true,
              "training_batch_iter":1,
              "training_iter":4,
              "training_frequency":60,
              "training_start_step":60
            },
            "memory":{
              "name":"Replay",
              "batch_size":60,
              "max_size":4000,
              "use_cer":true
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "clip_grad_val":1.0,
              "optim_spec":{
                "name":"SGD",
                "lr":0.04,
                "momentum":0.9
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }

          },
          {
            "copy_n":0
          },
          {
            "copy_n":0
          },
          {
            "name":"SupervisedLAPolicy",
            "algorithm":{
              "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
               "entropy_coef_spec":{
                    "name":"linear_decay",
                    "start_val":0.0,
                    "end_val":0.0,
                    "start_step":0,
                    "end_step":500
               },
              "training_frequency":1,
              "normalize_inputs":true,
              "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "loss_spec":{
                "name":"CrossEntropyLoss",
                "reduction":"none"
              },
              "optim_spec":{
                "name":"SGD",
                "lr":0.40,
                "momentum":0.000
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }
          }
        ]

      }
    },
    {
      "name":"LE",
      "memory":null,
      "net":null,
      "welfare_function":"utilitarian_welfare",
      "observing_other_agents":{
        "name":"FullyObservable"
      },
      "algorithm":{
        "name":"LE",
        "punishement_time":1,
        "min_coop_time":0,
        "defection_detection_mode":"spl_observed_actions",
        "defection_carac_threshold":0.0,
        "average_d_carac":true,
        "average_d_carac_len":20,
        "same_init_weights":true,
        "coop_net_ent_diff_as_lr":false,
        "use_sl_for_simu_coop":false,
        "use_strat_4":false,
        "use_strat_5":false,
        "strat_5_coeff":10.0,
        "use_strat_2":true,
        "block_len":4,
        "use_last_steps_for_search":true,
        "use_bolzmann_search":true,
        "PERCENTILE_FOR_LIKELIHOOD_TEST":95,
        "meta_algo_memory":{
          "name":"Replay",
          "batch_size":1,
          "max_size":-1
        },
        "meta_algo_loss":{
          "reduction":"none",
          "name":"CrossEntropyLoss"
        },
        "contained_algorithms":[
          {
            "name":"DoubleDQN",
            "algorithm":{
              "name":"DoubleDQN",
              "action_pdtype":"Categorical",
              "action_policy":"boltzmann_on_cluster",
              "explore_var_spec":{
                "name":"linear_decay",
                "start_val":1.0,
                "end_val":0.1,
                "start_step":0,
                "end_step":3000
              },
              "gamma":0.5,
              "normalize_inputs":true,
              "training_batch_iter":1,
              "training_iter":4,
              "training_frequency":60,
              "training_start_step":60
            },
            "memory":{
              "name":"Replay",
              "batch_size":60,
              "max_size":4000,
              "use_cer":true
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "clip_grad_val":1.0,
              "optim_spec":{
                "name":"SGD",
                "lr":0.04,
                "momentum":0.9
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }

          },
          {
            "copy_n":0
          },
          {
            "copy_n":0
          },
          {
            "name":"SupervisedLAPolicy",
            "algorithm":{
              "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
               "entropy_coef_spec":{
                    "name":"linear_decay",
                    "start_val":0.0,
                    "end_val":0.0,
                    "start_step":0,
                    "end_step":500
               },
              "training_frequency":1,
              "normalize_inputs":true,
              "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "loss_spec":{
                "name":"CrossEntropyLoss",
                "reduction":"none"
              },
              "optim_spec":{
                "name":"SGD",
                "lr":0.40,
                "momentum":0.000
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }
          }
        ]

      }
    }
    ],
    "env":[{
      "name":"IteratedPrisonersDilemma-v0",
      "max_t":null,
      "max_frame":4000,
      "num_envs":1
    }],
    "body":{
      "product":"outer",
      "num":1
    },
    "meta":{
      "distributed":false,
      "eval_frequency":20,
      "log_frequency":20,
      "max_session":10,
      "max_concurrent_session":10,
      "max_trial":1
    }
  },
  "ipd_ipm_le_self_play_strat_2_temp_1_0.75_0.85":{
    "world":{"name":"DefaultMultiAgentWorld",
             "deterministic":false},
    "agent":[{
      "name":"LE",
      "memory":null,
      "net":null,
      "welfare_function":"utilitarian_welfare",
      "observing_other_agents":{
        "name":"FullyObservable"
      },
      "algorithm":{
        "name":"LE",
        "punishement_time":1,
        "min_coop_time":0,
        "defection_detection_mode":"spl_observed_actions",
        "defection_carac_threshold":0.0,
        "average_d_carac":true,
        "average_d_carac_len":20,
        "same_init_weights":true,
        "coop_net_ent_diff_as_lr":false,
        "use_sl_for_simu_coop":false,
        "use_strat_4":false,
        "use_strat_5":false,
        "strat_5_coeff":10.0,
        "use_strat_2":true,
        "block_len":4,
        "use_last_steps_for_search":true,
        "use_bolzmann_search":true,
        "PERCENTILE_FOR_LIKELIHOOD_TEST":75,
        "meta_algo_memory":{
          "name":"Replay",
          "batch_size":1,
          "max_size":-1
        },
        "meta_algo_loss":{
          "reduction":"none",
          "name":"CrossEntropyLoss"
        },
        "contained_algorithms":[
          {
            "name":"DoubleDQN",
            "algorithm":{
              "name":"DoubleDQN",
              "action_pdtype":"Categorical",
              "action_policy":"boltzmann_on_cluster",
              "explore_var_spec":{
                "name":"linear_decay",
                "start_val":1.0,
                "end_val":0.1,
                "start_step":0,
                "end_step":3000
              },
              "gamma":0.5,
              "normalize_inputs":true,
              "training_batch_iter":1,
              "training_iter":4,
              "training_frequency":60,
              "training_start_step":60
            },
            "memory":{
              "name":"Replay",
              "batch_size":60,
              "max_size":4000,
              "use_cer":true
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "clip_grad_val":1.0,
              "optim_spec":{
                "name":"SGD",
                "lr":0.04,
                "momentum":0.9
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }

          },
          {
            "copy_n":0
          },
          {
            "copy_n":0
          },
          {
            "name":"SupervisedLAPolicy",
            "algorithm":{
              "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
               "entropy_coef_spec":{
                    "name":"linear_decay",
                    "start_val":0.0,
                    "end_val":0.0,
                    "start_step":0,
                    "end_step":500
               },
              "training_frequency":1,
              "normalize_inputs":true,
              "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "loss_spec":{
                "name":"CrossEntropyLoss",
                "reduction":"none"
              },
              "optim_spec":{
                "name":"SGD",
                "lr":0.40,
                "momentum":0.000
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }
          }
        ]

      }
    },
    {
      "name":"LE",
      "memory":null,
      "net":null,
      "welfare_function":"utilitarian_welfare",
      "observing_other_agents":{
        "name":"FullyObservable"
      },
      "algorithm":{
        "name":"LE",
        "punishement_time":1,
        "min_coop_time":0,
        "defection_detection_mode":"spl_observed_actions",
        "defection_carac_threshold":0.0,
        "average_d_carac":true,
        "average_d_carac_len":20,
        "same_init_weights":true,
        "coop_net_ent_diff_as_lr":false,
        "use_sl_for_simu_coop":false,
        "use_strat_4":false,
        "use_strat_5":false,
        "strat_5_coeff":10.0,
        "use_strat_2":true,
        "block_len":4,
        "use_last_steps_for_search":true,
        "use_bolzmann_search":true,
        "PERCENTILE_FOR_LIKELIHOOD_TEST":85,
        "meta_algo_memory":{
          "name":"Replay",
          "batch_size":1,
          "max_size":-1
        },
        "meta_algo_loss":{
          "reduction":"none",
          "name":"CrossEntropyLoss"
        },
        "contained_algorithms":[
          {
            "name":"DoubleDQN",
            "algorithm":{
              "name":"DoubleDQN",
              "action_pdtype":"Categorical",
              "action_policy":"boltzmann_on_cluster",
              "explore_var_spec":{
                "name":"linear_decay",
                "start_val":1.0,
                "end_val":0.1,
                "start_step":0,
                "end_step":3000
              },
              "gamma":0.5,
              "normalize_inputs":true,
              "training_batch_iter":1,
              "training_iter":4,
              "training_frequency":60,
              "training_start_step":60
            },
            "memory":{
              "name":"Replay",
              "batch_size":60,
              "max_size":4000,
              "use_cer":true
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "clip_grad_val":1.0,
              "optim_spec":{
                "name":"SGD",
                "lr":0.04,
                "momentum":0.9
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }

          },
          {
            "copy_n":0
          },
          {
            "copy_n":0
          },
          {
            "name":"SupervisedLAPolicy",
            "algorithm":{
              "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
               "entropy_coef_spec":{
                    "name":"linear_decay",
                    "start_val":0.0,
                    "end_val":0.0,
                    "start_step":0,
                    "end_step":500
               },
              "training_frequency":1,
              "normalize_inputs":true,
              "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "loss_spec":{
                "name":"CrossEntropyLoss",
                "reduction":"none"
              },
              "optim_spec":{
                "name":"SGD",
                "lr":0.40,
                "momentum":0.000
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }
          }
        ]

      }
    }
    ],
    "env":[{
      "name":"IteratedPrisonersDilemma-v0",
      "max_t":null,
      "max_frame":4000,
      "num_envs":1
    }],
    "body":{
      "product":"outer",
      "num":1
    },
    "meta":{
      "distributed":false,
      "eval_frequency":20,
      "log_frequency":20,
      "max_session":10,
      "max_concurrent_session":10,
      "max_trial":1
    }
  },
  "ipd_ipm_le_self_play_strat_2_temp_1_0.75_0.75":{
    "world":{"name":"DefaultMultiAgentWorld",
             "deterministic":false},
    "agent":[{
      "name":"LE",
      "memory":null,
      "net":null,
      "welfare_function":"utilitarian_welfare",
      "observing_other_agents":{
        "name":"FullyObservable"
      },
      "algorithm":{
        "name":"LE",
        "punishement_time":1,
        "min_coop_time":0,
        "defection_detection_mode":"spl_observed_actions",
        "defection_carac_threshold":0.0,
        "average_d_carac":true,
        "average_d_carac_len":20,
        "same_init_weights":true,
        "coop_net_ent_diff_as_lr":false,
        "use_sl_for_simu_coop":false,
        "use_strat_4":false,
        "use_strat_5":false,
        "strat_5_coeff":10.0,
        "use_strat_2":true,
        "block_len":4,
        "use_last_steps_for_search":true,
        "use_bolzmann_search":true,
        "PERCENTILE_FOR_LIKELIHOOD_TEST":75,
        "meta_algo_memory":{
          "name":"Replay",
          "batch_size":1,
          "max_size":-1
        },
        "meta_algo_loss":{
          "reduction":"none",
          "name":"CrossEntropyLoss"
        },
        "contained_algorithms":[
          {
            "name":"DoubleDQN",
            "algorithm":{
              "name":"DoubleDQN",
              "action_pdtype":"Categorical",
              "action_policy":"boltzmann_on_cluster",
              "explore_var_spec":{
                "name":"linear_decay",
                "start_val":1.0,
                "end_val":0.1,
                "start_step":0,
                "end_step":3000
              },
              "gamma":0.5,
              "normalize_inputs":true,
              "training_batch_iter":1,
              "training_iter":4,
              "training_frequency":60,
              "training_start_step":60
            },
            "memory":{
              "name":"Replay",
              "batch_size":60,
              "max_size":4000,
              "use_cer":true
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "clip_grad_val":1.0,
              "optim_spec":{
                "name":"SGD",
                "lr":0.04,
                "momentum":0.9
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }

          },
          {
            "copy_n":0
          },
          {
            "copy_n":0
          },
          {
            "name":"SupervisedLAPolicy",
            "algorithm":{
              "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
               "entropy_coef_spec":{
                    "name":"linear_decay",
                    "start_val":0.0,
                    "end_val":0.0,
                    "start_step":0,
                    "end_step":500
               },
              "training_frequency":1,
              "normalize_inputs":true,
              "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "loss_spec":{
                "name":"CrossEntropyLoss",
                "reduction":"none"
              },
              "optim_spec":{
                "name":"SGD",
                "lr":0.40,
                "momentum":0.000
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }
          }
        ]

      }
    },
    {
      "name":"LE",
      "memory":null,
      "net":null,
      "welfare_function":"utilitarian_welfare",
      "observing_other_agents":{
        "name":"FullyObservable"
      },
      "algorithm":{
        "name":"LE",
        "punishement_time":1,
        "min_coop_time":0,
        "defection_detection_mode":"spl_observed_actions",
        "defection_carac_threshold":0.0,
        "average_d_carac":true,
        "average_d_carac_len":20,
        "same_init_weights":true,
        "coop_net_ent_diff_as_lr":false,
        "use_sl_for_simu_coop":false,
        "use_strat_4":false,
        "use_strat_5":false,
        "strat_5_coeff":10.0,
        "use_strat_2":true,
        "block_len":4,
        "use_last_steps_for_search":true,
        "use_bolzmann_search":true,
        "PERCENTILE_FOR_LIKELIHOOD_TEST":75,
        "meta_algo_memory":{
          "name":"Replay",
          "batch_size":1,
          "max_size":-1
        },
        "meta_algo_loss":{
          "reduction":"none",
          "name":"CrossEntropyLoss"
        },
        "contained_algorithms":[
          {
            "name":"DoubleDQN",
            "algorithm":{
              "name":"DoubleDQN",
              "action_pdtype":"Categorical",
              "action_policy":"boltzmann_on_cluster",
              "explore_var_spec":{
                "name":"linear_decay",
                "start_val":1.0,
                "end_val":0.1,
                "start_step":0,
                "end_step":3000
              },
              "gamma":0.5,
              "normalize_inputs":true,
              "training_batch_iter":1,
              "training_iter":4,
              "training_frequency":60,
              "training_start_step":60
            },
            "memory":{
              "name":"Replay",
              "batch_size":60,
              "max_size":4000,
              "use_cer":true
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "clip_grad_val":1.0,
              "optim_spec":{
                "name":"SGD",
                "lr":0.04,
                "momentum":0.9
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }

          },
          {
            "copy_n":0
          },
          {
            "copy_n":0
          },
          {
            "name":"SupervisedLAPolicy",
            "algorithm":{
              "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
               "entropy_coef_spec":{
                    "name":"linear_decay",
                    "start_val":0.0,
                    "end_val":0.0,
                    "start_step":0,
                    "end_step":500
               },
              "training_frequency":1,
              "normalize_inputs":true,
              "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "loss_spec":{
                "name":"CrossEntropyLoss",
                "reduction":"none"
              },
              "optim_spec":{
                "name":"SGD",
                "lr":0.40,
                "momentum":0.000
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }
          }
        ]

      }
    }
    ],
    "env":[{
      "name":"IteratedPrisonersDilemma-v0",
      "max_t":null,
      "max_frame":4000,
      "num_envs":1
    }],
    "body":{
      "product":"outer",
      "num":1
    },
    "meta":{
      "distributed":false,
      "eval_frequency":20,
      "log_frequency":20,
      "max_session":10,
      "max_concurrent_session":10,
      "max_trial":1
    }
  },
  "ipd_ipm_le_self_play_strat_2_temp_1_0.75_0.65":{
    "world":{"name":"DefaultMultiAgentWorld",
             "deterministic":false},
    "agent":[{
      "name":"LE",
      "memory":null,
      "net":null,
      "welfare_function":"utilitarian_welfare",
      "observing_other_agents":{
        "name":"FullyObservable"
      },
      "algorithm":{
        "name":"LE",
        "punishement_time":1,
        "min_coop_time":0,
        "defection_detection_mode":"spl_observed_actions",
        "defection_carac_threshold":0.0,
        "average_d_carac":true,
        "average_d_carac_len":20,
        "same_init_weights":true,
        "coop_net_ent_diff_as_lr":false,
        "use_sl_for_simu_coop":false,
        "use_strat_4":false,
        "use_strat_5":false,
        "strat_5_coeff":10.0,
        "use_strat_2":true,
        "block_len":4,
        "use_last_steps_for_search":true,
        "use_bolzmann_search":true,
        "PERCENTILE_FOR_LIKELIHOOD_TEST":75,
        "meta_algo_memory":{
          "name":"Replay",
          "batch_size":1,
          "max_size":-1
        },
        "meta_algo_loss":{
          "reduction":"none",
          "name":"CrossEntropyLoss"
        },
        "contained_algorithms":[
          {
            "name":"DoubleDQN",
            "algorithm":{
              "name":"DoubleDQN",
              "action_pdtype":"Categorical",
              "action_policy":"boltzmann_on_cluster",
              "explore_var_spec":{
                "name":"linear_decay",
                "start_val":1.0,
                "end_val":0.1,
                "start_step":0,
                "end_step":3000
              },
              "gamma":0.5,
              "normalize_inputs":true,
              "training_batch_iter":1,
              "training_iter":4,
              "training_frequency":60,
              "training_start_step":60
            },
            "memory":{
              "name":"Replay",
              "batch_size":60,
              "max_size":4000,
              "use_cer":true
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "clip_grad_val":1.0,
              "optim_spec":{
                "name":"SGD",
                "lr":0.04,
                "momentum":0.9
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }

          },
          {
            "copy_n":0
          },
          {
            "copy_n":0
          },
          {
            "name":"SupervisedLAPolicy",
            "algorithm":{
              "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
               "entropy_coef_spec":{
                    "name":"linear_decay",
                    "start_val":0.0,
                    "end_val":0.0,
                    "start_step":0,
                    "end_step":500
               },
              "training_frequency":1,
              "normalize_inputs":true,
              "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "loss_spec":{
                "name":"CrossEntropyLoss",
                "reduction":"none"
              },
              "optim_spec":{
                "name":"SGD",
                "lr":0.40,
                "momentum":0.000
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }
          }
        ]

      }
    },
    {
      "name":"LE",
      "memory":null,
      "net":null,
      "welfare_function":"utilitarian_welfare",
      "observing_other_agents":{
        "name":"FullyObservable"
      },
      "algorithm":{
        "name":"LE",
        "punishement_time":1,
        "min_coop_time":0,
        "defection_detection_mode":"spl_observed_actions",
        "defection_carac_threshold":0.0,
        "average_d_carac":true,
        "average_d_carac_len":20,
        "same_init_weights":true,
        "coop_net_ent_diff_as_lr":false,
        "use_sl_for_simu_coop":false,
        "use_strat_4":false,
        "use_strat_5":false,
        "strat_5_coeff":10.0,
        "use_strat_2":true,
        "block_len":4,
        "use_last_steps_for_search":true,
        "use_bolzmann_search":true,
        "PERCENTILE_FOR_LIKELIHOOD_TEST":65,
        "meta_algo_memory":{
          "name":"Replay",
          "batch_size":1,
          "max_size":-1
        },
        "meta_algo_loss":{
          "reduction":"none",
          "name":"CrossEntropyLoss"
        },
        "contained_algorithms":[
          {
            "name":"DoubleDQN",
            "algorithm":{
              "name":"DoubleDQN",
              "action_pdtype":"Categorical",
              "action_policy":"boltzmann_on_cluster",
              "explore_var_spec":{
                "name":"linear_decay",
                "start_val":1.0,
                "end_val":0.1,
                "start_step":0,
                "end_step":3000
              },
              "gamma":0.5,
              "normalize_inputs":true,
              "training_batch_iter":1,
              "training_iter":4,
              "training_frequency":60,
              "training_start_step":60
            },
            "memory":{
              "name":"Replay",
              "batch_size":60,
              "max_size":4000,
              "use_cer":true
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "clip_grad_val":1.0,
              "optim_spec":{
                "name":"SGD",
                "lr":0.04,
                "momentum":0.9
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }

          },
          {
            "copy_n":0
          },
          {
            "copy_n":0
          },
          {
            "name":"SupervisedLAPolicy",
            "algorithm":{
              "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
               "entropy_coef_spec":{
                    "name":"linear_decay",
                    "start_val":0.0,
                    "end_val":0.0,
                    "start_step":0,
                    "end_step":500
               },
              "training_frequency":1,
              "normalize_inputs":true,
              "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "loss_spec":{
                "name":"CrossEntropyLoss",
                "reduction":"none"
              },
              "optim_spec":{
                "name":"SGD",
                "lr":0.40,
                "momentum":0.000
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }
          }
        ]

      }
    }
    ],
    "env":[{
      "name":"IteratedPrisonersDilemma-v0",
      "max_t":null,
      "max_frame":4000,
      "num_envs":1
    }],
    "body":{
      "product":"outer",
      "num":1
    },
    "meta":{
      "distributed":false,
      "eval_frequency":20,
      "log_frequency":20,
      "max_session":10,
      "max_concurrent_session":10,
      "max_trial":1
    }
  },
  "ipd_ipm_le_self_play_strat_2_temp_1_0.75_0.55":{
    "world":{"name":"DefaultMultiAgentWorld",
             "deterministic":false},
    "agent":[{
      "name":"LE",
      "memory":null,
      "net":null,
      "welfare_function":"utilitarian_welfare",
      "observing_other_agents":{
        "name":"FullyObservable"
      },
      "algorithm":{
        "name":"LE",
        "punishement_time":1,
        "min_coop_time":0,
        "defection_detection_mode":"spl_observed_actions",
        "defection_carac_threshold":0.0,
        "average_d_carac":true,
        "average_d_carac_len":20,
        "same_init_weights":true,
        "coop_net_ent_diff_as_lr":false,
        "use_sl_for_simu_coop":false,
        "use_strat_4":false,
        "use_strat_5":false,
        "strat_5_coeff":10.0,
        "use_strat_2":true,
        "block_len":4,
        "use_last_steps_for_search":true,
        "use_bolzmann_search":true,
        "PERCENTILE_FOR_LIKELIHOOD_TEST":75,
        "meta_algo_memory":{
          "name":"Replay",
          "batch_size":1,
          "max_size":-1
        },
        "meta_algo_loss":{
          "reduction":"none",
          "name":"CrossEntropyLoss"
        },
        "contained_algorithms":[
          {
            "name":"DoubleDQN",
            "algorithm":{
              "name":"DoubleDQN",
              "action_pdtype":"Categorical",
              "action_policy":"boltzmann_on_cluster",
              "explore_var_spec":{
                "name":"linear_decay",
                "start_val":1.0,
                "end_val":0.1,
                "start_step":0,
                "end_step":3000
              },
              "gamma":0.5,
              "normalize_inputs":true,
              "training_batch_iter":1,
              "training_iter":4,
              "training_frequency":60,
              "training_start_step":60
            },
            "memory":{
              "name":"Replay",
              "batch_size":60,
              "max_size":4000,
              "use_cer":true
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "clip_grad_val":1.0,
              "optim_spec":{
                "name":"SGD",
                "lr":0.04,
                "momentum":0.9
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }

          },
          {
            "copy_n":0
          },
          {
            "copy_n":0
          },
          {
            "name":"SupervisedLAPolicy",
            "algorithm":{
              "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
               "entropy_coef_spec":{
                    "name":"linear_decay",
                    "start_val":0.0,
                    "end_val":0.0,
                    "start_step":0,
                    "end_step":500
               },
              "training_frequency":1,
              "normalize_inputs":true,
              "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "loss_spec":{
                "name":"CrossEntropyLoss",
                "reduction":"none"
              },
              "optim_spec":{
                "name":"SGD",
                "lr":0.40,
                "momentum":0.000
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }
          }
        ]

      }
    },
    {
      "name":"LE",
      "memory":null,
      "net":null,
      "welfare_function":"utilitarian_welfare",
      "observing_other_agents":{
        "name":"FullyObservable"
      },
      "algorithm":{
        "name":"LE",
        "punishement_time":1,
        "min_coop_time":0,
        "defection_detection_mode":"spl_observed_actions",
        "defection_carac_threshold":0.0,
        "average_d_carac":true,
        "average_d_carac_len":20,
        "same_init_weights":true,
        "coop_net_ent_diff_as_lr":false,
        "use_sl_for_simu_coop":false,
        "use_strat_4":false,
        "use_strat_5":false,
        "strat_5_coeff":10.0,
        "use_strat_2":true,
        "block_len":4,
        "use_last_steps_for_search":true,
        "use_bolzmann_search":true,
        "PERCENTILE_FOR_LIKELIHOOD_TEST":55,
        "meta_algo_memory":{
          "name":"Replay",
          "batch_size":1,
          "max_size":-1
        },
        "meta_algo_loss":{
          "reduction":"none",
          "name":"CrossEntropyLoss"
        },
        "contained_algorithms":[
          {
            "name":"DoubleDQN",
            "algorithm":{
              "name":"DoubleDQN",
              "action_pdtype":"Categorical",
              "action_policy":"boltzmann_on_cluster",
              "explore_var_spec":{
                "name":"linear_decay",
                "start_val":1.0,
                "end_val":0.1,
                "start_step":0,
                "end_step":3000
              },
              "gamma":0.5,
              "normalize_inputs":true,
              "training_batch_iter":1,
              "training_iter":4,
              "training_frequency":60,
              "training_start_step":60
            },
            "memory":{
              "name":"Replay",
              "batch_size":60,
              "max_size":4000,
              "use_cer":true
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "clip_grad_val":1.0,
              "optim_spec":{
                "name":"SGD",
                "lr":0.04,
                "momentum":0.9
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }

          },
          {
            "copy_n":0
          },
          {
            "copy_n":0
          },
          {
            "name":"SupervisedLAPolicy",
            "algorithm":{
              "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
               "entropy_coef_spec":{
                    "name":"linear_decay",
                    "start_val":0.0,
                    "end_val":0.0,
                    "start_step":0,
                    "end_step":500
               },
              "training_frequency":1,
              "normalize_inputs":true,
              "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "loss_spec":{
                "name":"CrossEntropyLoss",
                "reduction":"none"
              },
              "optim_spec":{
                "name":"SGD",
                "lr":0.40,
                "momentum":0.000
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }
          }
        ]

      }
    }
    ],
    "env":[{
      "name":"IteratedPrisonersDilemma-v0",
      "max_t":null,
      "max_frame":4000,
      "num_envs":1
    }],
    "body":{
      "product":"outer",
      "num":1
    },
    "meta":{
      "distributed":false,
      "eval_frequency":20,
      "log_frequency":20,
      "max_session":10,
      "max_concurrent_session":10,
      "max_trial":1
    }
  },

  "ipd_ipm_le_self_play_strat_2_temp_1_0.65_0.95":{
    "world":{"name":"DefaultMultiAgentWorld",
             "deterministic":false},
    "agent":[{
      "name":"LE",
      "memory":null,
      "net":null,
      "welfare_function":"utilitarian_welfare",
      "observing_other_agents":{
        "name":"FullyObservable"
      },
      "algorithm":{
        "name":"LE",
        "punishement_time":1,
        "min_coop_time":0,
        "defection_detection_mode":"spl_observed_actions",
        "defection_carac_threshold":0.0,
        "average_d_carac":true,
        "average_d_carac_len":20,
        "same_init_weights":true,
        "coop_net_ent_diff_as_lr":false,
        "use_sl_for_simu_coop":false,
        "use_strat_4":false,
        "use_strat_5":false,
        "strat_5_coeff":10.0,
        "use_strat_2":true,
        "block_len":4,
        "use_last_steps_for_search":true,
        "use_bolzmann_search":true,
        "PERCENTILE_FOR_LIKELIHOOD_TEST":65,
        "meta_algo_memory":{
          "name":"Replay",
          "batch_size":1,
          "max_size":-1
        },
        "meta_algo_loss":{
          "reduction":"none",
          "name":"CrossEntropyLoss"
        },
        "contained_algorithms":[
          {
            "name":"DoubleDQN",
            "algorithm":{
              "name":"DoubleDQN",
              "action_pdtype":"Categorical",
              "action_policy":"boltzmann_on_cluster",
              "explore_var_spec":{
                "name":"linear_decay",
                "start_val":1.0,
                "end_val":0.1,
                "start_step":0,
                "end_step":3000
              },
              "gamma":0.5,
              "normalize_inputs":true,
              "training_batch_iter":1,
              "training_iter":4,
              "training_frequency":60,
              "training_start_step":60
            },
            "memory":{
              "name":"Replay",
              "batch_size":60,
              "max_size":4000,
              "use_cer":true
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "clip_grad_val":1.0,
              "optim_spec":{
                "name":"SGD",
                "lr":0.04,
                "momentum":0.9
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }

          },
          {
            "copy_n":0
          },
          {
            "copy_n":0
          },
          {
            "name":"SupervisedLAPolicy",
            "algorithm":{
              "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
               "entropy_coef_spec":{
                    "name":"linear_decay",
                    "start_val":0.0,
                    "end_val":0.0,
                    "start_step":0,
                    "end_step":500
               },
              "training_frequency":1,
              "normalize_inputs":true,
              "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "loss_spec":{
                "name":"CrossEntropyLoss",
                "reduction":"none"
              },
              "optim_spec":{
                "name":"SGD",
                "lr":0.40,
                "momentum":0.000
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }
          }
        ]

      }
    },
    {
      "name":"LE",
      "memory":null,
      "net":null,
      "welfare_function":"utilitarian_welfare",
      "observing_other_agents":{
        "name":"FullyObservable"
      },
      "algorithm":{
        "name":"LE",
        "punishement_time":1,
        "min_coop_time":0,
        "defection_detection_mode":"spl_observed_actions",
        "defection_carac_threshold":0.0,
        "average_d_carac":true,
        "average_d_carac_len":20,
        "same_init_weights":true,
        "coop_net_ent_diff_as_lr":false,
        "use_sl_for_simu_coop":false,
        "use_strat_4":false,
        "use_strat_5":false,
        "strat_5_coeff":10.0,
        "use_strat_2":true,
        "block_len":4,
        "use_last_steps_for_search":true,
        "use_bolzmann_search":true,
        "PERCENTILE_FOR_LIKELIHOOD_TEST":95,
        "meta_algo_memory":{
          "name":"Replay",
          "batch_size":1,
          "max_size":-1
        },
        "meta_algo_loss":{
          "reduction":"none",
          "name":"CrossEntropyLoss"
        },
        "contained_algorithms":[
          {
            "name":"DoubleDQN",
            "algorithm":{
              "name":"DoubleDQN",
              "action_pdtype":"Categorical",
              "action_policy":"boltzmann_on_cluster",
              "explore_var_spec":{
                "name":"linear_decay",
                "start_val":1.0,
                "end_val":0.1,
                "start_step":0,
                "end_step":3000
              },
              "gamma":0.5,
              "normalize_inputs":true,
              "training_batch_iter":1,
              "training_iter":4,
              "training_frequency":60,
              "training_start_step":60
            },
            "memory":{
              "name":"Replay",
              "batch_size":60,
              "max_size":4000,
              "use_cer":true
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "clip_grad_val":1.0,
              "optim_spec":{
                "name":"SGD",
                "lr":0.04,
                "momentum":0.9
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }

          },
          {
            "copy_n":0
          },
          {
            "copy_n":0
          },
          {
            "name":"SupervisedLAPolicy",
            "algorithm":{
              "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
               "entropy_coef_spec":{
                    "name":"linear_decay",
                    "start_val":0.0,
                    "end_val":0.0,
                    "start_step":0,
                    "end_step":500
               },
              "training_frequency":1,
              "normalize_inputs":true,
              "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "loss_spec":{
                "name":"CrossEntropyLoss",
                "reduction":"none"
              },
              "optim_spec":{
                "name":"SGD",
                "lr":0.40,
                "momentum":0.000
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }
          }
        ]

      }
    }
    ],
    "env":[{
      "name":"IteratedPrisonersDilemma-v0",
      "max_t":null,
      "max_frame":4000,
      "num_envs":1
    }],
    "body":{
      "product":"outer",
      "num":1
    },
    "meta":{
      "distributed":false,
      "eval_frequency":20,
      "log_frequency":20,
      "max_session":10,
      "max_concurrent_session":10,
      "max_trial":1
    }
  },
  "ipd_ipm_le_self_play_strat_2_temp_1_0.65_0.85":{
    "world":{"name":"DefaultMultiAgentWorld",
             "deterministic":false},
    "agent":[{
      "name":"LE",
      "memory":null,
      "net":null,
      "welfare_function":"utilitarian_welfare",
      "observing_other_agents":{
        "name":"FullyObservable"
      },
      "algorithm":{
        "name":"LE",
        "punishement_time":1,
        "min_coop_time":0,
        "defection_detection_mode":"spl_observed_actions",
        "defection_carac_threshold":0.0,
        "average_d_carac":true,
        "average_d_carac_len":20,
        "same_init_weights":true,
        "coop_net_ent_diff_as_lr":false,
        "use_sl_for_simu_coop":false,
        "use_strat_4":false,
        "use_strat_5":false,
        "strat_5_coeff":10.0,
        "use_strat_2":true,
        "block_len":4,
        "use_last_steps_for_search":true,
        "use_bolzmann_search":true,
        "PERCENTILE_FOR_LIKELIHOOD_TEST":65,
        "meta_algo_memory":{
          "name":"Replay",
          "batch_size":1,
          "max_size":-1
        },
        "meta_algo_loss":{
          "reduction":"none",
          "name":"CrossEntropyLoss"
        },
        "contained_algorithms":[
          {
            "name":"DoubleDQN",
            "algorithm":{
              "name":"DoubleDQN",
              "action_pdtype":"Categorical",
              "action_policy":"boltzmann_on_cluster",
              "explore_var_spec":{
                "name":"linear_decay",
                "start_val":1.0,
                "end_val":0.1,
                "start_step":0,
                "end_step":3000
              },
              "gamma":0.5,
              "normalize_inputs":true,
              "training_batch_iter":1,
              "training_iter":4,
              "training_frequency":60,
              "training_start_step":60
            },
            "memory":{
              "name":"Replay",
              "batch_size":60,
              "max_size":4000,
              "use_cer":true
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "clip_grad_val":1.0,
              "optim_spec":{
                "name":"SGD",
                "lr":0.04,
                "momentum":0.9
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }

          },
          {
            "copy_n":0
          },
          {
            "copy_n":0
          },
          {
            "name":"SupervisedLAPolicy",
            "algorithm":{
              "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
               "entropy_coef_spec":{
                    "name":"linear_decay",
                    "start_val":0.0,
                    "end_val":0.0,
                    "start_step":0,
                    "end_step":500
               },
              "training_frequency":1,
              "normalize_inputs":true,
              "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "loss_spec":{
                "name":"CrossEntropyLoss",
                "reduction":"none"
              },
              "optim_spec":{
                "name":"SGD",
                "lr":0.40,
                "momentum":0.000
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }
          }
        ]

      }
    },
    {
      "name":"LE",
      "memory":null,
      "net":null,
      "welfare_function":"utilitarian_welfare",
      "observing_other_agents":{
        "name":"FullyObservable"
      },
      "algorithm":{
        "name":"LE",
        "punishement_time":1,
        "min_coop_time":0,
        "defection_detection_mode":"spl_observed_actions",
        "defection_carac_threshold":0.0,
        "average_d_carac":true,
        "average_d_carac_len":20,
        "same_init_weights":true,
        "coop_net_ent_diff_as_lr":false,
        "use_sl_for_simu_coop":false,
        "use_strat_4":false,
        "use_strat_5":false,
        "strat_5_coeff":10.0,
        "use_strat_2":true,
        "block_len":4,
        "use_last_steps_for_search":true,
        "use_bolzmann_search":true,
        "PERCENTILE_FOR_LIKELIHOOD_TEST":85,
        "meta_algo_memory":{
          "name":"Replay",
          "batch_size":1,
          "max_size":-1
        },
        "meta_algo_loss":{
          "reduction":"none",
          "name":"CrossEntropyLoss"
        },
        "contained_algorithms":[
          {
            "name":"DoubleDQN",
            "algorithm":{
              "name":"DoubleDQN",
              "action_pdtype":"Categorical",
              "action_policy":"boltzmann_on_cluster",
              "explore_var_spec":{
                "name":"linear_decay",
                "start_val":1.0,
                "end_val":0.1,
                "start_step":0,
                "end_step":3000
              },
              "gamma":0.5,
              "normalize_inputs":true,
              "training_batch_iter":1,
              "training_iter":4,
              "training_frequency":60,
              "training_start_step":60
            },
            "memory":{
              "name":"Replay",
              "batch_size":60,
              "max_size":4000,
              "use_cer":true
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "clip_grad_val":1.0,
              "optim_spec":{
                "name":"SGD",
                "lr":0.04,
                "momentum":0.9
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }

          },
          {
            "copy_n":0
          },
          {
            "copy_n":0
          },
          {
            "name":"SupervisedLAPolicy",
            "algorithm":{
              "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
               "entropy_coef_spec":{
                    "name":"linear_decay",
                    "start_val":0.0,
                    "end_val":0.0,
                    "start_step":0,
                    "end_step":500
               },
              "training_frequency":1,
              "normalize_inputs":true,
              "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "loss_spec":{
                "name":"CrossEntropyLoss",
                "reduction":"none"
              },
              "optim_spec":{
                "name":"SGD",
                "lr":0.40,
                "momentum":0.000
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }
          }
        ]

      }
    }
    ],
    "env":[{
      "name":"IteratedPrisonersDilemma-v0",
      "max_t":null,
      "max_frame":4000,
      "num_envs":1
    }],
    "body":{
      "product":"outer",
      "num":1
    },
    "meta":{
      "distributed":false,
      "eval_frequency":20,
      "log_frequency":20,
      "max_session":10,
      "max_concurrent_session":10,
      "max_trial":1
    }
  },
  "ipd_ipm_le_self_play_strat_2_temp_1_0.65_0.75":{
    "world":{"name":"DefaultMultiAgentWorld",
             "deterministic":false},
    "agent":[{
      "name":"LE",
      "memory":null,
      "net":null,
      "welfare_function":"utilitarian_welfare",
      "observing_other_agents":{
        "name":"FullyObservable"
      },
      "algorithm":{
        "name":"LE",
        "punishement_time":1,
        "min_coop_time":0,
        "defection_detection_mode":"spl_observed_actions",
        "defection_carac_threshold":0.0,
        "average_d_carac":true,
        "average_d_carac_len":20,
        "same_init_weights":true,
        "coop_net_ent_diff_as_lr":false,
        "use_sl_for_simu_coop":false,
        "use_strat_4":false,
        "use_strat_5":false,
        "strat_5_coeff":10.0,
        "use_strat_2":true,
        "block_len":4,
        "use_last_steps_for_search":true,
        "use_bolzmann_search":true,
        "PERCENTILE_FOR_LIKELIHOOD_TEST":65,
        "meta_algo_memory":{
          "name":"Replay",
          "batch_size":1,
          "max_size":-1
        },
        "meta_algo_loss":{
          "reduction":"none",
          "name":"CrossEntropyLoss"
        },
        "contained_algorithms":[
          {
            "name":"DoubleDQN",
            "algorithm":{
              "name":"DoubleDQN",
              "action_pdtype":"Categorical",
              "action_policy":"boltzmann_on_cluster",
              "explore_var_spec":{
                "name":"linear_decay",
                "start_val":1.0,
                "end_val":0.1,
                "start_step":0,
                "end_step":3000
              },
              "gamma":0.5,
              "normalize_inputs":true,
              "training_batch_iter":1,
              "training_iter":4,
              "training_frequency":60,
              "training_start_step":60
            },
            "memory":{
              "name":"Replay",
              "batch_size":60,
              "max_size":4000,
              "use_cer":true
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "clip_grad_val":1.0,
              "optim_spec":{
                "name":"SGD",
                "lr":0.04,
                "momentum":0.9
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }

          },
          {
            "copy_n":0
          },
          {
            "copy_n":0
          },
          {
            "name":"SupervisedLAPolicy",
            "algorithm":{
              "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
               "entropy_coef_spec":{
                    "name":"linear_decay",
                    "start_val":0.0,
                    "end_val":0.0,
                    "start_step":0,
                    "end_step":500
               },
              "training_frequency":1,
              "normalize_inputs":true,
              "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "loss_spec":{
                "name":"CrossEntropyLoss",
                "reduction":"none"
              },
              "optim_spec":{
                "name":"SGD",
                "lr":0.40,
                "momentum":0.000
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }
          }
        ]

      }
    },
    {
      "name":"LE",
      "memory":null,
      "net":null,
      "welfare_function":"utilitarian_welfare",
      "observing_other_agents":{
        "name":"FullyObservable"
      },
      "algorithm":{
        "name":"LE",
        "punishement_time":1,
        "min_coop_time":0,
        "defection_detection_mode":"spl_observed_actions",
        "defection_carac_threshold":0.0,
        "average_d_carac":true,
        "average_d_carac_len":20,
        "same_init_weights":true,
        "coop_net_ent_diff_as_lr":false,
        "use_sl_for_simu_coop":false,
        "use_strat_4":false,
        "use_strat_5":false,
        "strat_5_coeff":10.0,
        "use_strat_2":true,
        "block_len":4,
        "use_last_steps_for_search":true,
        "use_bolzmann_search":true,
        "PERCENTILE_FOR_LIKELIHOOD_TEST":75,
        "meta_algo_memory":{
          "name":"Replay",
          "batch_size":1,
          "max_size":-1
        },
        "meta_algo_loss":{
          "reduction":"none",
          "name":"CrossEntropyLoss"
        },
        "contained_algorithms":[
          {
            "name":"DoubleDQN",
            "algorithm":{
              "name":"DoubleDQN",
              "action_pdtype":"Categorical",
              "action_policy":"boltzmann_on_cluster",
              "explore_var_spec":{
                "name":"linear_decay",
                "start_val":1.0,
                "end_val":0.1,
                "start_step":0,
                "end_step":3000
              },
              "gamma":0.5,
              "normalize_inputs":true,
              "training_batch_iter":1,
              "training_iter":4,
              "training_frequency":60,
              "training_start_step":60
            },
            "memory":{
              "name":"Replay",
              "batch_size":60,
              "max_size":4000,
              "use_cer":true
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "clip_grad_val":1.0,
              "optim_spec":{
                "name":"SGD",
                "lr":0.04,
                "momentum":0.9
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }

          },
          {
            "copy_n":0
          },
          {
            "copy_n":0
          },
          {
            "name":"SupervisedLAPolicy",
            "algorithm":{
              "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
               "entropy_coef_spec":{
                    "name":"linear_decay",
                    "start_val":0.0,
                    "end_val":0.0,
                    "start_step":0,
                    "end_step":500
               },
              "training_frequency":1,
              "normalize_inputs":true,
              "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "loss_spec":{
                "name":"CrossEntropyLoss",
                "reduction":"none"
              },
              "optim_spec":{
                "name":"SGD",
                "lr":0.40,
                "momentum":0.000
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }
          }
        ]

      }
    }
    ],
    "env":[{
      "name":"IteratedPrisonersDilemma-v0",
      "max_t":null,
      "max_frame":4000,
      "num_envs":1
    }],
    "body":{
      "product":"outer",
      "num":1
    },
    "meta":{
      "distributed":false,
      "eval_frequency":20,
      "log_frequency":20,
      "max_session":10,
      "max_concurrent_session":10,
      "max_trial":1
    }
  },
  "ipd_ipm_le_self_play_strat_2_temp_1_0.65_0.65":{
    "world":{"name":"DefaultMultiAgentWorld",
             "deterministic":false},
    "agent":[{
      "name":"LE",
      "memory":null,
      "net":null,
      "welfare_function":"utilitarian_welfare",
      "observing_other_agents":{
        "name":"FullyObservable"
      },
      "algorithm":{
        "name":"LE",
        "punishement_time":1,
        "min_coop_time":0,
        "defection_detection_mode":"spl_observed_actions",
        "defection_carac_threshold":0.0,
        "average_d_carac":true,
        "average_d_carac_len":20,
        "same_init_weights":true,
        "coop_net_ent_diff_as_lr":false,
        "use_sl_for_simu_coop":false,
        "use_strat_4":false,
        "use_strat_5":false,
        "strat_5_coeff":10.0,
        "use_strat_2":true,
        "block_len":4,
        "use_last_steps_for_search":true,
        "use_bolzmann_search":true,
        "PERCENTILE_FOR_LIKELIHOOD_TEST":65,
        "meta_algo_memory":{
          "name":"Replay",
          "batch_size":1,
          "max_size":-1
        },
        "meta_algo_loss":{
          "reduction":"none",
          "name":"CrossEntropyLoss"
        },
        "contained_algorithms":[
          {
            "name":"DoubleDQN",
            "algorithm":{
              "name":"DoubleDQN",
              "action_pdtype":"Categorical",
              "action_policy":"boltzmann_on_cluster",
              "explore_var_spec":{
                "name":"linear_decay",
                "start_val":1.0,
                "end_val":0.1,
                "start_step":0,
                "end_step":3000
              },
              "gamma":0.5,
              "normalize_inputs":true,
              "training_batch_iter":1,
              "training_iter":4,
              "training_frequency":60,
              "training_start_step":60
            },
            "memory":{
              "name":"Replay",
              "batch_size":60,
              "max_size":4000,
              "use_cer":true
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "clip_grad_val":1.0,
              "optim_spec":{
                "name":"SGD",
                "lr":0.04,
                "momentum":0.9
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }

          },
          {
            "copy_n":0
          },
          {
            "copy_n":0
          },
          {
            "name":"SupervisedLAPolicy",
            "algorithm":{
              "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
               "entropy_coef_spec":{
                    "name":"linear_decay",
                    "start_val":0.0,
                    "end_val":0.0,
                    "start_step":0,
                    "end_step":500
               },
              "training_frequency":1,
              "normalize_inputs":true,
              "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "loss_spec":{
                "name":"CrossEntropyLoss",
                "reduction":"none"
              },
              "optim_spec":{
                "name":"SGD",
                "lr":0.40,
                "momentum":0.000
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }
          }
        ]

      }
    },
    {
      "name":"LE",
      "memory":null,
      "net":null,
      "welfare_function":"utilitarian_welfare",
      "observing_other_agents":{
        "name":"FullyObservable"
      },
      "algorithm":{
        "name":"LE",
        "punishement_time":1,
        "min_coop_time":0,
        "defection_detection_mode":"spl_observed_actions",
        "defection_carac_threshold":0.0,
        "average_d_carac":true,
        "average_d_carac_len":20,
        "same_init_weights":true,
        "coop_net_ent_diff_as_lr":false,
        "use_sl_for_simu_coop":false,
        "use_strat_4":false,
        "use_strat_5":false,
        "strat_5_coeff":10.0,
        "use_strat_2":true,
        "block_len":4,
        "use_last_steps_for_search":true,
        "use_bolzmann_search":true,
        "PERCENTILE_FOR_LIKELIHOOD_TEST":65,
        "meta_algo_memory":{
          "name":"Replay",
          "batch_size":1,
          "max_size":-1
        },
        "meta_algo_loss":{
          "reduction":"none",
          "name":"CrossEntropyLoss"
        },
        "contained_algorithms":[
          {
            "name":"DoubleDQN",
            "algorithm":{
              "name":"DoubleDQN",
              "action_pdtype":"Categorical",
              "action_policy":"boltzmann_on_cluster",
              "explore_var_spec":{
                "name":"linear_decay",
                "start_val":1.0,
                "end_val":0.1,
                "start_step":0,
                "end_step":3000
              },
              "gamma":0.5,
              "normalize_inputs":true,
              "training_batch_iter":1,
              "training_iter":4,
              "training_frequency":60,
              "training_start_step":60
            },
            "memory":{
              "name":"Replay",
              "batch_size":60,
              "max_size":4000,
              "use_cer":true
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "clip_grad_val":1.0,
              "optim_spec":{
                "name":"SGD",
                "lr":0.04,
                "momentum":0.9
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }

          },
          {
            "copy_n":0
          },
          {
            "copy_n":0
          },
          {
            "name":"SupervisedLAPolicy",
            "algorithm":{
              "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
               "entropy_coef_spec":{
                    "name":"linear_decay",
                    "start_val":0.0,
                    "end_val":0.0,
                    "start_step":0,
                    "end_step":500
               },
              "training_frequency":1,
              "normalize_inputs":true,
              "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "loss_spec":{
                "name":"CrossEntropyLoss",
                "reduction":"none"
              },
              "optim_spec":{
                "name":"SGD",
                "lr":0.40,
                "momentum":0.000
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }
          }
        ]

      }
    }
    ],
    "env":[{
      "name":"IteratedPrisonersDilemma-v0",
      "max_t":null,
      "max_frame":4000,
      "num_envs":1
    }],
    "body":{
      "product":"outer",
      "num":1
    },
    "meta":{
      "distributed":false,
      "eval_frequency":20,
      "log_frequency":20,
      "max_session":10,
      "max_concurrent_session":10,
      "max_trial":1
    }
  },
  "ipd_ipm_le_self_play_strat_2_temp_1_0.65_0.55":{
    "world":{"name":"DefaultMultiAgentWorld",
             "deterministic":false},
    "agent":[{
      "name":"LE",
      "memory":null,
      "net":null,
      "welfare_function":"utilitarian_welfare",
      "observing_other_agents":{
        "name":"FullyObservable"
      },
      "algorithm":{
        "name":"LE",
        "punishement_time":1,
        "min_coop_time":0,
        "defection_detection_mode":"spl_observed_actions",
        "defection_carac_threshold":0.0,
        "average_d_carac":true,
        "average_d_carac_len":20,
        "same_init_weights":true,
        "coop_net_ent_diff_as_lr":false,
        "use_sl_for_simu_coop":false,
        "use_strat_4":false,
        "use_strat_5":false,
        "strat_5_coeff":10.0,
        "use_strat_2":true,
        "block_len":4,
        "use_last_steps_for_search":true,
        "use_bolzmann_search":true,
        "PERCENTILE_FOR_LIKELIHOOD_TEST":65,
        "meta_algo_memory":{
          "name":"Replay",
          "batch_size":1,
          "max_size":-1
        },
        "meta_algo_loss":{
          "reduction":"none",
          "name":"CrossEntropyLoss"
        },
        "contained_algorithms":[
          {
            "name":"DoubleDQN",
            "algorithm":{
              "name":"DoubleDQN",
              "action_pdtype":"Categorical",
              "action_policy":"boltzmann_on_cluster",
              "explore_var_spec":{
                "name":"linear_decay",
                "start_val":1.0,
                "end_val":0.1,
                "start_step":0,
                "end_step":3000
              },
              "gamma":0.5,
              "normalize_inputs":true,
              "training_batch_iter":1,
              "training_iter":4,
              "training_frequency":60,
              "training_start_step":60
            },
            "memory":{
              "name":"Replay",
              "batch_size":60,
              "max_size":4000,
              "use_cer":true
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "clip_grad_val":1.0,
              "optim_spec":{
                "name":"SGD",
                "lr":0.04,
                "momentum":0.9
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }

          },
          {
            "copy_n":0
          },
          {
            "copy_n":0
          },
          {
            "name":"SupervisedLAPolicy",
            "algorithm":{
              "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
               "entropy_coef_spec":{
                    "name":"linear_decay",
                    "start_val":0.0,
                    "end_val":0.0,
                    "start_step":0,
                    "end_step":500
               },
              "training_frequency":1,
              "normalize_inputs":true,
              "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "loss_spec":{
                "name":"CrossEntropyLoss",
                "reduction":"none"
              },
              "optim_spec":{
                "name":"SGD",
                "lr":0.40,
                "momentum":0.000
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }
          }
        ]

      }
    },
    {
      "name":"LE",
      "memory":null,
      "net":null,
      "welfare_function":"utilitarian_welfare",
      "observing_other_agents":{
        "name":"FullyObservable"
      },
      "algorithm":{
        "name":"LE",
        "punishement_time":1,
        "min_coop_time":0,
        "defection_detection_mode":"spl_observed_actions",
        "defection_carac_threshold":0.0,
        "average_d_carac":true,
        "average_d_carac_len":20,
        "same_init_weights":true,
        "coop_net_ent_diff_as_lr":false,
        "use_sl_for_simu_coop":false,
        "use_strat_4":false,
        "use_strat_5":false,
        "strat_5_coeff":10.0,
        "use_strat_2":true,
        "block_len":4,
        "use_last_steps_for_search":true,
        "use_bolzmann_search":true,
        "PERCENTILE_FOR_LIKELIHOOD_TEST":55,
        "meta_algo_memory":{
          "name":"Replay",
          "batch_size":1,
          "max_size":-1
        },
        "meta_algo_loss":{
          "reduction":"none",
          "name":"CrossEntropyLoss"
        },
        "contained_algorithms":[
          {
            "name":"DoubleDQN",
            "algorithm":{
              "name":"DoubleDQN",
              "action_pdtype":"Categorical",
              "action_policy":"boltzmann_on_cluster",
              "explore_var_spec":{
                "name":"linear_decay",
                "start_val":1.0,
                "end_val":0.1,
                "start_step":0,
                "end_step":3000
              },
              "gamma":0.5,
              "normalize_inputs":true,
              "training_batch_iter":1,
              "training_iter":4,
              "training_frequency":60,
              "training_start_step":60
            },
            "memory":{
              "name":"Replay",
              "batch_size":60,
              "max_size":4000,
              "use_cer":true
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "clip_grad_val":1.0,
              "optim_spec":{
                "name":"SGD",
                "lr":0.04,
                "momentum":0.9
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }

          },
          {
            "copy_n":0
          },
          {
            "copy_n":0
          },
          {
            "name":"SupervisedLAPolicy",
            "algorithm":{
              "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
               "entropy_coef_spec":{
                    "name":"linear_decay",
                    "start_val":0.0,
                    "end_val":0.0,
                    "start_step":0,
                    "end_step":500
               },
              "training_frequency":1,
              "normalize_inputs":true,
              "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "loss_spec":{
                "name":"CrossEntropyLoss",
                "reduction":"none"
              },
              "optim_spec":{
                "name":"SGD",
                "lr":0.40,
                "momentum":0.000
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }
          }
        ]

      }
    }
    ],
    "env":[{
      "name":"IteratedPrisonersDilemma-v0",
      "max_t":null,
      "max_frame":4000,
      "num_envs":1
    }],
    "body":{
      "product":"outer",
      "num":1
    },
    "meta":{
      "distributed":false,
      "eval_frequency":20,
      "log_frequency":20,
      "max_session":10,
      "max_concurrent_session":10,
      "max_trial":1
    }
  },

  "ipd_ipm_le_self_play_strat_2_temp_1_0.55_0.95":{
    "world":{"name":"DefaultMultiAgentWorld",
             "deterministic":false},
    "agent":[{
      "name":"LE",
      "memory":null,
      "net":null,
      "welfare_function":"utilitarian_welfare",
      "observing_other_agents":{
        "name":"FullyObservable"
      },
      "algorithm":{
        "name":"LE",
        "punishement_time":1,
        "min_coop_time":0,
        "defection_detection_mode":"spl_observed_actions",
        "defection_carac_threshold":0.0,
        "average_d_carac":true,
        "average_d_carac_len":20,
        "same_init_weights":true,
        "coop_net_ent_diff_as_lr":false,
        "use_sl_for_simu_coop":false,
        "use_strat_4":false,
        "use_strat_5":false,
        "strat_5_coeff":10.0,
        "use_strat_2":true,
        "block_len":4,
        "use_last_steps_for_search":true,
        "use_bolzmann_search":true,
        "PERCENTILE_FOR_LIKELIHOOD_TEST":55,
        "meta_algo_memory":{
          "name":"Replay",
          "batch_size":1,
          "max_size":-1
        },
        "meta_algo_loss":{
          "reduction":"none",
          "name":"CrossEntropyLoss"
        },
        "contained_algorithms":[
          {
            "name":"DoubleDQN",
            "algorithm":{
              "name":"DoubleDQN",
              "action_pdtype":"Categorical",
              "action_policy":"boltzmann_on_cluster",
              "explore_var_spec":{
                "name":"linear_decay",
                "start_val":1.0,
                "end_val":0.1,
                "start_step":0,
                "end_step":3000
              },
              "gamma":0.5,
              "normalize_inputs":true,
              "training_batch_iter":1,
              "training_iter":4,
              "training_frequency":60,
              "training_start_step":60
            },
            "memory":{
              "name":"Replay",
              "batch_size":60,
              "max_size":4000,
              "use_cer":true
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "clip_grad_val":1.0,
              "optim_spec":{
                "name":"SGD",
                "lr":0.04,
                "momentum":0.9
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }

          },
          {
            "copy_n":0
          },
          {
            "copy_n":0
          },
          {
            "name":"SupervisedLAPolicy",
            "algorithm":{
              "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
               "entropy_coef_spec":{
                    "name":"linear_decay",
                    "start_val":0.0,
                    "end_val":0.0,
                    "start_step":0,
                    "end_step":500
               },
              "training_frequency":1,
              "normalize_inputs":true,
              "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "loss_spec":{
                "name":"CrossEntropyLoss",
                "reduction":"none"
              },
              "optim_spec":{
                "name":"SGD",
                "lr":0.40,
                "momentum":0.000
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }
          }
        ]

      }
    },
    {
      "name":"LE",
      "memory":null,
      "net":null,
      "welfare_function":"utilitarian_welfare",
      "observing_other_agents":{
        "name":"FullyObservable"
      },
      "algorithm":{
        "name":"LE",
        "punishement_time":1,
        "min_coop_time":0,
        "defection_detection_mode":"spl_observed_actions",
        "defection_carac_threshold":0.0,
        "average_d_carac":true,
        "average_d_carac_len":20,
        "same_init_weights":true,
        "coop_net_ent_diff_as_lr":false,
        "use_sl_for_simu_coop":false,
        "use_strat_4":false,
        "use_strat_5":false,
        "strat_5_coeff":10.0,
        "use_strat_2":true,
        "block_len":4,
        "use_last_steps_for_search":true,
        "use_bolzmann_search":true,
        "PERCENTILE_FOR_LIKELIHOOD_TEST":95,
        "meta_algo_memory":{
          "name":"Replay",
          "batch_size":1,
          "max_size":-1
        },
        "meta_algo_loss":{
          "reduction":"none",
          "name":"CrossEntropyLoss"
        },
        "contained_algorithms":[
          {
            "name":"DoubleDQN",
            "algorithm":{
              "name":"DoubleDQN",
              "action_pdtype":"Categorical",
              "action_policy":"boltzmann_on_cluster",
              "explore_var_spec":{
                "name":"linear_decay",
                "start_val":1.0,
                "end_val":0.1,
                "start_step":0,
                "end_step":3000
              },
              "gamma":0.5,
              "normalize_inputs":true,
              "training_batch_iter":1,
              "training_iter":4,
              "training_frequency":60,
              "training_start_step":60
            },
            "memory":{
              "name":"Replay",
              "batch_size":60,
              "max_size":4000,
              "use_cer":true
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "clip_grad_val":1.0,
              "optim_spec":{
                "name":"SGD",
                "lr":0.04,
                "momentum":0.9
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }

          },
          {
            "copy_n":0
          },
          {
            "copy_n":0
          },
          {
            "name":"SupervisedLAPolicy",
            "algorithm":{
              "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
               "entropy_coef_spec":{
                    "name":"linear_decay",
                    "start_val":0.0,
                    "end_val":0.0,
                    "start_step":0,
                    "end_step":500
               },
              "training_frequency":1,
              "normalize_inputs":true,
              "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "loss_spec":{
                "name":"CrossEntropyLoss",
                "reduction":"none"
              },
              "optim_spec":{
                "name":"SGD",
                "lr":0.40,
                "momentum":0.000
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }
          }
        ]

      }
    }
    ],
    "env":[{
      "name":"IteratedPrisonersDilemma-v0",
      "max_t":null,
      "max_frame":4000,
      "num_envs":1
    }],
    "body":{
      "product":"outer",
      "num":1
    },
    "meta":{
      "distributed":false,
      "eval_frequency":20,
      "log_frequency":20,
      "max_session":10,
      "max_concurrent_session":10,
      "max_trial":1
    }
  },
  "ipd_ipm_le_self_play_strat_2_temp_1_0.55_0.85":{
    "world":{"name":"DefaultMultiAgentWorld",
             "deterministic":false},
    "agent":[{
      "name":"LE",
      "memory":null,
      "net":null,
      "welfare_function":"utilitarian_welfare",
      "observing_other_agents":{
        "name":"FullyObservable"
      },
      "algorithm":{
        "name":"LE",
        "punishement_time":1,
        "min_coop_time":0,
        "defection_detection_mode":"spl_observed_actions",
        "defection_carac_threshold":0.0,
        "average_d_carac":true,
        "average_d_carac_len":20,
        "same_init_weights":true,
        "coop_net_ent_diff_as_lr":false,
        "use_sl_for_simu_coop":false,
        "use_strat_4":false,
        "use_strat_5":false,
        "strat_5_coeff":10.0,
        "use_strat_2":true,
        "block_len":4,
        "use_last_steps_for_search":true,
        "use_bolzmann_search":true,
        "PERCENTILE_FOR_LIKELIHOOD_TEST":55,
        "meta_algo_memory":{
          "name":"Replay",
          "batch_size":1,
          "max_size":-1
        },
        "meta_algo_loss":{
          "reduction":"none",
          "name":"CrossEntropyLoss"
        },
        "contained_algorithms":[
          {
            "name":"DoubleDQN",
            "algorithm":{
              "name":"DoubleDQN",
              "action_pdtype":"Categorical",
              "action_policy":"boltzmann_on_cluster",
              "explore_var_spec":{
                "name":"linear_decay",
                "start_val":1.0,
                "end_val":0.1,
                "start_step":0,
                "end_step":3000
              },
              "gamma":0.5,
              "normalize_inputs":true,
              "training_batch_iter":1,
              "training_iter":4,
              "training_frequency":60,
              "training_start_step":60
            },
            "memory":{
              "name":"Replay",
              "batch_size":60,
              "max_size":4000,
              "use_cer":true
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "clip_grad_val":1.0,
              "optim_spec":{
                "name":"SGD",
                "lr":0.04,
                "momentum":0.9
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }

          },
          {
            "copy_n":0
          },
          {
            "copy_n":0
          },
          {
            "name":"SupervisedLAPolicy",
            "algorithm":{
              "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
               "entropy_coef_spec":{
                    "name":"linear_decay",
                    "start_val":0.0,
                    "end_val":0.0,
                    "start_step":0,
                    "end_step":500
               },
              "training_frequency":1,
              "normalize_inputs":true,
              "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "loss_spec":{
                "name":"CrossEntropyLoss",
                "reduction":"none"
              },
              "optim_spec":{
                "name":"SGD",
                "lr":0.40,
                "momentum":0.000
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }
          }
        ]

      }
    },
    {
      "name":"LE",
      "memory":null,
      "net":null,
      "welfare_function":"utilitarian_welfare",
      "observing_other_agents":{
        "name":"FullyObservable"
      },
      "algorithm":{
        "name":"LE",
        "punishement_time":1,
        "min_coop_time":0,
        "defection_detection_mode":"spl_observed_actions",
        "defection_carac_threshold":0.0,
        "average_d_carac":true,
        "average_d_carac_len":20,
        "same_init_weights":true,
        "coop_net_ent_diff_as_lr":false,
        "use_sl_for_simu_coop":false,
        "use_strat_4":false,
        "use_strat_5":false,
        "strat_5_coeff":10.0,
        "use_strat_2":true,
        "block_len":4,
        "use_last_steps_for_search":true,
        "use_bolzmann_search":true,
        "PERCENTILE_FOR_LIKELIHOOD_TEST":85,
        "meta_algo_memory":{
          "name":"Replay",
          "batch_size":1,
          "max_size":-1
        },
        "meta_algo_loss":{
          "reduction":"none",
          "name":"CrossEntropyLoss"
        },
        "contained_algorithms":[
          {
            "name":"DoubleDQN",
            "algorithm":{
              "name":"DoubleDQN",
              "action_pdtype":"Categorical",
              "action_policy":"boltzmann_on_cluster",
              "explore_var_spec":{
                "name":"linear_decay",
                "start_val":1.0,
                "end_val":0.1,
                "start_step":0,
                "end_step":3000
              },
              "gamma":0.5,
              "normalize_inputs":true,
              "training_batch_iter":1,
              "training_iter":4,
              "training_frequency":60,
              "training_start_step":60
            },
            "memory":{
              "name":"Replay",
              "batch_size":60,
              "max_size":4000,
              "use_cer":true
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "clip_grad_val":1.0,
              "optim_spec":{
                "name":"SGD",
                "lr":0.04,
                "momentum":0.9
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }

          },
          {
            "copy_n":0
          },
          {
            "copy_n":0
          },
          {
            "name":"SupervisedLAPolicy",
            "algorithm":{
              "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
               "entropy_coef_spec":{
                    "name":"linear_decay",
                    "start_val":0.0,
                    "end_val":0.0,
                    "start_step":0,
                    "end_step":500
               },
              "training_frequency":1,
              "normalize_inputs":true,
              "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "loss_spec":{
                "name":"CrossEntropyLoss",
                "reduction":"none"
              },
              "optim_spec":{
                "name":"SGD",
                "lr":0.40,
                "momentum":0.000
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }
          }
        ]

      }
    }
    ],
    "env":[{
      "name":"IteratedPrisonersDilemma-v0",
      "max_t":null,
      "max_frame":4000,
      "num_envs":1
    }],
    "body":{
      "product":"outer",
      "num":1
    },
    "meta":{
      "distributed":false,
      "eval_frequency":20,
      "log_frequency":20,
      "max_session":10,
      "max_concurrent_session":10,
      "max_trial":1
    }
  },
  "ipd_ipm_le_self_play_strat_2_temp_1_0.55_0.75":{
    "world":{"name":"DefaultMultiAgentWorld",
             "deterministic":false},
    "agent":[{
      "name":"LE",
      "memory":null,
      "net":null,
      "welfare_function":"utilitarian_welfare",
      "observing_other_agents":{
        "name":"FullyObservable"
      },
      "algorithm":{
        "name":"LE",
        "punishement_time":1,
        "min_coop_time":0,
        "defection_detection_mode":"spl_observed_actions",
        "defection_carac_threshold":0.0,
        "average_d_carac":true,
        "average_d_carac_len":20,
        "same_init_weights":true,
        "coop_net_ent_diff_as_lr":false,
        "use_sl_for_simu_coop":false,
        "use_strat_4":false,
        "use_strat_5":false,
        "strat_5_coeff":10.0,
        "use_strat_2":true,
        "block_len":4,
        "use_last_steps_for_search":true,
        "use_bolzmann_search":true,
        "PERCENTILE_FOR_LIKELIHOOD_TEST":55,
        "meta_algo_memory":{
          "name":"Replay",
          "batch_size":1,
          "max_size":-1
        },
        "meta_algo_loss":{
          "reduction":"none",
          "name":"CrossEntropyLoss"
        },
        "contained_algorithms":[
          {
            "name":"DoubleDQN",
            "algorithm":{
              "name":"DoubleDQN",
              "action_pdtype":"Categorical",
              "action_policy":"boltzmann_on_cluster",
              "explore_var_spec":{
                "name":"linear_decay",
                "start_val":1.0,
                "end_val":0.1,
                "start_step":0,
                "end_step":3000
              },
              "gamma":0.5,
              "normalize_inputs":true,
              "training_batch_iter":1,
              "training_iter":4,
              "training_frequency":60,
              "training_start_step":60
            },
            "memory":{
              "name":"Replay",
              "batch_size":60,
              "max_size":4000,
              "use_cer":true
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "clip_grad_val":1.0,
              "optim_spec":{
                "name":"SGD",
                "lr":0.04,
                "momentum":0.9
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }

          },
          {
            "copy_n":0
          },
          {
            "copy_n":0
          },
          {
            "name":"SupervisedLAPolicy",
            "algorithm":{
              "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
               "entropy_coef_spec":{
                    "name":"linear_decay",
                    "start_val":0.0,
                    "end_val":0.0,
                    "start_step":0,
                    "end_step":500
               },
              "training_frequency":1,
              "normalize_inputs":true,
              "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "loss_spec":{
                "name":"CrossEntropyLoss",
                "reduction":"none"
              },
              "optim_spec":{
                "name":"SGD",
                "lr":0.40,
                "momentum":0.000
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }
          }
        ]

      }
    },
    {
      "name":"LE",
      "memory":null,
      "net":null,
      "welfare_function":"utilitarian_welfare",
      "observing_other_agents":{
        "name":"FullyObservable"
      },
      "algorithm":{
        "name":"LE",
        "punishement_time":1,
        "min_coop_time":0,
        "defection_detection_mode":"spl_observed_actions",
        "defection_carac_threshold":0.0,
        "average_d_carac":true,
        "average_d_carac_len":20,
        "same_init_weights":true,
        "coop_net_ent_diff_as_lr":false,
        "use_sl_for_simu_coop":false,
        "use_strat_4":false,
        "use_strat_5":false,
        "strat_5_coeff":10.0,
        "use_strat_2":true,
        "block_len":4,
        "use_last_steps_for_search":true,
        "use_bolzmann_search":true,
        "PERCENTILE_FOR_LIKELIHOOD_TEST":75,
        "meta_algo_memory":{
          "name":"Replay",
          "batch_size":1,
          "max_size":-1
        },
        "meta_algo_loss":{
          "reduction":"none",
          "name":"CrossEntropyLoss"
        },
        "contained_algorithms":[
          {
            "name":"DoubleDQN",
            "algorithm":{
              "name":"DoubleDQN",
              "action_pdtype":"Categorical",
              "action_policy":"boltzmann_on_cluster",
              "explore_var_spec":{
                "name":"linear_decay",
                "start_val":1.0,
                "end_val":0.1,
                "start_step":0,
                "end_step":3000
              },
              "gamma":0.5,
              "normalize_inputs":true,
              "training_batch_iter":1,
              "training_iter":4,
              "training_frequency":60,
              "training_start_step":60
            },
            "memory":{
              "name":"Replay",
              "batch_size":60,
              "max_size":4000,
              "use_cer":true
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "clip_grad_val":1.0,
              "optim_spec":{
                "name":"SGD",
                "lr":0.04,
                "momentum":0.9
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }

          },
          {
            "copy_n":0
          },
          {
            "copy_n":0
          },
          {
            "name":"SupervisedLAPolicy",
            "algorithm":{
              "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
               "entropy_coef_spec":{
                    "name":"linear_decay",
                    "start_val":0.0,
                    "end_val":0.0,
                    "start_step":0,
                    "end_step":500
               },
              "training_frequency":1,
              "normalize_inputs":true,
              "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "loss_spec":{
                "name":"CrossEntropyLoss",
                "reduction":"none"
              },
              "optim_spec":{
                "name":"SGD",
                "lr":0.40,
                "momentum":0.000
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }
          }
        ]

      }
    }
    ],
    "env":[{
      "name":"IteratedPrisonersDilemma-v0",
      "max_t":null,
      "max_frame":4000,
      "num_envs":1
    }],
    "body":{
      "product":"outer",
      "num":1
    },
    "meta":{
      "distributed":false,
      "eval_frequency":20,
      "log_frequency":20,
      "max_session":10,
      "max_concurrent_session":10,
      "max_trial":1
    }
  },
  "ipd_ipm_le_self_play_strat_2_temp_1_0.55_0.65":{
    "world":{"name":"DefaultMultiAgentWorld",
             "deterministic":false},
    "agent":[{
      "name":"LE",
      "memory":null,
      "net":null,
      "welfare_function":"utilitarian_welfare",
      "observing_other_agents":{
        "name":"FullyObservable"
      },
      "algorithm":{
        "name":"LE",
        "punishement_time":1,
        "min_coop_time":0,
        "defection_detection_mode":"spl_observed_actions",
        "defection_carac_threshold":0.0,
        "average_d_carac":true,
        "average_d_carac_len":20,
        "same_init_weights":true,
        "coop_net_ent_diff_as_lr":false,
        "use_sl_for_simu_coop":false,
        "use_strat_4":false,
        "use_strat_5":false,
        "strat_5_coeff":10.0,
        "use_strat_2":true,
        "block_len":4,
        "use_last_steps_for_search":true,
        "use_bolzmann_search":true,
        "PERCENTILE_FOR_LIKELIHOOD_TEST":55,
        "meta_algo_memory":{
          "name":"Replay",
          "batch_size":1,
          "max_size":-1
        },
        "meta_algo_loss":{
          "reduction":"none",
          "name":"CrossEntropyLoss"
        },
        "contained_algorithms":[
          {
            "name":"DoubleDQN",
            "algorithm":{
              "name":"DoubleDQN",
              "action_pdtype":"Categorical",
              "action_policy":"boltzmann_on_cluster",
              "explore_var_spec":{
                "name":"linear_decay",
                "start_val":1.0,
                "end_val":0.1,
                "start_step":0,
                "end_step":3000
              },
              "gamma":0.5,
              "normalize_inputs":true,
              "training_batch_iter":1,
              "training_iter":4,
              "training_frequency":60,
              "training_start_step":60
            },
            "memory":{
              "name":"Replay",
              "batch_size":60,
              "max_size":4000,
              "use_cer":true
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "clip_grad_val":1.0,
              "optim_spec":{
                "name":"SGD",
                "lr":0.04,
                "momentum":0.9
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }

          },
          {
            "copy_n":0
          },
          {
            "copy_n":0
          },
          {
            "name":"SupervisedLAPolicy",
            "algorithm":{
              "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
               "entropy_coef_spec":{
                    "name":"linear_decay",
                    "start_val":0.0,
                    "end_val":0.0,
                    "start_step":0,
                    "end_step":500
               },
              "training_frequency":1,
              "normalize_inputs":true,
              "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "loss_spec":{
                "name":"CrossEntropyLoss",
                "reduction":"none"
              },
              "optim_spec":{
                "name":"SGD",
                "lr":0.40,
                "momentum":0.000
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }
          }
        ]

      }
    },
    {
      "name":"LE",
      "memory":null,
      "net":null,
      "welfare_function":"utilitarian_welfare",
      "observing_other_agents":{
        "name":"FullyObservable"
      },
      "algorithm":{
        "name":"LE",
        "punishement_time":1,
        "min_coop_time":0,
        "defection_detection_mode":"spl_observed_actions",
        "defection_carac_threshold":0.0,
        "average_d_carac":true,
        "average_d_carac_len":20,
        "same_init_weights":true,
        "coop_net_ent_diff_as_lr":false,
        "use_sl_for_simu_coop":false,
        "use_strat_4":false,
        "use_strat_5":false,
        "strat_5_coeff":10.0,
        "use_strat_2":true,
        "block_len":4,
        "use_last_steps_for_search":true,
        "use_bolzmann_search":true,
        "PERCENTILE_FOR_LIKELIHOOD_TEST":65,
        "meta_algo_memory":{
          "name":"Replay",
          "batch_size":1,
          "max_size":-1
        },
        "meta_algo_loss":{
          "reduction":"none",
          "name":"CrossEntropyLoss"
        },
        "contained_algorithms":[
          {
            "name":"DoubleDQN",
            "algorithm":{
              "name":"DoubleDQN",
              "action_pdtype":"Categorical",
              "action_policy":"boltzmann_on_cluster",
              "explore_var_spec":{
                "name":"linear_decay",
                "start_val":1.0,
                "end_val":0.1,
                "start_step":0,
                "end_step":3000
              },
              "gamma":0.5,
              "normalize_inputs":true,
              "training_batch_iter":1,
              "training_iter":4,
              "training_frequency":60,
              "training_start_step":60
            },
            "memory":{
              "name":"Replay",
              "batch_size":60,
              "max_size":4000,
              "use_cer":true
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "clip_grad_val":1.0,
              "optim_spec":{
                "name":"SGD",
                "lr":0.04,
                "momentum":0.9
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }

          },
          {
            "copy_n":0
          },
          {
            "copy_n":0
          },
          {
            "name":"SupervisedLAPolicy",
            "algorithm":{
              "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
               "entropy_coef_spec":{
                    "name":"linear_decay",
                    "start_val":0.0,
                    "end_val":0.0,
                    "start_step":0,
                    "end_step":500
               },
              "training_frequency":1,
              "normalize_inputs":true,
              "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "loss_spec":{
                "name":"CrossEntropyLoss",
                "reduction":"none"
              },
              "optim_spec":{
                "name":"SGD",
                "lr":0.40,
                "momentum":0.000
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }
          }
        ]

      }
    }
    ],
    "env":[{
      "name":"IteratedPrisonersDilemma-v0",
      "max_t":null,
      "max_frame":4000,
      "num_envs":1
    }],
    "body":{
      "product":"outer",
      "num":1
    },
    "meta":{
      "distributed":false,
      "eval_frequency":20,
      "log_frequency":20,
      "max_session":10,
      "max_concurrent_session":10,
      "max_trial":1
    }
  },
  "ipd_ipm_le_self_play_strat_2_temp_1_0.55_0.55":{
    "world":{"name":"DefaultMultiAgentWorld",
             "deterministic":false},
    "agent":[{
      "name":"LE",
      "memory":null,
      "net":null,
      "welfare_function":"utilitarian_welfare",
      "observing_other_agents":{
        "name":"FullyObservable"
      },
      "algorithm":{
        "name":"LE",
        "punishement_time":1,
        "min_coop_time":0,
        "defection_detection_mode":"spl_observed_actions",
        "defection_carac_threshold":0.0,
        "average_d_carac":true,
        "average_d_carac_len":20,
        "same_init_weights":true,
        "coop_net_ent_diff_as_lr":false,
        "use_sl_for_simu_coop":false,
        "use_strat_4":false,
        "use_strat_5":false,
        "strat_5_coeff":10.0,
        "use_strat_2":true,
        "block_len":4,
        "use_last_steps_for_search":true,
        "use_bolzmann_search":true,
        "PERCENTILE_FOR_LIKELIHOOD_TEST":55,
        "meta_algo_memory":{
          "name":"Replay",
          "batch_size":1,
          "max_size":-1
        },
        "meta_algo_loss":{
          "reduction":"none",
          "name":"CrossEntropyLoss"
        },
        "contained_algorithms":[
          {
            "name":"DoubleDQN",
            "algorithm":{
              "name":"DoubleDQN",
              "action_pdtype":"Categorical",
              "action_policy":"boltzmann_on_cluster",
              "explore_var_spec":{
                "name":"linear_decay",
                "start_val":1.0,
                "end_val":0.1,
                "start_step":0,
                "end_step":3000
              },
              "gamma":0.5,
              "normalize_inputs":true,
              "training_batch_iter":1,
              "training_iter":4,
              "training_frequency":60,
              "training_start_step":60
            },
            "memory":{
              "name":"Replay",
              "batch_size":60,
              "max_size":4000,
              "use_cer":true
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "clip_grad_val":1.0,
              "optim_spec":{
                "name":"SGD",
                "lr":0.04,
                "momentum":0.9
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }

          },
          {
            "copy_n":0
          },
          {
            "copy_n":0
          },
          {
            "name":"SupervisedLAPolicy",
            "algorithm":{
              "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
               "entropy_coef_spec":{
                    "name":"linear_decay",
                    "start_val":0.0,
                    "end_val":0.0,
                    "start_step":0,
                    "end_step":500
               },
              "training_frequency":1,
              "normalize_inputs":true,
              "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "loss_spec":{
                "name":"CrossEntropyLoss",
                "reduction":"none"
              },
              "optim_spec":{
                "name":"SGD",
                "lr":0.40,
                "momentum":0.000
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }
          }
        ]

      }
    },
    {
      "name":"LE",
      "memory":null,
      "net":null,
      "welfare_function":"utilitarian_welfare",
      "observing_other_agents":{
        "name":"FullyObservable"
      },
      "algorithm":{
        "name":"LE",
        "punishement_time":1,
        "min_coop_time":0,
        "defection_detection_mode":"spl_observed_actions",
        "defection_carac_threshold":0.0,
        "average_d_carac":true,
        "average_d_carac_len":20,
        "same_init_weights":true,
        "coop_net_ent_diff_as_lr":false,
        "use_sl_for_simu_coop":false,
        "use_strat_4":false,
        "use_strat_5":false,
        "strat_5_coeff":10.0,
        "use_strat_2":true,
        "block_len":4,
        "use_last_steps_for_search":true,
        "use_bolzmann_search":true,
        "PERCENTILE_FOR_LIKELIHOOD_TEST":55,
        "meta_algo_memory":{
          "name":"Replay",
          "batch_size":1,
          "max_size":-1
        },
        "meta_algo_loss":{
          "reduction":"none",
          "name":"CrossEntropyLoss"
        },
        "contained_algorithms":[
          {
            "name":"DoubleDQN",
            "algorithm":{
              "name":"DoubleDQN",
              "action_pdtype":"Categorical",
              "action_policy":"boltzmann_on_cluster",
              "explore_var_spec":{
                "name":"linear_decay",
                "start_val":1.0,
                "end_val":0.1,
                "start_step":0,
                "end_step":3000
              },
              "gamma":0.5,
              "normalize_inputs":true,
              "training_batch_iter":1,
              "training_iter":4,
              "training_frequency":60,
              "training_start_step":60
            },
            "memory":{
              "name":"Replay",
              "batch_size":60,
              "max_size":4000,
              "use_cer":true
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "clip_grad_val":1.0,
              "optim_spec":{
                "name":"SGD",
                "lr":0.04,
                "momentum":0.9
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }

          },
          {
            "copy_n":0
          },
          {
            "copy_n":0
          },
          {
            "name":"SupervisedLAPolicy",
            "algorithm":{
              "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
               "entropy_coef_spec":{
                    "name":"linear_decay",
                    "start_val":0.0,
                    "end_val":0.0,
                    "start_step":0,
                    "end_step":500
               },
              "training_frequency":1,
              "normalize_inputs":true,
              "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
            },
            "net":{
              "type":"MLPNet",
              "hid_layers":[4],
              "hid_layers_activation":"LeakyReLU",
              "init_fn":"normal_mu_0_std_0.1",
              "loss_spec":{
                "name":"CrossEntropyLoss",
                "reduction":"none"
              },
              "optim_spec":{
                "name":"SGD",
                "lr":0.40,
                "momentum":0.000
              },
              "lr_scheduler_spec":{
                "name":"LinearToZero",
                "frame":4000
              }
            }
          }
        ]

      }
    }
    ],
    "env":[{
      "name":"IteratedPrisonersDilemma-v0",
      "max_t":null,
      "max_frame":4000,
      "num_envs":1
    }],
    "body":{
      "product":"outer",
      "num":1
    },
    "meta":{
      "distributed":false,
      "eval_frequency":20,
      "log_frequency":20,
      "max_session":10,
      "max_concurrent_session":10,
      "max_trial":1
    }
  },



  "ipd_ipm_le_vs_exploiter_strat_2_temp_1_0.95_0.95":{
    "world":{
      "name":"DefaultMultiAgentWorld",
      "deterministic":false
    },
    "agent":[
      {
        "name":"LE",
        "memory":null,
        "net":null,
        "welfare_function":"utilitarian_welfare",
        "observing_other_agents":{
          "name":"FullyObservable"
        },
        "algorithm":{
          "name":"LE",
          "punishement_time":1,
          "min_coop_time":0,
          "defection_detection_mode":"spl_observed_actions",
          "defection_carac_threshold":0.0,
          "average_d_carac":true,
          "average_d_carac_len":20,
          "same_init_weights":false,
          "coop_net_ent_diff_as_lr":false,
          "use_sl_for_simu_coop":false,
          "use_strat_4":false,
          "use_strat_5":false,
          "strat_5_coeff":10.0,
          "use_strat_2":true,
          "length_of_history":200,
          "block_len":4,
          "use_last_steps_for_search":true,
          "use_bolzmann_search":true,
          "PERCENTILE_FOR_LIKELIHOOD_TEST":95,
          "meta_algo_memory":{
            "name":"Replay",
            "batch_size":1,
            "max_size":-1
          },
          "meta_algo_loss":{
            "reduction":"none",
            "name":"CrossEntropyLoss"
          },
          "contained_algorithms":[
            {
              "name":"DoubleDQN",
              "algorithm":{
                "name":"DoubleDQN",
                "action_pdtype":"Categorical",
                "action_policy":"boltzmann_on_cluster",
                "explore_var_spec":{
                  "name":"linear_decay",
                  "start_val":1.0,
                  "end_val":0.1,
                  "start_step":0,
                  "end_step":3000
                },
                "gamma":0.5,
                "normalize_inputs":true,
                "training_batch_iter":1,
                "training_iter":4,
                "training_frequency":60,
                "training_start_step":60
              },
              "memory":{
                "name":"Replay",
                "batch_size":60,
                "max_size":4000,
                "use_cer":true
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "clip_grad_val":1.0,
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.04,
                  "momentum":0.9
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            },
            {
              "copy_n":0
            },
            {
              "copy_n":0
            },
            {
              "name":"SupervisedLAPolicy",
              "algorithm":{
                "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
                "entropy_coef_spec":{
                  "name":"linear_decay",
                  "start_val":0.0,
                  "end_val":0.0,
                  "start_step":0,
                  "end_step":500
                },
                "training_frequency":1,
                "normalize_inputs":true,
                "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "loss_spec":{
                  "name":"CrossEntropyLoss",
                  "reduction":"none"
                },
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.40,
                  "momentum":0.000
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            }
          ]
        }
      },
      {
        "name":"LEExploiter",
        "memory":null,
        "net":null,
        "welfare_function":"default_welfare",
        "observing_other_agents":{
          "name":"FullyObservable"
        },
        "algorithm":{
          "name":"LEExploiter",
          "punishement_time":1,
          "min_coop_time":0,
          "defection_detection_mode":"spl_observed_actions",
          "defection_carac_threshold":0.0,
          "average_d_carac":true,
          "average_d_carac_len":20,
          "same_init_weights":false,
          "coop_net_ent_diff_as_lr":false,
          "use_sl_for_simu_coop":false,
          "use_strat_4":false,
          "use_strat_5":false,
          "strat_5_coeff":10.0,
          "use_strat_2":true,
          "length_of_history":200,
          "block_len":4,
          "use_last_steps_for_search":true,
          "use_bolzmann_search":true,
          "PERCENTILE_FOR_LIKELIHOOD_TEST":95,
          "meta_algo_memory":{
            "name":"Replay",
            "batch_size":1,
            "max_size":-1
          },
          "meta_algo_loss":{
            "reduction":"none",
            "name":"CrossEntropyLoss"
          },
          "contained_algorithms":[
            {
              "name":"DoubleDQN",
              "algorithm":{
                "name":"DoubleDQN",
                "action_pdtype":"Categorical",
                "action_policy":"boltzmann_on_cluster",
                "explore_var_spec":{
                  "name":"linear_decay",
                  "start_val":1.0,
                  "end_val":0.1,
                  "start_step":0,
                  "end_step":3000
                },
                "gamma":0.5,
                "normalize_inputs":true,
                "training_batch_iter":1,
                "training_iter":4,
                "training_frequency":60,
                "training_start_step":60
              },
              "memory":{
                "name":"Replay",
                "batch_size":60,
                "max_size":4000,
                "use_cer":true
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "clip_grad_val":1.0,
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.04,
                  "momentum":0.9
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            },
            {
              "copy_n":0
            },
            {
              "copy_n":0
            },
            {
              "name":"SupervisedLAPolicy",
              "algorithm":{
                "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
                "entropy_coef_spec":{
                  "name":"linear_decay",
                  "start_val":0.0,
                  "end_val":0.0,
                  "start_step":0,
                  "end_step":500
                },
                "training_frequency":1,
                "normalize_inputs":true,
                "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "loss_spec":{
                  "name":"CrossEntropyLoss",
                  "reduction":"none"
                },
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.40,
                  "momentum":0.000
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            }
          ]
        }
      }
    ],
    "env":[
      {
        "name":"IteratedPrisonersDilemma-v0",
        "max_t":null,
        "max_frame":4000,
        "num_envs":1
      }
    ],
    "body":{
      "product":"outer",
      "num":1
    },
    "meta":{
      "distributed":false,
      "eval_frequency":20,
      "log_frequency":20,
      "max_session":10,
      "max_concurrent_session":10,
      "max_trial":1
    }
  },
  "ipd_ipm_le_vs_exploiter_strat_2_temp_1_0.95_0.85":{
    "world":{
      "name":"DefaultMultiAgentWorld",
      "deterministic":false
    },
    "agent":[
      {
        "name":"LE",
        "memory":null,
        "net":null,
        "welfare_function":"utilitarian_welfare",
        "observing_other_agents":{
          "name":"FullyObservable"
        },
        "algorithm":{
          "name":"LE",
          "punishement_time":1,
          "min_coop_time":0,
          "defection_detection_mode":"spl_observed_actions",
          "defection_carac_threshold":0.0,
          "average_d_carac":true,
          "average_d_carac_len":20,
          "same_init_weights":false,
          "coop_net_ent_diff_as_lr":false,
          "use_sl_for_simu_coop":false,
          "use_strat_4":false,
          "use_strat_5":false,
          "strat_5_coeff":10.0,
          "use_strat_2":true,
          "length_of_history":200,
          "block_len":4,
          "use_last_steps_for_search":true,
          "use_bolzmann_search":true,
          "PERCENTILE_FOR_LIKELIHOOD_TEST":95,
          "meta_algo_memory":{
            "name":"Replay",
            "batch_size":1,
            "max_size":-1
          },
          "meta_algo_loss":{
            "reduction":"none",
            "name":"CrossEntropyLoss"
          },
          "contained_algorithms":[
            {
              "name":"DoubleDQN",
              "algorithm":{
                "name":"DoubleDQN",
                "action_pdtype":"Categorical",
                "action_policy":"boltzmann_on_cluster",
                "explore_var_spec":{
                  "name":"linear_decay",
                  "start_val":1.0,
                  "end_val":0.1,
                  "start_step":0,
                  "end_step":3000
                },
                "gamma":0.5,
                "normalize_inputs":true,
                "training_batch_iter":1,
                "training_iter":4,
                "training_frequency":60,
                "training_start_step":60
              },
              "memory":{
                "name":"Replay",
                "batch_size":60,
                "max_size":4000,
                "use_cer":true
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "clip_grad_val":1.0,
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.04,
                  "momentum":0.9
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            },
            {
              "copy_n":0
            },
            {
              "copy_n":0
            },
            {
              "name":"SupervisedLAPolicy",
              "algorithm":{
                "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
                "entropy_coef_spec":{
                  "name":"linear_decay",
                  "start_val":0.0,
                  "end_val":0.0,
                  "start_step":0,
                  "end_step":500
                },
                "training_frequency":1,
                "normalize_inputs":true,
                "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "loss_spec":{
                  "name":"CrossEntropyLoss",
                  "reduction":"none"
                },
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.40,
                  "momentum":0.000
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            }
          ]
        }
      },
      {
        "name":"LEExploiter",
        "memory":null,
        "net":null,
        "welfare_function":"default_welfare",
        "observing_other_agents":{
          "name":"FullyObservable"
        },
        "algorithm":{
          "name":"LEExploiter",
          "punishement_time":1,
          "min_coop_time":0,
          "defection_detection_mode":"spl_observed_actions",
          "defection_carac_threshold":0.0,
          "average_d_carac":true,
          "average_d_carac_len":20,
          "same_init_weights":false,
          "coop_net_ent_diff_as_lr":false,
          "use_sl_for_simu_coop":false,
          "use_strat_4":false,
          "use_strat_5":false,
          "strat_5_coeff":10.0,
          "use_strat_2":true,
          "length_of_history":200,
          "block_len":4,
          "use_last_steps_for_search":true,
          "use_bolzmann_search":true,
          "PERCENTILE_FOR_LIKELIHOOD_TEST":85,
          "meta_algo_memory":{
            "name":"Replay",
            "batch_size":1,
            "max_size":-1
          },
          "meta_algo_loss":{
            "reduction":"none",
            "name":"CrossEntropyLoss"
          },
          "contained_algorithms":[
            {
              "name":"DoubleDQN",
              "algorithm":{
                "name":"DoubleDQN",
                "action_pdtype":"Categorical",
                "action_policy":"boltzmann_on_cluster",
                "explore_var_spec":{
                  "name":"linear_decay",
                  "start_val":1.0,
                  "end_val":0.1,
                  "start_step":0,
                  "end_step":3000
                },
                "gamma":0.5,
                "normalize_inputs":true,
                "training_batch_iter":1,
                "training_iter":4,
                "training_frequency":60,
                "training_start_step":60
              },
              "memory":{
                "name":"Replay",
                "batch_size":60,
                "max_size":4000,
                "use_cer":true
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "clip_grad_val":1.0,
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.04,
                  "momentum":0.9
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            },
            {
              "copy_n":0
            },
            {
              "copy_n":0
            },
            {
              "name":"SupervisedLAPolicy",
              "algorithm":{
                "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
                "entropy_coef_spec":{
                  "name":"linear_decay",
                  "start_val":0.0,
                  "end_val":0.0,
                  "start_step":0,
                  "end_step":500
                },
                "training_frequency":1,
                "normalize_inputs":true,
                "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "loss_spec":{
                  "name":"CrossEntropyLoss",
                  "reduction":"none"
                },
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.40,
                  "momentum":0.000
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            }
          ]
        }
      }
    ],
    "env":[
      {
        "name":"IteratedPrisonersDilemma-v0",
        "max_t":null,
        "max_frame":4000,
        "num_envs":1
      }
    ],
    "body":{
      "product":"outer",
      "num":1
    },
    "meta":{
      "distributed":false,
      "eval_frequency":20,
      "log_frequency":20,
      "max_session":10,
      "max_concurrent_session":10,
      "max_trial":1
    }
  },
  "ipd_ipm_le_vs_exploiter_strat_2_temp_1_0.95_0.75":{
    "world":{
      "name":"DefaultMultiAgentWorld",
      "deterministic":false
    },
    "agent":[
      {
        "name":"LE",
        "memory":null,
        "net":null,
        "welfare_function":"utilitarian_welfare",
        "observing_other_agents":{
          "name":"FullyObservable"
        },
        "algorithm":{
          "name":"LE",
          "punishement_time":1,
          "min_coop_time":0,
          "defection_detection_mode":"spl_observed_actions",
          "defection_carac_threshold":0.0,
          "average_d_carac":true,
          "average_d_carac_len":20,
          "same_init_weights":false,
          "coop_net_ent_diff_as_lr":false,
          "use_sl_for_simu_coop":false,
          "use_strat_4":false,
          "use_strat_5":false,
          "strat_5_coeff":10.0,
          "use_strat_2":true,
          "length_of_history":200,
          "block_len":4,
          "use_last_steps_for_search":true,
          "use_bolzmann_search":true,
          "PERCENTILE_FOR_LIKELIHOOD_TEST":95,
          "meta_algo_memory":{
            "name":"Replay",
            "batch_size":1,
            "max_size":-1
          },
          "meta_algo_loss":{
            "reduction":"none",
            "name":"CrossEntropyLoss"
          },
          "contained_algorithms":[
            {
              "name":"DoubleDQN",
              "algorithm":{
                "name":"DoubleDQN",
                "action_pdtype":"Categorical",
                "action_policy":"boltzmann_on_cluster",
                "explore_var_spec":{
                  "name":"linear_decay",
                  "start_val":1.0,
                  "end_val":0.1,
                  "start_step":0,
                  "end_step":3000
                },
                "gamma":0.5,
                "normalize_inputs":true,
                "training_batch_iter":1,
                "training_iter":4,
                "training_frequency":60,
                "training_start_step":60
              },
              "memory":{
                "name":"Replay",
                "batch_size":60,
                "max_size":4000,
                "use_cer":true
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "clip_grad_val":1.0,
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.04,
                  "momentum":0.9
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            },
            {
              "copy_n":0
            },
            {
              "copy_n":0
            },
            {
              "name":"SupervisedLAPolicy",
              "algorithm":{
                "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
                "entropy_coef_spec":{
                  "name":"linear_decay",
                  "start_val":0.0,
                  "end_val":0.0,
                  "start_step":0,
                  "end_step":500
                },
                "training_frequency":1,
                "normalize_inputs":true,
                "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "loss_spec":{
                  "name":"CrossEntropyLoss",
                  "reduction":"none"
                },
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.40,
                  "momentum":0.000
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            }
          ]
        }
      },
      {
        "name":"LEExploiter",
        "memory":null,
        "net":null,
        "welfare_function":"default_welfare",
        "observing_other_agents":{
          "name":"FullyObservable"
        },
        "algorithm":{
          "name":"LEExploiter",
          "punishement_time":1,
          "min_coop_time":0,
          "defection_detection_mode":"spl_observed_actions",
          "defection_carac_threshold":0.0,
          "average_d_carac":true,
          "average_d_carac_len":20,
          "same_init_weights":false,
          "coop_net_ent_diff_as_lr":false,
          "use_sl_for_simu_coop":false,
          "use_strat_4":false,
          "use_strat_5":false,
          "strat_5_coeff":10.0,
          "use_strat_2":true,
          "length_of_history":200,
          "block_len":4,
          "use_last_steps_for_search":true,
          "use_bolzmann_search":true,
          "PERCENTILE_FOR_LIKELIHOOD_TEST":75,
          "meta_algo_memory":{
            "name":"Replay",
            "batch_size":1,
            "max_size":-1
          },
          "meta_algo_loss":{
            "reduction":"none",
            "name":"CrossEntropyLoss"
          },
          "contained_algorithms":[
            {
              "name":"DoubleDQN",
              "algorithm":{
                "name":"DoubleDQN",
                "action_pdtype":"Categorical",
                "action_policy":"boltzmann_on_cluster",
                "explore_var_spec":{
                  "name":"linear_decay",
                  "start_val":1.0,
                  "end_val":0.1,
                  "start_step":0,
                  "end_step":3000
                },
                "gamma":0.5,
                "normalize_inputs":true,
                "training_batch_iter":1,
                "training_iter":4,
                "training_frequency":60,
                "training_start_step":60
              },
              "memory":{
                "name":"Replay",
                "batch_size":60,
                "max_size":4000,
                "use_cer":true
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "clip_grad_val":1.0,
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.04,
                  "momentum":0.9
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            },
            {
              "copy_n":0
            },
            {
              "copy_n":0
            },
            {
              "name":"SupervisedLAPolicy",
              "algorithm":{
                "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
                "entropy_coef_spec":{
                  "name":"linear_decay",
                  "start_val":0.0,
                  "end_val":0.0,
                  "start_step":0,
                  "end_step":500
                },
                "training_frequency":1,
                "normalize_inputs":true,
                "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "loss_spec":{
                  "name":"CrossEntropyLoss",
                  "reduction":"none"
                },
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.40,
                  "momentum":0.000
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            }
          ]
        }
      }
    ],
    "env":[
      {
        "name":"IteratedPrisonersDilemma-v0",
        "max_t":null,
        "max_frame":4000,
        "num_envs":1
      }
    ],
    "body":{
      "product":"outer",
      "num":1
    },
    "meta":{
      "distributed":false,
      "eval_frequency":20,
      "log_frequency":20,
      "max_session":10,
      "max_concurrent_session":10,
      "max_trial":1
    }
  },
  "ipd_ipm_le_vs_exploiter_strat_2_temp_1_0.95_0.65":{
    "world":{
      "name":"DefaultMultiAgentWorld",
      "deterministic":false
    },
    "agent":[
      {
        "name":"LE",
        "memory":null,
        "net":null,
        "welfare_function":"utilitarian_welfare",
        "observing_other_agents":{
          "name":"FullyObservable"
        },
        "algorithm":{
          "name":"LE",
          "punishement_time":1,
          "min_coop_time":0,
          "defection_detection_mode":"spl_observed_actions",
          "defection_carac_threshold":0.0,
          "average_d_carac":true,
          "average_d_carac_len":20,
          "same_init_weights":false,
          "coop_net_ent_diff_as_lr":false,
          "use_sl_for_simu_coop":false,
          "use_strat_4":false,
          "use_strat_5":false,
          "strat_5_coeff":10.0,
          "use_strat_2":true,
          "length_of_history":200,
          "block_len":4,
          "use_last_steps_for_search":true,
          "use_bolzmann_search":true,
          "PERCENTILE_FOR_LIKELIHOOD_TEST":95,
          "meta_algo_memory":{
            "name":"Replay",
            "batch_size":1,
            "max_size":-1
          },
          "meta_algo_loss":{
            "reduction":"none",
            "name":"CrossEntropyLoss"
          },
          "contained_algorithms":[
            {
              "name":"DoubleDQN",
              "algorithm":{
                "name":"DoubleDQN",
                "action_pdtype":"Categorical",
                "action_policy":"boltzmann_on_cluster",
                "explore_var_spec":{
                  "name":"linear_decay",
                  "start_val":1.0,
                  "end_val":0.1,
                  "start_step":0,
                  "end_step":3000
                },
                "gamma":0.5,
                "normalize_inputs":true,
                "training_batch_iter":1,
                "training_iter":4,
                "training_frequency":60,
                "training_start_step":60
              },
              "memory":{
                "name":"Replay",
                "batch_size":60,
                "max_size":4000,
                "use_cer":true
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "clip_grad_val":1.0,
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.04,
                  "momentum":0.9
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            },
            {
              "copy_n":0
            },
            {
              "copy_n":0
            },
            {
              "name":"SupervisedLAPolicy",
              "algorithm":{
                "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
                "entropy_coef_spec":{
                  "name":"linear_decay",
                  "start_val":0.0,
                  "end_val":0.0,
                  "start_step":0,
                  "end_step":500
                },
                "training_frequency":1,
                "normalize_inputs":true,
                "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "loss_spec":{
                  "name":"CrossEntropyLoss",
                  "reduction":"none"
                },
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.40,
                  "momentum":0.000
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            }
          ]
        }
      },
      {
        "name":"LEExploiter",
        "memory":null,
        "net":null,
        "welfare_function":"default_welfare",
        "observing_other_agents":{
          "name":"FullyObservable"
        },
        "algorithm":{
          "name":"LEExploiter",
          "punishement_time":1,
          "min_coop_time":0,
          "defection_detection_mode":"spl_observed_actions",
          "defection_carac_threshold":0.0,
          "average_d_carac":true,
          "average_d_carac_len":20,
          "same_init_weights":false,
          "coop_net_ent_diff_as_lr":false,
          "use_sl_for_simu_coop":false,
          "use_strat_4":false,
          "use_strat_5":false,
          "strat_5_coeff":10.0,
          "use_strat_2":true,
          "length_of_history":200,
          "block_len":4,
          "use_last_steps_for_search":true,
          "use_bolzmann_search":true,
          "PERCENTILE_FOR_LIKELIHOOD_TEST":65,
          "meta_algo_memory":{
            "name":"Replay",
            "batch_size":1,
            "max_size":-1
          },
          "meta_algo_loss":{
            "reduction":"none",
            "name":"CrossEntropyLoss"
          },
          "contained_algorithms":[
            {
              "name":"DoubleDQN",
              "algorithm":{
                "name":"DoubleDQN",
                "action_pdtype":"Categorical",
                "action_policy":"boltzmann_on_cluster",
                "explore_var_spec":{
                  "name":"linear_decay",
                  "start_val":1.0,
                  "end_val":0.1,
                  "start_step":0,
                  "end_step":3000
                },
                "gamma":0.5,
                "normalize_inputs":true,
                "training_batch_iter":1,
                "training_iter":4,
                "training_frequency":60,
                "training_start_step":60
              },
              "memory":{
                "name":"Replay",
                "batch_size":60,
                "max_size":4000,
                "use_cer":true
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "clip_grad_val":1.0,
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.04,
                  "momentum":0.9
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            },
            {
              "copy_n":0
            },
            {
              "copy_n":0
            },
            {
              "name":"SupervisedLAPolicy",
              "algorithm":{
                "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
                "entropy_coef_spec":{
                  "name":"linear_decay",
                  "start_val":0.0,
                  "end_val":0.0,
                  "start_step":0,
                  "end_step":500
                },
                "training_frequency":1,
                "normalize_inputs":true,
                "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "loss_spec":{
                  "name":"CrossEntropyLoss",
                  "reduction":"none"
                },
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.40,
                  "momentum":0.000
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            }
          ]
        }
      }
    ],
    "env":[
      {
        "name":"IteratedPrisonersDilemma-v0",
        "max_t":null,
        "max_frame":4000,
        "num_envs":1
      }
    ],
    "body":{
      "product":"outer",
      "num":1
    },
    "meta":{
      "distributed":false,
      "eval_frequency":20,
      "log_frequency":20,
      "max_session":10,
      "max_concurrent_session":10,
      "max_trial":1
    }
  },
  "ipd_ipm_le_vs_exploiter_strat_2_temp_1_0.95_0.55":{
    "world":{
      "name":"DefaultMultiAgentWorld",
      "deterministic":false
    },
    "agent":[
      {
        "name":"LE",
        "memory":null,
        "net":null,
        "welfare_function":"utilitarian_welfare",
        "observing_other_agents":{
          "name":"FullyObservable"
        },
        "algorithm":{
          "name":"LE",
          "punishement_time":1,
          "min_coop_time":0,
          "defection_detection_mode":"spl_observed_actions",
          "defection_carac_threshold":0.0,
          "average_d_carac":true,
          "average_d_carac_len":20,
          "same_init_weights":false,
          "coop_net_ent_diff_as_lr":false,
          "use_sl_for_simu_coop":false,
          "use_strat_4":false,
          "use_strat_5":false,
          "strat_5_coeff":10.0,
          "use_strat_2":true,
          "length_of_history":200,
          "block_len":4,
          "use_last_steps_for_search":true,
          "use_bolzmann_search":true,
          "PERCENTILE_FOR_LIKELIHOOD_TEST":95,
          "meta_algo_memory":{
            "name":"Replay",
            "batch_size":1,
            "max_size":-1
          },
          "meta_algo_loss":{
            "reduction":"none",
            "name":"CrossEntropyLoss"
          },
          "contained_algorithms":[
            {
              "name":"DoubleDQN",
              "algorithm":{
                "name":"DoubleDQN",
                "action_pdtype":"Categorical",
                "action_policy":"boltzmann_on_cluster",
                "explore_var_spec":{
                  "name":"linear_decay",
                  "start_val":1.0,
                  "end_val":0.1,
                  "start_step":0,
                  "end_step":3000
                },
                "gamma":0.5,
                "normalize_inputs":true,
                "training_batch_iter":1,
                "training_iter":4,
                "training_frequency":60,
                "training_start_step":60
              },
              "memory":{
                "name":"Replay",
                "batch_size":60,
                "max_size":4000,
                "use_cer":true
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "clip_grad_val":1.0,
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.04,
                  "momentum":0.9
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            },
            {
              "copy_n":0
            },
            {
              "copy_n":0
            },
            {
              "name":"SupervisedLAPolicy",
              "algorithm":{
                "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
                "entropy_coef_spec":{
                  "name":"linear_decay",
                  "start_val":0.0,
                  "end_val":0.0,
                  "start_step":0,
                  "end_step":500
                },
                "training_frequency":1,
                "normalize_inputs":true,
                "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "loss_spec":{
                  "name":"CrossEntropyLoss",
                  "reduction":"none"
                },
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.40,
                  "momentum":0.000
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            }
          ]
        }
      },
      {
        "name":"LEExploiter",
        "memory":null,
        "net":null,
        "welfare_function":"default_welfare",
        "observing_other_agents":{
          "name":"FullyObservable"
        },
        "algorithm":{
          "name":"LEExploiter",
          "punishement_time":1,
          "min_coop_time":0,
          "defection_detection_mode":"spl_observed_actions",
          "defection_carac_threshold":0.0,
          "average_d_carac":true,
          "average_d_carac_len":20,
          "same_init_weights":false,
          "coop_net_ent_diff_as_lr":false,
          "use_sl_for_simu_coop":false,
          "use_strat_4":false,
          "use_strat_5":false,
          "strat_5_coeff":10.0,
          "use_strat_2":true,
          "length_of_history":200,
          "block_len":4,
          "use_last_steps_for_search":true,
          "use_bolzmann_search":true,
          "PERCENTILE_FOR_LIKELIHOOD_TEST":55,
          "meta_algo_memory":{
            "name":"Replay",
            "batch_size":1,
            "max_size":-1
          },
          "meta_algo_loss":{
            "reduction":"none",
            "name":"CrossEntropyLoss"
          },
          "contained_algorithms":[
            {
              "name":"DoubleDQN",
              "algorithm":{
                "name":"DoubleDQN",
                "action_pdtype":"Categorical",
                "action_policy":"boltzmann_on_cluster",
                "explore_var_spec":{
                  "name":"linear_decay",
                  "start_val":1.0,
                  "end_val":0.1,
                  "start_step":0,
                  "end_step":3000
                },
                "gamma":0.5,
                "normalize_inputs":true,
                "training_batch_iter":1,
                "training_iter":4,
                "training_frequency":60,
                "training_start_step":60
              },
              "memory":{
                "name":"Replay",
                "batch_size":60,
                "max_size":4000,
                "use_cer":true
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "clip_grad_val":1.0,
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.04,
                  "momentum":0.9
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            },
            {
              "copy_n":0
            },
            {
              "copy_n":0
            },
            {
              "name":"SupervisedLAPolicy",
              "algorithm":{
                "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
                "entropy_coef_spec":{
                  "name":"linear_decay",
                  "start_val":0.0,
                  "end_val":0.0,
                  "start_step":0,
                  "end_step":500
                },
                "training_frequency":1,
                "normalize_inputs":true,
                "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "loss_spec":{
                  "name":"CrossEntropyLoss",
                  "reduction":"none"
                },
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.40,
                  "momentum":0.000
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            }
          ]
        }
      }
    ],
    "env":[
      {
        "name":"IteratedPrisonersDilemma-v0",
        "max_t":null,
        "max_frame":4000,
        "num_envs":1
      }
    ],
    "body":{
      "product":"outer",
      "num":1
    },
    "meta":{
      "distributed":false,
      "eval_frequency":20,
      "log_frequency":20,
      "max_session":10,
      "max_concurrent_session":10,
      "max_trial":1
    }
  },

  "ipd_ipm_le_vs_exploiter_strat_2_temp_1_0.85_0.95":{
    "world":{
      "name":"DefaultMultiAgentWorld",
      "deterministic":false
    },
    "agent":[
      {
        "name":"LE",
        "memory":null,
        "net":null,
        "welfare_function":"utilitarian_welfare",
        "observing_other_agents":{
          "name":"FullyObservable"
        },
        "algorithm":{
          "name":"LE",
          "punishement_time":1,
          "min_coop_time":0,
          "defection_detection_mode":"spl_observed_actions",
          "defection_carac_threshold":0.0,
          "average_d_carac":true,
          "average_d_carac_len":20,
          "same_init_weights":false,
          "coop_net_ent_diff_as_lr":false,
          "use_sl_for_simu_coop":false,
          "use_strat_4":false,
          "use_strat_5":false,
          "strat_5_coeff":10.0,
          "use_strat_2":true,
          "length_of_history":200,
          "block_len":4,
          "use_last_steps_for_search":true,
          "use_bolzmann_search":true,
          "PERCENTILE_FOR_LIKELIHOOD_TEST":85,
          "meta_algo_memory":{
            "name":"Replay",
            "batch_size":1,
            "max_size":-1
          },
          "meta_algo_loss":{
            "reduction":"none",
            "name":"CrossEntropyLoss"
          },
          "contained_algorithms":[
            {
              "name":"DoubleDQN",
              "algorithm":{
                "name":"DoubleDQN",
                "action_pdtype":"Categorical",
                "action_policy":"boltzmann_on_cluster",
                "explore_var_spec":{
                  "name":"linear_decay",
                  "start_val":1.0,
                  "end_val":0.1,
                  "start_step":0,
                  "end_step":3000
                },
                "gamma":0.5,
                "normalize_inputs":true,
                "training_batch_iter":1,
                "training_iter":4,
                "training_frequency":60,
                "training_start_step":60
              },
              "memory":{
                "name":"Replay",
                "batch_size":60,
                "max_size":4000,
                "use_cer":true
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "clip_grad_val":1.0,
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.04,
                  "momentum":0.9
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            },
            {
              "copy_n":0
            },
            {
              "copy_n":0
            },
            {
              "name":"SupervisedLAPolicy",
              "algorithm":{
                "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
                "entropy_coef_spec":{
                  "name":"linear_decay",
                  "start_val":0.0,
                  "end_val":0.0,
                  "start_step":0,
                  "end_step":500
                },
                "training_frequency":1,
                "normalize_inputs":true,
                "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "loss_spec":{
                  "name":"CrossEntropyLoss",
                  "reduction":"none"
                },
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.40,
                  "momentum":0.000
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            }
          ]
        }
      },
      {
        "name":"LEExploiter",
        "memory":null,
        "net":null,
        "welfare_function":"default_welfare",
        "observing_other_agents":{
          "name":"FullyObservable"
        },
        "algorithm":{
          "name":"LEExploiter",
          "punishement_time":1,
          "min_coop_time":0,
          "defection_detection_mode":"spl_observed_actions",
          "defection_carac_threshold":0.0,
          "average_d_carac":true,
          "average_d_carac_len":20,
          "same_init_weights":false,
          "coop_net_ent_diff_as_lr":false,
          "use_sl_for_simu_coop":false,
          "use_strat_4":false,
          "use_strat_5":false,
          "strat_5_coeff":10.0,
          "use_strat_2":true,
          "length_of_history":200,
          "block_len":4,
          "use_last_steps_for_search":true,
          "use_bolzmann_search":true,
          "PERCENTILE_FOR_LIKELIHOOD_TEST":95,
          "meta_algo_memory":{
            "name":"Replay",
            "batch_size":1,
            "max_size":-1
          },
          "meta_algo_loss":{
            "reduction":"none",
            "name":"CrossEntropyLoss"
          },
          "contained_algorithms":[
            {
              "name":"DoubleDQN",
              "algorithm":{
                "name":"DoubleDQN",
                "action_pdtype":"Categorical",
                "action_policy":"boltzmann_on_cluster",
                "explore_var_spec":{
                  "name":"linear_decay",
                  "start_val":1.0,
                  "end_val":0.1,
                  "start_step":0,
                  "end_step":3000
                },
                "gamma":0.5,
                "normalize_inputs":true,
                "training_batch_iter":1,
                "training_iter":4,
                "training_frequency":60,
                "training_start_step":60
              },
              "memory":{
                "name":"Replay",
                "batch_size":60,
                "max_size":4000,
                "use_cer":true
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "clip_grad_val":1.0,
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.04,
                  "momentum":0.9
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            },
            {
              "copy_n":0
            },
            {
              "copy_n":0
            },
            {
              "name":"SupervisedLAPolicy",
              "algorithm":{
                "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
                "entropy_coef_spec":{
                  "name":"linear_decay",
                  "start_val":0.0,
                  "end_val":0.0,
                  "start_step":0,
                  "end_step":500
                },
                "training_frequency":1,
                "normalize_inputs":true,
                "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "loss_spec":{
                  "name":"CrossEntropyLoss",
                  "reduction":"none"
                },
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.40,
                  "momentum":0.000
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            }
          ]
        }
      }
    ],
    "env":[
      {
        "name":"IteratedPrisonersDilemma-v0",
        "max_t":null,
        "max_frame":4000,
        "num_envs":1
      }
    ],
    "body":{
      "product":"outer",
      "num":1
    },
    "meta":{
      "distributed":false,
      "eval_frequency":20,
      "log_frequency":20,
      "max_session":10,
      "max_concurrent_session":10,
      "max_trial":1
    }
  },
  "ipd_ipm_le_vs_exploiter_strat_2_temp_1_0.85_0.85":{
    "world":{
      "name":"DefaultMultiAgentWorld",
      "deterministic":false
    },
    "agent":[
      {
        "name":"LE",
        "memory":null,
        "net":null,
        "welfare_function":"utilitarian_welfare",
        "observing_other_agents":{
          "name":"FullyObservable"
        },
        "algorithm":{
          "name":"LE",
          "punishement_time":1,
          "min_coop_time":0,
          "defection_detection_mode":"spl_observed_actions",
          "defection_carac_threshold":0.0,
          "average_d_carac":true,
          "average_d_carac_len":20,
          "same_init_weights":false,
          "coop_net_ent_diff_as_lr":false,
          "use_sl_for_simu_coop":false,
          "use_strat_4":false,
          "use_strat_5":false,
          "strat_5_coeff":10.0,
          "use_strat_2":true,
          "length_of_history":200,
          "block_len":4,
          "use_last_steps_for_search":true,
          "use_bolzmann_search":true,
          "PERCENTILE_FOR_LIKELIHOOD_TEST":85,
          "meta_algo_memory":{
            "name":"Replay",
            "batch_size":1,
            "max_size":-1
          },
          "meta_algo_loss":{
            "reduction":"none",
            "name":"CrossEntropyLoss"
          },
          "contained_algorithms":[
            {
              "name":"DoubleDQN",
              "algorithm":{
                "name":"DoubleDQN",
                "action_pdtype":"Categorical",
                "action_policy":"boltzmann_on_cluster",
                "explore_var_spec":{
                  "name":"linear_decay",
                  "start_val":1.0,
                  "end_val":0.1,
                  "start_step":0,
                  "end_step":3000
                },
                "gamma":0.5,
                "normalize_inputs":true,
                "training_batch_iter":1,
                "training_iter":4,
                "training_frequency":60,
                "training_start_step":60
              },
              "memory":{
                "name":"Replay",
                "batch_size":60,
                "max_size":4000,
                "use_cer":true
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "clip_grad_val":1.0,
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.04,
                  "momentum":0.9
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            },
            {
              "copy_n":0
            },
            {
              "copy_n":0
            },
            {
              "name":"SupervisedLAPolicy",
              "algorithm":{
                "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
                "entropy_coef_spec":{
                  "name":"linear_decay",
                  "start_val":0.0,
                  "end_val":0.0,
                  "start_step":0,
                  "end_step":500
                },
                "training_frequency":1,
                "normalize_inputs":true,
                "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "loss_spec":{
                  "name":"CrossEntropyLoss",
                  "reduction":"none"
                },
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.40,
                  "momentum":0.000
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            }
          ]
        }
      },
      {
        "name":"LEExploiter",
        "memory":null,
        "net":null,
        "welfare_function":"default_welfare",
        "observing_other_agents":{
          "name":"FullyObservable"
        },
        "algorithm":{
          "name":"LEExploiter",
          "punishement_time":1,
          "min_coop_time":0,
          "defection_detection_mode":"spl_observed_actions",
          "defection_carac_threshold":0.0,
          "average_d_carac":true,
          "average_d_carac_len":20,
          "same_init_weights":false,
          "coop_net_ent_diff_as_lr":false,
          "use_sl_for_simu_coop":false,
          "use_strat_4":false,
          "use_strat_5":false,
          "strat_5_coeff":10.0,
          "use_strat_2":true,
          "length_of_history":200,
          "block_len":4,
          "use_last_steps_for_search":true,
          "use_bolzmann_search":true,
          "PERCENTILE_FOR_LIKELIHOOD_TEST":85,
          "meta_algo_memory":{
            "name":"Replay",
            "batch_size":1,
            "max_size":-1
          },
          "meta_algo_loss":{
            "reduction":"none",
            "name":"CrossEntropyLoss"
          },
          "contained_algorithms":[
            {
              "name":"DoubleDQN",
              "algorithm":{
                "name":"DoubleDQN",
                "action_pdtype":"Categorical",
                "action_policy":"boltzmann_on_cluster",
                "explore_var_spec":{
                  "name":"linear_decay",
                  "start_val":1.0,
                  "end_val":0.1,
                  "start_step":0,
                  "end_step":3000
                },
                "gamma":0.5,
                "normalize_inputs":true,
                "training_batch_iter":1,
                "training_iter":4,
                "training_frequency":60,
                "training_start_step":60
              },
              "memory":{
                "name":"Replay",
                "batch_size":60,
                "max_size":4000,
                "use_cer":true
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "clip_grad_val":1.0,
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.04,
                  "momentum":0.9
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            },
            {
              "copy_n":0
            },
            {
              "copy_n":0
            },
            {
              "name":"SupervisedLAPolicy",
              "algorithm":{
                "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
                "entropy_coef_spec":{
                  "name":"linear_decay",
                  "start_val":0.0,
                  "end_val":0.0,
                  "start_step":0,
                  "end_step":500
                },
                "training_frequency":1,
                "normalize_inputs":true,
                "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "loss_spec":{
                  "name":"CrossEntropyLoss",
                  "reduction":"none"
                },
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.40,
                  "momentum":0.000
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            }
          ]
        }
      }
    ],
    "env":[
      {
        "name":"IteratedPrisonersDilemma-v0",
        "max_t":null,
        "max_frame":4000,
        "num_envs":1
      }
    ],
    "body":{
      "product":"outer",
      "num":1
    },
    "meta":{
      "distributed":false,
      "eval_frequency":20,
      "log_frequency":20,
      "max_session":10,
      "max_concurrent_session":10,
      "max_trial":1
    }
  },
  "ipd_ipm_le_vs_exploiter_strat_2_temp_1_0.85_0.75":{
    "world":{
      "name":"DefaultMultiAgentWorld",
      "deterministic":false
    },
    "agent":[
      {
        "name":"LE",
        "memory":null,
        "net":null,
        "welfare_function":"utilitarian_welfare",
        "observing_other_agents":{
          "name":"FullyObservable"
        },
        "algorithm":{
          "name":"LE",
          "punishement_time":1,
          "min_coop_time":0,
          "defection_detection_mode":"spl_observed_actions",
          "defection_carac_threshold":0.0,
          "average_d_carac":true,
          "average_d_carac_len":20,
          "same_init_weights":false,
          "coop_net_ent_diff_as_lr":false,
          "use_sl_for_simu_coop":false,
          "use_strat_4":false,
          "use_strat_5":false,
          "strat_5_coeff":10.0,
          "use_strat_2":true,
          "length_of_history":200,
          "block_len":4,
          "use_last_steps_for_search":true,
          "use_bolzmann_search":true,
          "PERCENTILE_FOR_LIKELIHOOD_TEST":85,
          "meta_algo_memory":{
            "name":"Replay",
            "batch_size":1,
            "max_size":-1
          },
          "meta_algo_loss":{
            "reduction":"none",
            "name":"CrossEntropyLoss"
          },
          "contained_algorithms":[
            {
              "name":"DoubleDQN",
              "algorithm":{
                "name":"DoubleDQN",
                "action_pdtype":"Categorical",
                "action_policy":"boltzmann_on_cluster",
                "explore_var_spec":{
                  "name":"linear_decay",
                  "start_val":1.0,
                  "end_val":0.1,
                  "start_step":0,
                  "end_step":3000
                },
                "gamma":0.5,
                "normalize_inputs":true,
                "training_batch_iter":1,
                "training_iter":4,
                "training_frequency":60,
                "training_start_step":60
              },
              "memory":{
                "name":"Replay",
                "batch_size":60,
                "max_size":4000,
                "use_cer":true
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "clip_grad_val":1.0,
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.04,
                  "momentum":0.9
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            },
            {
              "copy_n":0
            },
            {
              "copy_n":0
            },
            {
              "name":"SupervisedLAPolicy",
              "algorithm":{
                "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
                "entropy_coef_spec":{
                  "name":"linear_decay",
                  "start_val":0.0,
                  "end_val":0.0,
                  "start_step":0,
                  "end_step":500
                },
                "training_frequency":1,
                "normalize_inputs":true,
                "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "loss_spec":{
                  "name":"CrossEntropyLoss",
                  "reduction":"none"
                },
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.40,
                  "momentum":0.000
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            }
          ]
        }
      },
      {
        "name":"LEExploiter",
        "memory":null,
        "net":null,
        "welfare_function":"default_welfare",
        "observing_other_agents":{
          "name":"FullyObservable"
        },
        "algorithm":{
          "name":"LEExploiter",
          "punishement_time":1,
          "min_coop_time":0,
          "defection_detection_mode":"spl_observed_actions",
          "defection_carac_threshold":0.0,
          "average_d_carac":true,
          "average_d_carac_len":20,
          "same_init_weights":false,
          "coop_net_ent_diff_as_lr":false,
          "use_sl_for_simu_coop":false,
          "use_strat_4":false,
          "use_strat_5":false,
          "strat_5_coeff":10.0,
          "use_strat_2":true,
          "length_of_history":200,
          "block_len":4,
          "use_last_steps_for_search":true,
          "use_bolzmann_search":true,
          "PERCENTILE_FOR_LIKELIHOOD_TEST":75,
          "meta_algo_memory":{
            "name":"Replay",
            "batch_size":1,
            "max_size":-1
          },
          "meta_algo_loss":{
            "reduction":"none",
            "name":"CrossEntropyLoss"
          },
          "contained_algorithms":[
            {
              "name":"DoubleDQN",
              "algorithm":{
                "name":"DoubleDQN",
                "action_pdtype":"Categorical",
                "action_policy":"boltzmann_on_cluster",
                "explore_var_spec":{
                  "name":"linear_decay",
                  "start_val":1.0,
                  "end_val":0.1,
                  "start_step":0,
                  "end_step":3000
                },
                "gamma":0.5,
                "normalize_inputs":true,
                "training_batch_iter":1,
                "training_iter":4,
                "training_frequency":60,
                "training_start_step":60
              },
              "memory":{
                "name":"Replay",
                "batch_size":60,
                "max_size":4000,
                "use_cer":true
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "clip_grad_val":1.0,
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.04,
                  "momentum":0.9
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            },
            {
              "copy_n":0
            },
            {
              "copy_n":0
            },
            {
              "name":"SupervisedLAPolicy",
              "algorithm":{
                "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
                "entropy_coef_spec":{
                  "name":"linear_decay",
                  "start_val":0.0,
                  "end_val":0.0,
                  "start_step":0,
                  "end_step":500
                },
                "training_frequency":1,
                "normalize_inputs":true,
                "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "loss_spec":{
                  "name":"CrossEntropyLoss",
                  "reduction":"none"
                },
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.40,
                  "momentum":0.000
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            }
          ]
        }
      }
    ],
    "env":[
      {
        "name":"IteratedPrisonersDilemma-v0",
        "max_t":null,
        "max_frame":4000,
        "num_envs":1
      }
    ],
    "body":{
      "product":"outer",
      "num":1
    },
    "meta":{
      "distributed":false,
      "eval_frequency":20,
      "log_frequency":20,
      "max_session":10,
      "max_concurrent_session":10,
      "max_trial":1
    }
  },
  "ipd_ipm_le_vs_exploiter_strat_2_temp_1_0.85_0.65":{
    "world":{
      "name":"DefaultMultiAgentWorld",
      "deterministic":false
    },
    "agent":[
      {
        "name":"LE",
        "memory":null,
        "net":null,
        "welfare_function":"utilitarian_welfare",
        "observing_other_agents":{
          "name":"FullyObservable"
        },
        "algorithm":{
          "name":"LE",
          "punishement_time":1,
          "min_coop_time":0,
          "defection_detection_mode":"spl_observed_actions",
          "defection_carac_threshold":0.0,
          "average_d_carac":true,
          "average_d_carac_len":20,
          "same_init_weights":false,
          "coop_net_ent_diff_as_lr":false,
          "use_sl_for_simu_coop":false,
          "use_strat_4":false,
          "use_strat_5":false,
          "strat_5_coeff":10.0,
          "use_strat_2":true,
          "length_of_history":200,
          "block_len":4,
          "use_last_steps_for_search":true,
          "use_bolzmann_search":true,
          "PERCENTILE_FOR_LIKELIHOOD_TEST":85,
          "meta_algo_memory":{
            "name":"Replay",
            "batch_size":1,
            "max_size":-1
          },
          "meta_algo_loss":{
            "reduction":"none",
            "name":"CrossEntropyLoss"
          },
          "contained_algorithms":[
            {
              "name":"DoubleDQN",
              "algorithm":{
                "name":"DoubleDQN",
                "action_pdtype":"Categorical",
                "action_policy":"boltzmann_on_cluster",
                "explore_var_spec":{
                  "name":"linear_decay",
                  "start_val":1.0,
                  "end_val":0.1,
                  "start_step":0,
                  "end_step":3000
                },
                "gamma":0.5,
                "normalize_inputs":true,
                "training_batch_iter":1,
                "training_iter":4,
                "training_frequency":60,
                "training_start_step":60
              },
              "memory":{
                "name":"Replay",
                "batch_size":60,
                "max_size":4000,
                "use_cer":true
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "clip_grad_val":1.0,
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.04,
                  "momentum":0.9
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            },
            {
              "copy_n":0
            },
            {
              "copy_n":0
            },
            {
              "name":"SupervisedLAPolicy",
              "algorithm":{
                "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
                "entropy_coef_spec":{
                  "name":"linear_decay",
                  "start_val":0.0,
                  "end_val":0.0,
                  "start_step":0,
                  "end_step":500
                },
                "training_frequency":1,
                "normalize_inputs":true,
                "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "loss_spec":{
                  "name":"CrossEntropyLoss",
                  "reduction":"none"
                },
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.40,
                  "momentum":0.000
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            }
          ]
        }
      },
      {
        "name":"LEExploiter",
        "memory":null,
        "net":null,
        "welfare_function":"default_welfare",
        "observing_other_agents":{
          "name":"FullyObservable"
        },
        "algorithm":{
          "name":"LEExploiter",
          "punishement_time":1,
          "min_coop_time":0,
          "defection_detection_mode":"spl_observed_actions",
          "defection_carac_threshold":0.0,
          "average_d_carac":true,
          "average_d_carac_len":20,
          "same_init_weights":false,
          "coop_net_ent_diff_as_lr":false,
          "use_sl_for_simu_coop":false,
          "use_strat_4":false,
          "use_strat_5":false,
          "strat_5_coeff":10.0,
          "use_strat_2":true,
          "length_of_history":200,
          "block_len":4,
          "use_last_steps_for_search":true,
          "use_bolzmann_search":true,
          "PERCENTILE_FOR_LIKELIHOOD_TEST":65,
          "meta_algo_memory":{
            "name":"Replay",
            "batch_size":1,
            "max_size":-1
          },
          "meta_algo_loss":{
            "reduction":"none",
            "name":"CrossEntropyLoss"
          },
          "contained_algorithms":[
            {
              "name":"DoubleDQN",
              "algorithm":{
                "name":"DoubleDQN",
                "action_pdtype":"Categorical",
                "action_policy":"boltzmann_on_cluster",
                "explore_var_spec":{
                  "name":"linear_decay",
                  "start_val":1.0,
                  "end_val":0.1,
                  "start_step":0,
                  "end_step":3000
                },
                "gamma":0.5,
                "normalize_inputs":true,
                "training_batch_iter":1,
                "training_iter":4,
                "training_frequency":60,
                "training_start_step":60
              },
              "memory":{
                "name":"Replay",
                "batch_size":60,
                "max_size":4000,
                "use_cer":true
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "clip_grad_val":1.0,
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.04,
                  "momentum":0.9
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            },
            {
              "copy_n":0
            },
            {
              "copy_n":0
            },
            {
              "name":"SupervisedLAPolicy",
              "algorithm":{
                "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
                "entropy_coef_spec":{
                  "name":"linear_decay",
                  "start_val":0.0,
                  "end_val":0.0,
                  "start_step":0,
                  "end_step":500
                },
                "training_frequency":1,
                "normalize_inputs":true,
                "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "loss_spec":{
                  "name":"CrossEntropyLoss",
                  "reduction":"none"
                },
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.40,
                  "momentum":0.000
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            }
          ]
        }
      }
    ],
    "env":[
      {
        "name":"IteratedPrisonersDilemma-v0",
        "max_t":null,
        "max_frame":4000,
        "num_envs":1
      }
    ],
    "body":{
      "product":"outer",
      "num":1
    },
    "meta":{
      "distributed":false,
      "eval_frequency":20,
      "log_frequency":20,
      "max_session":10,
      "max_concurrent_session":10,
      "max_trial":1
    }
  },
  "ipd_ipm_le_vs_exploiter_strat_2_temp_1_0.85_0.55":{
    "world":{
      "name":"DefaultMultiAgentWorld",
      "deterministic":false
    },
    "agent":[
      {
        "name":"LE",
        "memory":null,
        "net":null,
        "welfare_function":"utilitarian_welfare",
        "observing_other_agents":{
          "name":"FullyObservable"
        },
        "algorithm":{
          "name":"LE",
          "punishement_time":1,
          "min_coop_time":0,
          "defection_detection_mode":"spl_observed_actions",
          "defection_carac_threshold":0.0,
          "average_d_carac":true,
          "average_d_carac_len":20,
          "same_init_weights":false,
          "coop_net_ent_diff_as_lr":false,
          "use_sl_for_simu_coop":false,
          "use_strat_4":false,
          "use_strat_5":false,
          "strat_5_coeff":10.0,
          "use_strat_2":true,
          "length_of_history":200,
          "block_len":4,
          "use_last_steps_for_search":true,
          "use_bolzmann_search":true,
          "PERCENTILE_FOR_LIKELIHOOD_TEST":85,
          "meta_algo_memory":{
            "name":"Replay",
            "batch_size":1,
            "max_size":-1
          },
          "meta_algo_loss":{
            "reduction":"none",
            "name":"CrossEntropyLoss"
          },
          "contained_algorithms":[
            {
              "name":"DoubleDQN",
              "algorithm":{
                "name":"DoubleDQN",
                "action_pdtype":"Categorical",
                "action_policy":"boltzmann_on_cluster",
                "explore_var_spec":{
                  "name":"linear_decay",
                  "start_val":1.0,
                  "end_val":0.1,
                  "start_step":0,
                  "end_step":3000
                },
                "gamma":0.5,
                "normalize_inputs":true,
                "training_batch_iter":1,
                "training_iter":4,
                "training_frequency":60,
                "training_start_step":60
              },
              "memory":{
                "name":"Replay",
                "batch_size":60,
                "max_size":4000,
                "use_cer":true
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "clip_grad_val":1.0,
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.04,
                  "momentum":0.9
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            },
            {
              "copy_n":0
            },
            {
              "copy_n":0
            },
            {
              "name":"SupervisedLAPolicy",
              "algorithm":{
                "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
                "entropy_coef_spec":{
                  "name":"linear_decay",
                  "start_val":0.0,
                  "end_val":0.0,
                  "start_step":0,
                  "end_step":500
                },
                "training_frequency":1,
                "normalize_inputs":true,
                "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "loss_spec":{
                  "name":"CrossEntropyLoss",
                  "reduction":"none"
                },
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.40,
                  "momentum":0.000
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            }
          ]
        }
      },
      {
        "name":"LEExploiter",
        "memory":null,
        "net":null,
        "welfare_function":"default_welfare",
        "observing_other_agents":{
          "name":"FullyObservable"
        },
        "algorithm":{
          "name":"LEExploiter",
          "punishement_time":1,
          "min_coop_time":0,
          "defection_detection_mode":"spl_observed_actions",
          "defection_carac_threshold":0.0,
          "average_d_carac":true,
          "average_d_carac_len":20,
          "same_init_weights":false,
          "coop_net_ent_diff_as_lr":false,
          "use_sl_for_simu_coop":false,
          "use_strat_4":false,
          "use_strat_5":false,
          "strat_5_coeff":10.0,
          "use_strat_2":true,
          "length_of_history":200,
          "block_len":4,
          "use_last_steps_for_search":true,
          "use_bolzmann_search":true,
          "PERCENTILE_FOR_LIKELIHOOD_TEST":55,
          "meta_algo_memory":{
            "name":"Replay",
            "batch_size":1,
            "max_size":-1
          },
          "meta_algo_loss":{
            "reduction":"none",
            "name":"CrossEntropyLoss"
          },
          "contained_algorithms":[
            {
              "name":"DoubleDQN",
              "algorithm":{
                "name":"DoubleDQN",
                "action_pdtype":"Categorical",
                "action_policy":"boltzmann_on_cluster",
                "explore_var_spec":{
                  "name":"linear_decay",
                  "start_val":1.0,
                  "end_val":0.1,
                  "start_step":0,
                  "end_step":3000
                },
                "gamma":0.5,
                "normalize_inputs":true,
                "training_batch_iter":1,
                "training_iter":4,
                "training_frequency":60,
                "training_start_step":60
              },
              "memory":{
                "name":"Replay",
                "batch_size":60,
                "max_size":4000,
                "use_cer":true
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "clip_grad_val":1.0,
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.04,
                  "momentum":0.9
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            },
            {
              "copy_n":0
            },
            {
              "copy_n":0
            },
            {
              "name":"SupervisedLAPolicy",
              "algorithm":{
                "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
                "entropy_coef_spec":{
                  "name":"linear_decay",
                  "start_val":0.0,
                  "end_val":0.0,
                  "start_step":0,
                  "end_step":500
                },
                "training_frequency":1,
                "normalize_inputs":true,
                "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "loss_spec":{
                  "name":"CrossEntropyLoss",
                  "reduction":"none"
                },
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.40,
                  "momentum":0.000
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            }
          ]
        }
      }
    ],
    "env":[
      {
        "name":"IteratedPrisonersDilemma-v0",
        "max_t":null,
        "max_frame":4000,
        "num_envs":1
      }
    ],
    "body":{
      "product":"outer",
      "num":1
    },
    "meta":{
      "distributed":false,
      "eval_frequency":20,
      "log_frequency":20,
      "max_session":10,
      "max_concurrent_session":10,
      "max_trial":1
    }
  },

  "ipd_ipm_le_vs_exploiter_strat_2_temp_1_0.75_0.95":{
    "world":{
      "name":"DefaultMultiAgentWorld",
      "deterministic":false
    },
    "agent":[
      {
        "name":"LE",
        "memory":null,
        "net":null,
        "welfare_function":"utilitarian_welfare",
        "observing_other_agents":{
          "name":"FullyObservable"
        },
        "algorithm":{
          "name":"LE",
          "punishement_time":1,
          "min_coop_time":0,
          "defection_detection_mode":"spl_observed_actions",
          "defection_carac_threshold":0.0,
          "average_d_carac":true,
          "average_d_carac_len":20,
          "same_init_weights":false,
          "coop_net_ent_diff_as_lr":false,
          "use_sl_for_simu_coop":false,
          "use_strat_4":false,
          "use_strat_5":false,
          "strat_5_coeff":10.0,
          "use_strat_2":true,
          "length_of_history":200,
          "block_len":4,
          "use_last_steps_for_search":true,
          "use_bolzmann_search":true,
          "PERCENTILE_FOR_LIKELIHOOD_TEST":75,
          "meta_algo_memory":{
            "name":"Replay",
            "batch_size":1,
            "max_size":-1
          },
          "meta_algo_loss":{
            "reduction":"none",
            "name":"CrossEntropyLoss"
          },
          "contained_algorithms":[
            {
              "name":"DoubleDQN",
              "algorithm":{
                "name":"DoubleDQN",
                "action_pdtype":"Categorical",
                "action_policy":"boltzmann_on_cluster",
                "explore_var_spec":{
                  "name":"linear_decay",
                  "start_val":1.0,
                  "end_val":0.1,
                  "start_step":0,
                  "end_step":3000
                },
                "gamma":0.5,
                "normalize_inputs":true,
                "training_batch_iter":1,
                "training_iter":4,
                "training_frequency":60,
                "training_start_step":60
              },
              "memory":{
                "name":"Replay",
                "batch_size":60,
                "max_size":4000,
                "use_cer":true
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "clip_grad_val":1.0,
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.04,
                  "momentum":0.9
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            },
            {
              "copy_n":0
            },
            {
              "copy_n":0
            },
            {
              "name":"SupervisedLAPolicy",
              "algorithm":{
                "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
                "entropy_coef_spec":{
                  "name":"linear_decay",
                  "start_val":0.0,
                  "end_val":0.0,
                  "start_step":0,
                  "end_step":500
                },
                "training_frequency":1,
                "normalize_inputs":true,
                "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "loss_spec":{
                  "name":"CrossEntropyLoss",
                  "reduction":"none"
                },
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.40,
                  "momentum":0.000
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            }
          ]
        }
      },
      {
        "name":"LEExploiter",
        "memory":null,
        "net":null,
        "welfare_function":"default_welfare",
        "observing_other_agents":{
          "name":"FullyObservable"
        },
        "algorithm":{
          "name":"LEExploiter",
          "punishement_time":1,
          "min_coop_time":0,
          "defection_detection_mode":"spl_observed_actions",
          "defection_carac_threshold":0.0,
          "average_d_carac":true,
          "average_d_carac_len":20,
          "same_init_weights":false,
          "coop_net_ent_diff_as_lr":false,
          "use_sl_for_simu_coop":false,
          "use_strat_4":false,
          "use_strat_5":false,
          "strat_5_coeff":10.0,
          "use_strat_2":true,
          "length_of_history":200,
          "block_len":4,
          "use_last_steps_for_search":true,
          "use_bolzmann_search":true,
          "PERCENTILE_FOR_LIKELIHOOD_TEST":95,
          "meta_algo_memory":{
            "name":"Replay",
            "batch_size":1,
            "max_size":-1
          },
          "meta_algo_loss":{
            "reduction":"none",
            "name":"CrossEntropyLoss"
          },
          "contained_algorithms":[
            {
              "name":"DoubleDQN",
              "algorithm":{
                "name":"DoubleDQN",
                "action_pdtype":"Categorical",
                "action_policy":"boltzmann_on_cluster",
                "explore_var_spec":{
                  "name":"linear_decay",
                  "start_val":1.0,
                  "end_val":0.1,
                  "start_step":0,
                  "end_step":3000
                },
                "gamma":0.5,
                "normalize_inputs":true,
                "training_batch_iter":1,
                "training_iter":4,
                "training_frequency":60,
                "training_start_step":60
              },
              "memory":{
                "name":"Replay",
                "batch_size":60,
                "max_size":4000,
                "use_cer":true
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "clip_grad_val":1.0,
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.04,
                  "momentum":0.9
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            },
            {
              "copy_n":0
            },
            {
              "copy_n":0
            },
            {
              "name":"SupervisedLAPolicy",
              "algorithm":{
                "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
                "entropy_coef_spec":{
                  "name":"linear_decay",
                  "start_val":0.0,
                  "end_val":0.0,
                  "start_step":0,
                  "end_step":500
                },
                "training_frequency":1,
                "normalize_inputs":true,
                "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "loss_spec":{
                  "name":"CrossEntropyLoss",
                  "reduction":"none"
                },
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.40,
                  "momentum":0.000
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            }
          ]
        }
      }
    ],
    "env":[
      {
        "name":"IteratedPrisonersDilemma-v0",
        "max_t":null,
        "max_frame":4000,
        "num_envs":1
      }
    ],
    "body":{
      "product":"outer",
      "num":1
    },
    "meta":{
      "distributed":false,
      "eval_frequency":20,
      "log_frequency":20,
      "max_session":10,
      "max_concurrent_session":10,
      "max_trial":1
    }
  },
  "ipd_ipm_le_vs_exploiter_strat_2_temp_1_0.75_0.85":{
    "world":{
      "name":"DefaultMultiAgentWorld",
      "deterministic":false
    },
    "agent":[
      {
        "name":"LE",
        "memory":null,
        "net":null,
        "welfare_function":"utilitarian_welfare",
        "observing_other_agents":{
          "name":"FullyObservable"
        },
        "algorithm":{
          "name":"LE",
          "punishement_time":1,
          "min_coop_time":0,
          "defection_detection_mode":"spl_observed_actions",
          "defection_carac_threshold":0.0,
          "average_d_carac":true,
          "average_d_carac_len":20,
          "same_init_weights":false,
          "coop_net_ent_diff_as_lr":false,
          "use_sl_for_simu_coop":false,
          "use_strat_4":false,
          "use_strat_5":false,
          "strat_5_coeff":10.0,
          "use_strat_2":true,
          "length_of_history":200,
          "block_len":4,
          "use_last_steps_for_search":true,
          "use_bolzmann_search":true,
          "PERCENTILE_FOR_LIKELIHOOD_TEST":75,
          "meta_algo_memory":{
            "name":"Replay",
            "batch_size":1,
            "max_size":-1
          },
          "meta_algo_loss":{
            "reduction":"none",
            "name":"CrossEntropyLoss"
          },
          "contained_algorithms":[
            {
              "name":"DoubleDQN",
              "algorithm":{
                "name":"DoubleDQN",
                "action_pdtype":"Categorical",
                "action_policy":"boltzmann_on_cluster",
                "explore_var_spec":{
                  "name":"linear_decay",
                  "start_val":1.0,
                  "end_val":0.1,
                  "start_step":0,
                  "end_step":3000
                },
                "gamma":0.5,
                "normalize_inputs":true,
                "training_batch_iter":1,
                "training_iter":4,
                "training_frequency":60,
                "training_start_step":60
              },
              "memory":{
                "name":"Replay",
                "batch_size":60,
                "max_size":4000,
                "use_cer":true
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "clip_grad_val":1.0,
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.04,
                  "momentum":0.9
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            },
            {
              "copy_n":0
            },
            {
              "copy_n":0
            },
            {
              "name":"SupervisedLAPolicy",
              "algorithm":{
                "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
                "entropy_coef_spec":{
                  "name":"linear_decay",
                  "start_val":0.0,
                  "end_val":0.0,
                  "start_step":0,
                  "end_step":500
                },
                "training_frequency":1,
                "normalize_inputs":true,
                "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "loss_spec":{
                  "name":"CrossEntropyLoss",
                  "reduction":"none"
                },
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.40,
                  "momentum":0.000
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            }
          ]
        }
      },
      {
        "name":"LEExploiter",
        "memory":null,
        "net":null,
        "welfare_function":"default_welfare",
        "observing_other_agents":{
          "name":"FullyObservable"
        },
        "algorithm":{
          "name":"LEExploiter",
          "punishement_time":1,
          "min_coop_time":0,
          "defection_detection_mode":"spl_observed_actions",
          "defection_carac_threshold":0.0,
          "average_d_carac":true,
          "average_d_carac_len":20,
          "same_init_weights":false,
          "coop_net_ent_diff_as_lr":false,
          "use_sl_for_simu_coop":false,
          "use_strat_4":false,
          "use_strat_5":false,
          "strat_5_coeff":10.0,
          "use_strat_2":true,
          "length_of_history":200,
          "block_len":4,
          "use_last_steps_for_search":true,
          "use_bolzmann_search":true,
          "PERCENTILE_FOR_LIKELIHOOD_TEST":85,
          "meta_algo_memory":{
            "name":"Replay",
            "batch_size":1,
            "max_size":-1
          },
          "meta_algo_loss":{
            "reduction":"none",
            "name":"CrossEntropyLoss"
          },
          "contained_algorithms":[
            {
              "name":"DoubleDQN",
              "algorithm":{
                "name":"DoubleDQN",
                "action_pdtype":"Categorical",
                "action_policy":"boltzmann_on_cluster",
                "explore_var_spec":{
                  "name":"linear_decay",
                  "start_val":1.0,
                  "end_val":0.1,
                  "start_step":0,
                  "end_step":3000
                },
                "gamma":0.5,
                "normalize_inputs":true,
                "training_batch_iter":1,
                "training_iter":4,
                "training_frequency":60,
                "training_start_step":60
              },
              "memory":{
                "name":"Replay",
                "batch_size":60,
                "max_size":4000,
                "use_cer":true
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "clip_grad_val":1.0,
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.04,
                  "momentum":0.9
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            },
            {
              "copy_n":0
            },
            {
              "copy_n":0
            },
            {
              "name":"SupervisedLAPolicy",
              "algorithm":{
                "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
                "entropy_coef_spec":{
                  "name":"linear_decay",
                  "start_val":0.0,
                  "end_val":0.0,
                  "start_step":0,
                  "end_step":500
                },
                "training_frequency":1,
                "normalize_inputs":true,
                "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "loss_spec":{
                  "name":"CrossEntropyLoss",
                  "reduction":"none"
                },
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.40,
                  "momentum":0.000
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            }
          ]
        }
      }
    ],
    "env":[
      {
        "name":"IteratedPrisonersDilemma-v0",
        "max_t":null,
        "max_frame":4000,
        "num_envs":1
      }
    ],
    "body":{
      "product":"outer",
      "num":1
    },
    "meta":{
      "distributed":false,
      "eval_frequency":20,
      "log_frequency":20,
      "max_session":10,
      "max_concurrent_session":10,
      "max_trial":1
    }
  },
  "ipd_ipm_le_vs_exploiter_strat_2_temp_1_0.75_0.75":{
    "world":{
      "name":"DefaultMultiAgentWorld",
      "deterministic":false
    },
    "agent":[
      {
        "name":"LE",
        "memory":null,
        "net":null,
        "welfare_function":"utilitarian_welfare",
        "observing_other_agents":{
          "name":"FullyObservable"
        },
        "algorithm":{
          "name":"LE",
          "punishement_time":1,
          "min_coop_time":0,
          "defection_detection_mode":"spl_observed_actions",
          "defection_carac_threshold":0.0,
          "average_d_carac":true,
          "average_d_carac_len":20,
          "same_init_weights":false,
          "coop_net_ent_diff_as_lr":false,
          "use_sl_for_simu_coop":false,
          "use_strat_4":false,
          "use_strat_5":false,
          "strat_5_coeff":10.0,
          "use_strat_2":true,
          "length_of_history":200,
          "block_len":4,
          "use_last_steps_for_search":true,
          "use_bolzmann_search":true,
          "PERCENTILE_FOR_LIKELIHOOD_TEST":75,
          "meta_algo_memory":{
            "name":"Replay",
            "batch_size":1,
            "max_size":-1
          },
          "meta_algo_loss":{
            "reduction":"none",
            "name":"CrossEntropyLoss"
          },
          "contained_algorithms":[
            {
              "name":"DoubleDQN",
              "algorithm":{
                "name":"DoubleDQN",
                "action_pdtype":"Categorical",
                "action_policy":"boltzmann_on_cluster",
                "explore_var_spec":{
                  "name":"linear_decay",
                  "start_val":1.0,
                  "end_val":0.1,
                  "start_step":0,
                  "end_step":3000
                },
                "gamma":0.5,
                "normalize_inputs":true,
                "training_batch_iter":1,
                "training_iter":4,
                "training_frequency":60,
                "training_start_step":60
              },
              "memory":{
                "name":"Replay",
                "batch_size":60,
                "max_size":4000,
                "use_cer":true
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "clip_grad_val":1.0,
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.04,
                  "momentum":0.9
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            },
            {
              "copy_n":0
            },
            {
              "copy_n":0
            },
            {
              "name":"SupervisedLAPolicy",
              "algorithm":{
                "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
                "entropy_coef_spec":{
                  "name":"linear_decay",
                  "start_val":0.0,
                  "end_val":0.0,
                  "start_step":0,
                  "end_step":500
                },
                "training_frequency":1,
                "normalize_inputs":true,
                "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "loss_spec":{
                  "name":"CrossEntropyLoss",
                  "reduction":"none"
                },
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.40,
                  "momentum":0.000
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            }
          ]
        }
      },
      {
        "name":"LEExploiter",
        "memory":null,
        "net":null,
        "welfare_function":"default_welfare",
        "observing_other_agents":{
          "name":"FullyObservable"
        },
        "algorithm":{
          "name":"LEExploiter",
          "punishement_time":1,
          "min_coop_time":0,
          "defection_detection_mode":"spl_observed_actions",
          "defection_carac_threshold":0.0,
          "average_d_carac":true,
          "average_d_carac_len":20,
          "same_init_weights":false,
          "coop_net_ent_diff_as_lr":false,
          "use_sl_for_simu_coop":false,
          "use_strat_4":false,
          "use_strat_5":false,
          "strat_5_coeff":10.0,
          "use_strat_2":true,
          "length_of_history":200,
          "block_len":4,
          "use_last_steps_for_search":true,
          "use_bolzmann_search":true,
          "PERCENTILE_FOR_LIKELIHOOD_TEST":75,
          "meta_algo_memory":{
            "name":"Replay",
            "batch_size":1,
            "max_size":-1
          },
          "meta_algo_loss":{
            "reduction":"none",
            "name":"CrossEntropyLoss"
          },
          "contained_algorithms":[
            {
              "name":"DoubleDQN",
              "algorithm":{
                "name":"DoubleDQN",
                "action_pdtype":"Categorical",
                "action_policy":"boltzmann_on_cluster",
                "explore_var_spec":{
                  "name":"linear_decay",
                  "start_val":1.0,
                  "end_val":0.1,
                  "start_step":0,
                  "end_step":3000
                },
                "gamma":0.5,
                "normalize_inputs":true,
                "training_batch_iter":1,
                "training_iter":4,
                "training_frequency":60,
                "training_start_step":60
              },
              "memory":{
                "name":"Replay",
                "batch_size":60,
                "max_size":4000,
                "use_cer":true
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "clip_grad_val":1.0,
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.04,
                  "momentum":0.9
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            },
            {
              "copy_n":0
            },
            {
              "copy_n":0
            },
            {
              "name":"SupervisedLAPolicy",
              "algorithm":{
                "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
                "entropy_coef_spec":{
                  "name":"linear_decay",
                  "start_val":0.0,
                  "end_val":0.0,
                  "start_step":0,
                  "end_step":500
                },
                "training_frequency":1,
                "normalize_inputs":true,
                "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "loss_spec":{
                  "name":"CrossEntropyLoss",
                  "reduction":"none"
                },
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.40,
                  "momentum":0.000
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            }
          ]
        }
      }
    ],
    "env":[
      {
        "name":"IteratedPrisonersDilemma-v0",
        "max_t":null,
        "max_frame":4000,
        "num_envs":1
      }
    ],
    "body":{
      "product":"outer",
      "num":1
    },
    "meta":{
      "distributed":false,
      "eval_frequency":20,
      "log_frequency":20,
      "max_session":10,
      "max_concurrent_session":10,
      "max_trial":1
    }
  },
  "ipd_ipm_le_vs_exploiter_strat_2_temp_1_0.75_0.65":{
    "world":{
      "name":"DefaultMultiAgentWorld",
      "deterministic":false
    },
    "agent":[
      {
        "name":"LE",
        "memory":null,
        "net":null,
        "welfare_function":"utilitarian_welfare",
        "observing_other_agents":{
          "name":"FullyObservable"
        },
        "algorithm":{
          "name":"LE",
          "punishement_time":1,
          "min_coop_time":0,
          "defection_detection_mode":"spl_observed_actions",
          "defection_carac_threshold":0.0,
          "average_d_carac":true,
          "average_d_carac_len":20,
          "same_init_weights":false,
          "coop_net_ent_diff_as_lr":false,
          "use_sl_for_simu_coop":false,
          "use_strat_4":false,
          "use_strat_5":false,
          "strat_5_coeff":10.0,
          "use_strat_2":true,
          "length_of_history":200,
          "block_len":4,
          "use_last_steps_for_search":true,
          "use_bolzmann_search":true,
          "PERCENTILE_FOR_LIKELIHOOD_TEST":75,
          "meta_algo_memory":{
            "name":"Replay",
            "batch_size":1,
            "max_size":-1
          },
          "meta_algo_loss":{
            "reduction":"none",
            "name":"CrossEntropyLoss"
          },
          "contained_algorithms":[
            {
              "name":"DoubleDQN",
              "algorithm":{
                "name":"DoubleDQN",
                "action_pdtype":"Categorical",
                "action_policy":"boltzmann_on_cluster",
                "explore_var_spec":{
                  "name":"linear_decay",
                  "start_val":1.0,
                  "end_val":0.1,
                  "start_step":0,
                  "end_step":3000
                },
                "gamma":0.5,
                "normalize_inputs":true,
                "training_batch_iter":1,
                "training_iter":4,
                "training_frequency":60,
                "training_start_step":60
              },
              "memory":{
                "name":"Replay",
                "batch_size":60,
                "max_size":4000,
                "use_cer":true
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "clip_grad_val":1.0,
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.04,
                  "momentum":0.9
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            },
            {
              "copy_n":0
            },
            {
              "copy_n":0
            },
            {
              "name":"SupervisedLAPolicy",
              "algorithm":{
                "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
                "entropy_coef_spec":{
                  "name":"linear_decay",
                  "start_val":0.0,
                  "end_val":0.0,
                  "start_step":0,
                  "end_step":500
                },
                "training_frequency":1,
                "normalize_inputs":true,
                "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "loss_spec":{
                  "name":"CrossEntropyLoss",
                  "reduction":"none"
                },
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.40,
                  "momentum":0.000
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            }
          ]
        }
      },
      {
        "name":"LEExploiter",
        "memory":null,
        "net":null,
        "welfare_function":"default_welfare",
        "observing_other_agents":{
          "name":"FullyObservable"
        },
        "algorithm":{
          "name":"LEExploiter",
          "punishement_time":1,
          "min_coop_time":0,
          "defection_detection_mode":"spl_observed_actions",
          "defection_carac_threshold":0.0,
          "average_d_carac":true,
          "average_d_carac_len":20,
          "same_init_weights":false,
          "coop_net_ent_diff_as_lr":false,
          "use_sl_for_simu_coop":false,
          "use_strat_4":false,
          "use_strat_5":false,
          "strat_5_coeff":10.0,
          "use_strat_2":true,
          "length_of_history":200,
          "block_len":4,
          "use_last_steps_for_search":true,
          "use_bolzmann_search":true,
          "PERCENTILE_FOR_LIKELIHOOD_TEST":65,
          "meta_algo_memory":{
            "name":"Replay",
            "batch_size":1,
            "max_size":-1
          },
          "meta_algo_loss":{
            "reduction":"none",
            "name":"CrossEntropyLoss"
          },
          "contained_algorithms":[
            {
              "name":"DoubleDQN",
              "algorithm":{
                "name":"DoubleDQN",
                "action_pdtype":"Categorical",
                "action_policy":"boltzmann_on_cluster",
                "explore_var_spec":{
                  "name":"linear_decay",
                  "start_val":1.0,
                  "end_val":0.1,
                  "start_step":0,
                  "end_step":3000
                },
                "gamma":0.5,
                "normalize_inputs":true,
                "training_batch_iter":1,
                "training_iter":4,
                "training_frequency":60,
                "training_start_step":60
              },
              "memory":{
                "name":"Replay",
                "batch_size":60,
                "max_size":4000,
                "use_cer":true
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "clip_grad_val":1.0,
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.04,
                  "momentum":0.9
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            },
            {
              "copy_n":0
            },
            {
              "copy_n":0
            },
            {
              "name":"SupervisedLAPolicy",
              "algorithm":{
                "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
                "entropy_coef_spec":{
                  "name":"linear_decay",
                  "start_val":0.0,
                  "end_val":0.0,
                  "start_step":0,
                  "end_step":500
                },
                "training_frequency":1,
                "normalize_inputs":true,
                "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "loss_spec":{
                  "name":"CrossEntropyLoss",
                  "reduction":"none"
                },
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.40,
                  "momentum":0.000
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            }
          ]
        }
      }
    ],
    "env":[
      {
        "name":"IteratedPrisonersDilemma-v0",
        "max_t":null,
        "max_frame":4000,
        "num_envs":1
      }
    ],
    "body":{
      "product":"outer",
      "num":1
    },
    "meta":{
      "distributed":false,
      "eval_frequency":20,
      "log_frequency":20,
      "max_session":10,
      "max_concurrent_session":10,
      "max_trial":1
    }
  },
  "ipd_ipm_le_vs_exploiter_strat_2_temp_1_0.75_0.55":{
    "world":{
      "name":"DefaultMultiAgentWorld",
      "deterministic":false
    },
    "agent":[
      {
        "name":"LE",
        "memory":null,
        "net":null,
        "welfare_function":"utilitarian_welfare",
        "observing_other_agents":{
          "name":"FullyObservable"
        },
        "algorithm":{
          "name":"LE",
          "punishement_time":1,
          "min_coop_time":0,
          "defection_detection_mode":"spl_observed_actions",
          "defection_carac_threshold":0.0,
          "average_d_carac":true,
          "average_d_carac_len":20,
          "same_init_weights":false,
          "coop_net_ent_diff_as_lr":false,
          "use_sl_for_simu_coop":false,
          "use_strat_4":false,
          "use_strat_5":false,
          "strat_5_coeff":10.0,
          "use_strat_2":true,
          "length_of_history":200,
          "block_len":4,
          "use_last_steps_for_search":true,
          "use_bolzmann_search":true,
          "PERCENTILE_FOR_LIKELIHOOD_TEST":75,
          "meta_algo_memory":{
            "name":"Replay",
            "batch_size":1,
            "max_size":-1
          },
          "meta_algo_loss":{
            "reduction":"none",
            "name":"CrossEntropyLoss"
          },
          "contained_algorithms":[
            {
              "name":"DoubleDQN",
              "algorithm":{
                "name":"DoubleDQN",
                "action_pdtype":"Categorical",
                "action_policy":"boltzmann_on_cluster",
                "explore_var_spec":{
                  "name":"linear_decay",
                  "start_val":1.0,
                  "end_val":0.1,
                  "start_step":0,
                  "end_step":3000
                },
                "gamma":0.5,
                "normalize_inputs":true,
                "training_batch_iter":1,
                "training_iter":4,
                "training_frequency":60,
                "training_start_step":60
              },
              "memory":{
                "name":"Replay",
                "batch_size":60,
                "max_size":4000,
                "use_cer":true
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "clip_grad_val":1.0,
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.04,
                  "momentum":0.9
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            },
            {
              "copy_n":0
            },
            {
              "copy_n":0
            },
            {
              "name":"SupervisedLAPolicy",
              "algorithm":{
                "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
                "entropy_coef_spec":{
                  "name":"linear_decay",
                  "start_val":0.0,
                  "end_val":0.0,
                  "start_step":0,
                  "end_step":500
                },
                "training_frequency":1,
                "normalize_inputs":true,
                "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "loss_spec":{
                  "name":"CrossEntropyLoss",
                  "reduction":"none"
                },
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.40,
                  "momentum":0.000
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            }
          ]
        }
      },
      {
        "name":"LEExploiter",
        "memory":null,
        "net":null,
        "welfare_function":"default_welfare",
        "observing_other_agents":{
          "name":"FullyObservable"
        },
        "algorithm":{
          "name":"LEExploiter",
          "punishement_time":1,
          "min_coop_time":0,
          "defection_detection_mode":"spl_observed_actions",
          "defection_carac_threshold":0.0,
          "average_d_carac":true,
          "average_d_carac_len":20,
          "same_init_weights":false,
          "coop_net_ent_diff_as_lr":false,
          "use_sl_for_simu_coop":false,
          "use_strat_4":false,
          "use_strat_5":false,
          "strat_5_coeff":10.0,
          "use_strat_2":true,
          "length_of_history":200,
          "block_len":4,
          "use_last_steps_for_search":true,
          "use_bolzmann_search":true,
          "PERCENTILE_FOR_LIKELIHOOD_TEST":55,
          "meta_algo_memory":{
            "name":"Replay",
            "batch_size":1,
            "max_size":-1
          },
          "meta_algo_loss":{
            "reduction":"none",
            "name":"CrossEntropyLoss"
          },
          "contained_algorithms":[
            {
              "name":"DoubleDQN",
              "algorithm":{
                "name":"DoubleDQN",
                "action_pdtype":"Categorical",
                "action_policy":"boltzmann_on_cluster",
                "explore_var_spec":{
                  "name":"linear_decay",
                  "start_val":1.0,
                  "end_val":0.1,
                  "start_step":0,
                  "end_step":3000
                },
                "gamma":0.5,
                "normalize_inputs":true,
                "training_batch_iter":1,
                "training_iter":4,
                "training_frequency":60,
                "training_start_step":60
              },
              "memory":{
                "name":"Replay",
                "batch_size":60,
                "max_size":4000,
                "use_cer":true
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "clip_grad_val":1.0,
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.04,
                  "momentum":0.9
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            },
            {
              "copy_n":0
            },
            {
              "copy_n":0
            },
            {
              "name":"SupervisedLAPolicy",
              "algorithm":{
                "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
                "entropy_coef_spec":{
                  "name":"linear_decay",
                  "start_val":0.0,
                  "end_val":0.0,
                  "start_step":0,
                  "end_step":500
                },
                "training_frequency":1,
                "normalize_inputs":true,
                "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "loss_spec":{
                  "name":"CrossEntropyLoss",
                  "reduction":"none"
                },
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.40,
                  "momentum":0.000
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            }
          ]
        }
      }
    ],
    "env":[
      {
        "name":"IteratedPrisonersDilemma-v0",
        "max_t":null,
        "max_frame":4000,
        "num_envs":1
      }
    ],
    "body":{
      "product":"outer",
      "num":1
    },
    "meta":{
      "distributed":false,
      "eval_frequency":20,
      "log_frequency":20,
      "max_session":10,
      "max_concurrent_session":10,
      "max_trial":1
    }
  },

  "ipd_ipm_le_vs_exploiter_strat_2_temp_1_0.65_0.95":{
    "world":{
      "name":"DefaultMultiAgentWorld",
      "deterministic":false
    },
    "agent":[
      {
        "name":"LE",
        "memory":null,
        "net":null,
        "welfare_function":"utilitarian_welfare",
        "observing_other_agents":{
          "name":"FullyObservable"
        },
        "algorithm":{
          "name":"LE",
          "punishement_time":1,
          "min_coop_time":0,
          "defection_detection_mode":"spl_observed_actions",
          "defection_carac_threshold":0.0,
          "average_d_carac":true,
          "average_d_carac_len":20,
          "same_init_weights":false,
          "coop_net_ent_diff_as_lr":false,
          "use_sl_for_simu_coop":false,
          "use_strat_4":false,
          "use_strat_5":false,
          "strat_5_coeff":10.0,
          "use_strat_2":true,
          "length_of_history":200,
          "block_len":4,
          "use_last_steps_for_search":true,
          "use_bolzmann_search":true,
          "PERCENTILE_FOR_LIKELIHOOD_TEST":65,
          "meta_algo_memory":{
            "name":"Replay",
            "batch_size":1,
            "max_size":-1
          },
          "meta_algo_loss":{
            "reduction":"none",
            "name":"CrossEntropyLoss"
          },
          "contained_algorithms":[
            {
              "name":"DoubleDQN",
              "algorithm":{
                "name":"DoubleDQN",
                "action_pdtype":"Categorical",
                "action_policy":"boltzmann_on_cluster",
                "explore_var_spec":{
                  "name":"linear_decay",
                  "start_val":1.0,
                  "end_val":0.1,
                  "start_step":0,
                  "end_step":3000
                },
                "gamma":0.5,
                "normalize_inputs":true,
                "training_batch_iter":1,
                "training_iter":4,
                "training_frequency":60,
                "training_start_step":60
              },
              "memory":{
                "name":"Replay",
                "batch_size":60,
                "max_size":4000,
                "use_cer":true
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "clip_grad_val":1.0,
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.04,
                  "momentum":0.9
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            },
            {
              "copy_n":0
            },
            {
              "copy_n":0
            },
            {
              "name":"SupervisedLAPolicy",
              "algorithm":{
                "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
                "entropy_coef_spec":{
                  "name":"linear_decay",
                  "start_val":0.0,
                  "end_val":0.0,
                  "start_step":0,
                  "end_step":500
                },
                "training_frequency":1,
                "normalize_inputs":true,
                "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "loss_spec":{
                  "name":"CrossEntropyLoss",
                  "reduction":"none"
                },
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.40,
                  "momentum":0.000
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            }
          ]
        }
      },
      {
        "name":"LEExploiter",
        "memory":null,
        "net":null,
        "welfare_function":"default_welfare",
        "observing_other_agents":{
          "name":"FullyObservable"
        },
        "algorithm":{
          "name":"LEExploiter",
          "punishement_time":1,
          "min_coop_time":0,
          "defection_detection_mode":"spl_observed_actions",
          "defection_carac_threshold":0.0,
          "average_d_carac":true,
          "average_d_carac_len":20,
          "same_init_weights":false,
          "coop_net_ent_diff_as_lr":false,
          "use_sl_for_simu_coop":false,
          "use_strat_4":false,
          "use_strat_5":false,
          "strat_5_coeff":10.0,
          "use_strat_2":true,
          "length_of_history":200,
          "block_len":4,
          "use_last_steps_for_search":true,
          "use_bolzmann_search":true,
          "PERCENTILE_FOR_LIKELIHOOD_TEST":95,
          "meta_algo_memory":{
            "name":"Replay",
            "batch_size":1,
            "max_size":-1
          },
          "meta_algo_loss":{
            "reduction":"none",
            "name":"CrossEntropyLoss"
          },
          "contained_algorithms":[
            {
              "name":"DoubleDQN",
              "algorithm":{
                "name":"DoubleDQN",
                "action_pdtype":"Categorical",
                "action_policy":"boltzmann_on_cluster",
                "explore_var_spec":{
                  "name":"linear_decay",
                  "start_val":1.0,
                  "end_val":0.1,
                  "start_step":0,
                  "end_step":3000
                },
                "gamma":0.5,
                "normalize_inputs":true,
                "training_batch_iter":1,
                "training_iter":4,
                "training_frequency":60,
                "training_start_step":60
              },
              "memory":{
                "name":"Replay",
                "batch_size":60,
                "max_size":4000,
                "use_cer":true
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "clip_grad_val":1.0,
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.04,
                  "momentum":0.9
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            },
            {
              "copy_n":0
            },
            {
              "copy_n":0
            },
            {
              "name":"SupervisedLAPolicy",
              "algorithm":{
                "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
                "entropy_coef_spec":{
                  "name":"linear_decay",
                  "start_val":0.0,
                  "end_val":0.0,
                  "start_step":0,
                  "end_step":500
                },
                "training_frequency":1,
                "normalize_inputs":true,
                "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "loss_spec":{
                  "name":"CrossEntropyLoss",
                  "reduction":"none"
                },
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.40,
                  "momentum":0.000
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            }
          ]
        }
      }
    ],
    "env":[
      {
        "name":"IteratedPrisonersDilemma-v0",
        "max_t":null,
        "max_frame":4000,
        "num_envs":1
      }
    ],
    "body":{
      "product":"outer",
      "num":1
    },
    "meta":{
      "distributed":false,
      "eval_frequency":20,
      "log_frequency":20,
      "max_session":10,
      "max_concurrent_session":10,
      "max_trial":1
    }
  },
  "ipd_ipm_le_vs_exploiter_strat_2_temp_1_0.65_0.85":{
    "world":{
      "name":"DefaultMultiAgentWorld",
      "deterministic":false
    },
    "agent":[
      {
        "name":"LE",
        "memory":null,
        "net":null,
        "welfare_function":"utilitarian_welfare",
        "observing_other_agents":{
          "name":"FullyObservable"
        },
        "algorithm":{
          "name":"LE",
          "punishement_time":1,
          "min_coop_time":0,
          "defection_detection_mode":"spl_observed_actions",
          "defection_carac_threshold":0.0,
          "average_d_carac":true,
          "average_d_carac_len":20,
          "same_init_weights":false,
          "coop_net_ent_diff_as_lr":false,
          "use_sl_for_simu_coop":false,
          "use_strat_4":false,
          "use_strat_5":false,
          "strat_5_coeff":10.0,
          "use_strat_2":true,
          "length_of_history":200,
          "block_len":4,
          "use_last_steps_for_search":true,
          "use_bolzmann_search":true,
          "PERCENTILE_FOR_LIKELIHOOD_TEST":65,
          "meta_algo_memory":{
            "name":"Replay",
            "batch_size":1,
            "max_size":-1
          },
          "meta_algo_loss":{
            "reduction":"none",
            "name":"CrossEntropyLoss"
          },
          "contained_algorithms":[
            {
              "name":"DoubleDQN",
              "algorithm":{
                "name":"DoubleDQN",
                "action_pdtype":"Categorical",
                "action_policy":"boltzmann_on_cluster",
                "explore_var_spec":{
                  "name":"linear_decay",
                  "start_val":1.0,
                  "end_val":0.1,
                  "start_step":0,
                  "end_step":3000
                },
                "gamma":0.5,
                "normalize_inputs":true,
                "training_batch_iter":1,
                "training_iter":4,
                "training_frequency":60,
                "training_start_step":60
              },
              "memory":{
                "name":"Replay",
                "batch_size":60,
                "max_size":4000,
                "use_cer":true
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "clip_grad_val":1.0,
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.04,
                  "momentum":0.9
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            },
            {
              "copy_n":0
            },
            {
              "copy_n":0
            },
            {
              "name":"SupervisedLAPolicy",
              "algorithm":{
                "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
                "entropy_coef_spec":{
                  "name":"linear_decay",
                  "start_val":0.0,
                  "end_val":0.0,
                  "start_step":0,
                  "end_step":500
                },
                "training_frequency":1,
                "normalize_inputs":true,
                "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "loss_spec":{
                  "name":"CrossEntropyLoss",
                  "reduction":"none"
                },
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.40,
                  "momentum":0.000
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            }
          ]
        }
      },
      {
        "name":"LEExploiter",
        "memory":null,
        "net":null,
        "welfare_function":"default_welfare",
        "observing_other_agents":{
          "name":"FullyObservable"
        },
        "algorithm":{
          "name":"LEExploiter",
          "punishement_time":1,
          "min_coop_time":0,
          "defection_detection_mode":"spl_observed_actions",
          "defection_carac_threshold":0.0,
          "average_d_carac":true,
          "average_d_carac_len":20,
          "same_init_weights":false,
          "coop_net_ent_diff_as_lr":false,
          "use_sl_for_simu_coop":false,
          "use_strat_4":false,
          "use_strat_5":false,
          "strat_5_coeff":10.0,
          "use_strat_2":true,
          "length_of_history":200,
          "block_len":4,
          "use_last_steps_for_search":true,
          "use_bolzmann_search":true,
          "PERCENTILE_FOR_LIKELIHOOD_TEST":85,
          "meta_algo_memory":{
            "name":"Replay",
            "batch_size":1,
            "max_size":-1
          },
          "meta_algo_loss":{
            "reduction":"none",
            "name":"CrossEntropyLoss"
          },
          "contained_algorithms":[
            {
              "name":"DoubleDQN",
              "algorithm":{
                "name":"DoubleDQN",
                "action_pdtype":"Categorical",
                "action_policy":"boltzmann_on_cluster",
                "explore_var_spec":{
                  "name":"linear_decay",
                  "start_val":1.0,
                  "end_val":0.1,
                  "start_step":0,
                  "end_step":3000
                },
                "gamma":0.5,
                "normalize_inputs":true,
                "training_batch_iter":1,
                "training_iter":4,
                "training_frequency":60,
                "training_start_step":60
              },
              "memory":{
                "name":"Replay",
                "batch_size":60,
                "max_size":4000,
                "use_cer":true
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "clip_grad_val":1.0,
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.04,
                  "momentum":0.9
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            },
            {
              "copy_n":0
            },
            {
              "copy_n":0
            },
            {
              "name":"SupervisedLAPolicy",
              "algorithm":{
                "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
                "entropy_coef_spec":{
                  "name":"linear_decay",
                  "start_val":0.0,
                  "end_val":0.0,
                  "start_step":0,
                  "end_step":500
                },
                "training_frequency":1,
                "normalize_inputs":true,
                "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "loss_spec":{
                  "name":"CrossEntropyLoss",
                  "reduction":"none"
                },
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.40,
                  "momentum":0.000
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            }
          ]
        }
      }
    ],
    "env":[
      {
        "name":"IteratedPrisonersDilemma-v0",
        "max_t":null,
        "max_frame":4000,
        "num_envs":1
      }
    ],
    "body":{
      "product":"outer",
      "num":1
    },
    "meta":{
      "distributed":false,
      "eval_frequency":20,
      "log_frequency":20,
      "max_session":10,
      "max_concurrent_session":10,
      "max_trial":1
    }
  },
  "ipd_ipm_le_vs_exploiter_strat_2_temp_1_0.65_0.75":{
    "world":{
      "name":"DefaultMultiAgentWorld",
      "deterministic":false
    },
    "agent":[
      {
        "name":"LE",
        "memory":null,
        "net":null,
        "welfare_function":"utilitarian_welfare",
        "observing_other_agents":{
          "name":"FullyObservable"
        },
        "algorithm":{
          "name":"LE",
          "punishement_time":1,
          "min_coop_time":0,
          "defection_detection_mode":"spl_observed_actions",
          "defection_carac_threshold":0.0,
          "average_d_carac":true,
          "average_d_carac_len":20,
          "same_init_weights":false,
          "coop_net_ent_diff_as_lr":false,
          "use_sl_for_simu_coop":false,
          "use_strat_4":false,
          "use_strat_5":false,
          "strat_5_coeff":10.0,
          "use_strat_2":true,
          "length_of_history":200,
          "block_len":4,
          "use_last_steps_for_search":true,
          "use_bolzmann_search":true,
          "PERCENTILE_FOR_LIKELIHOOD_TEST":65,
          "meta_algo_memory":{
            "name":"Replay",
            "batch_size":1,
            "max_size":-1
          },
          "meta_algo_loss":{
            "reduction":"none",
            "name":"CrossEntropyLoss"
          },
          "contained_algorithms":[
            {
              "name":"DoubleDQN",
              "algorithm":{
                "name":"DoubleDQN",
                "action_pdtype":"Categorical",
                "action_policy":"boltzmann_on_cluster",
                "explore_var_spec":{
                  "name":"linear_decay",
                  "start_val":1.0,
                  "end_val":0.1,
                  "start_step":0,
                  "end_step":3000
                },
                "gamma":0.5,
                "normalize_inputs":true,
                "training_batch_iter":1,
                "training_iter":4,
                "training_frequency":60,
                "training_start_step":60
              },
              "memory":{
                "name":"Replay",
                "batch_size":60,
                "max_size":4000,
                "use_cer":true
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "clip_grad_val":1.0,
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.04,
                  "momentum":0.9
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            },
            {
              "copy_n":0
            },
            {
              "copy_n":0
            },
            {
              "name":"SupervisedLAPolicy",
              "algorithm":{
                "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
                "entropy_coef_spec":{
                  "name":"linear_decay",
                  "start_val":0.0,
                  "end_val":0.0,
                  "start_step":0,
                  "end_step":500
                },
                "training_frequency":1,
                "normalize_inputs":true,
                "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "loss_spec":{
                  "name":"CrossEntropyLoss",
                  "reduction":"none"
                },
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.40,
                  "momentum":0.000
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            }
          ]
        }
      },
      {
        "name":"LEExploiter",
        "memory":null,
        "net":null,
        "welfare_function":"default_welfare",
        "observing_other_agents":{
          "name":"FullyObservable"
        },
        "algorithm":{
          "name":"LEExploiter",
          "punishement_time":1,
          "min_coop_time":0,
          "defection_detection_mode":"spl_observed_actions",
          "defection_carac_threshold":0.0,
          "average_d_carac":true,
          "average_d_carac_len":20,
          "same_init_weights":false,
          "coop_net_ent_diff_as_lr":false,
          "use_sl_for_simu_coop":false,
          "use_strat_4":false,
          "use_strat_5":false,
          "strat_5_coeff":10.0,
          "use_strat_2":true,
          "length_of_history":200,
          "block_len":4,
          "use_last_steps_for_search":true,
          "use_bolzmann_search":true,
          "PERCENTILE_FOR_LIKELIHOOD_TEST":75,
          "meta_algo_memory":{
            "name":"Replay",
            "batch_size":1,
            "max_size":-1
          },
          "meta_algo_loss":{
            "reduction":"none",
            "name":"CrossEntropyLoss"
          },
          "contained_algorithms":[
            {
              "name":"DoubleDQN",
              "algorithm":{
                "name":"DoubleDQN",
                "action_pdtype":"Categorical",
                "action_policy":"boltzmann_on_cluster",
                "explore_var_spec":{
                  "name":"linear_decay",
                  "start_val":1.0,
                  "end_val":0.1,
                  "start_step":0,
                  "end_step":3000
                },
                "gamma":0.5,
                "normalize_inputs":true,
                "training_batch_iter":1,
                "training_iter":4,
                "training_frequency":60,
                "training_start_step":60
              },
              "memory":{
                "name":"Replay",
                "batch_size":60,
                "max_size":4000,
                "use_cer":true
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "clip_grad_val":1.0,
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.04,
                  "momentum":0.9
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            },
            {
              "copy_n":0
            },
            {
              "copy_n":0
            },
            {
              "name":"SupervisedLAPolicy",
              "algorithm":{
                "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
                "entropy_coef_spec":{
                  "name":"linear_decay",
                  "start_val":0.0,
                  "end_val":0.0,
                  "start_step":0,
                  "end_step":500
                },
                "training_frequency":1,
                "normalize_inputs":true,
                "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "loss_spec":{
                  "name":"CrossEntropyLoss",
                  "reduction":"none"
                },
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.40,
                  "momentum":0.000
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            }
          ]
        }
      }
    ],
    "env":[
      {
        "name":"IteratedPrisonersDilemma-v0",
        "max_t":null,
        "max_frame":4000,
        "num_envs":1
      }
    ],
    "body":{
      "product":"outer",
      "num":1
    },
    "meta":{
      "distributed":false,
      "eval_frequency":20,
      "log_frequency":20,
      "max_session":10,
      "max_concurrent_session":10,
      "max_trial":1
    }
  },
  "ipd_ipm_le_vs_exploiter_strat_2_temp_1_0.65_0.65":{
    "world":{
      "name":"DefaultMultiAgentWorld",
      "deterministic":false
    },
    "agent":[
      {
        "name":"LE",
        "memory":null,
        "net":null,
        "welfare_function":"utilitarian_welfare",
        "observing_other_agents":{
          "name":"FullyObservable"
        },
        "algorithm":{
          "name":"LE",
          "punishement_time":1,
          "min_coop_time":0,
          "defection_detection_mode":"spl_observed_actions",
          "defection_carac_threshold":0.0,
          "average_d_carac":true,
          "average_d_carac_len":20,
          "same_init_weights":false,
          "coop_net_ent_diff_as_lr":false,
          "use_sl_for_simu_coop":false,
          "use_strat_4":false,
          "use_strat_5":false,
          "strat_5_coeff":10.0,
          "use_strat_2":true,
          "length_of_history":200,
          "block_len":4,
          "use_last_steps_for_search":true,
          "use_bolzmann_search":true,
          "PERCENTILE_FOR_LIKELIHOOD_TEST":65,
          "meta_algo_memory":{
            "name":"Replay",
            "batch_size":1,
            "max_size":-1
          },
          "meta_algo_loss":{
            "reduction":"none",
            "name":"CrossEntropyLoss"
          },
          "contained_algorithms":[
            {
              "name":"DoubleDQN",
              "algorithm":{
                "name":"DoubleDQN",
                "action_pdtype":"Categorical",
                "action_policy":"boltzmann_on_cluster",
                "explore_var_spec":{
                  "name":"linear_decay",
                  "start_val":1.0,
                  "end_val":0.1,
                  "start_step":0,
                  "end_step":3000
                },
                "gamma":0.5,
                "normalize_inputs":true,
                "training_batch_iter":1,
                "training_iter":4,
                "training_frequency":60,
                "training_start_step":60
              },
              "memory":{
                "name":"Replay",
                "batch_size":60,
                "max_size":4000,
                "use_cer":true
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "clip_grad_val":1.0,
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.04,
                  "momentum":0.9
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            },
            {
              "copy_n":0
            },
            {
              "copy_n":0
            },
            {
              "name":"SupervisedLAPolicy",
              "algorithm":{
                "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
                "entropy_coef_spec":{
                  "name":"linear_decay",
                  "start_val":0.0,
                  "end_val":0.0,
                  "start_step":0,
                  "end_step":500
                },
                "training_frequency":1,
                "normalize_inputs":true,
                "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "loss_spec":{
                  "name":"CrossEntropyLoss",
                  "reduction":"none"
                },
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.40,
                  "momentum":0.000
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            }
          ]
        }
      },
      {
        "name":"LEExploiter",
        "memory":null,
        "net":null,
        "welfare_function":"default_welfare",
        "observing_other_agents":{
          "name":"FullyObservable"
        },
        "algorithm":{
          "name":"LEExploiter",
          "punishement_time":1,
          "min_coop_time":0,
          "defection_detection_mode":"spl_observed_actions",
          "defection_carac_threshold":0.0,
          "average_d_carac":true,
          "average_d_carac_len":20,
          "same_init_weights":false,
          "coop_net_ent_diff_as_lr":false,
          "use_sl_for_simu_coop":false,
          "use_strat_4":false,
          "use_strat_5":false,
          "strat_5_coeff":10.0,
          "use_strat_2":true,
          "length_of_history":200,
          "block_len":4,
          "use_last_steps_for_search":true,
          "use_bolzmann_search":true,
          "PERCENTILE_FOR_LIKELIHOOD_TEST":65,
          "meta_algo_memory":{
            "name":"Replay",
            "batch_size":1,
            "max_size":-1
          },
          "meta_algo_loss":{
            "reduction":"none",
            "name":"CrossEntropyLoss"
          },
          "contained_algorithms":[
            {
              "name":"DoubleDQN",
              "algorithm":{
                "name":"DoubleDQN",
                "action_pdtype":"Categorical",
                "action_policy":"boltzmann_on_cluster",
                "explore_var_spec":{
                  "name":"linear_decay",
                  "start_val":1.0,
                  "end_val":0.1,
                  "start_step":0,
                  "end_step":3000
                },
                "gamma":0.5,
                "normalize_inputs":true,
                "training_batch_iter":1,
                "training_iter":4,
                "training_frequency":60,
                "training_start_step":60
              },
              "memory":{
                "name":"Replay",
                "batch_size":60,
                "max_size":4000,
                "use_cer":true
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "clip_grad_val":1.0,
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.04,
                  "momentum":0.9
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            },
            {
              "copy_n":0
            },
            {
              "copy_n":0
            },
            {
              "name":"SupervisedLAPolicy",
              "algorithm":{
                "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
                "entropy_coef_spec":{
                  "name":"linear_decay",
                  "start_val":0.0,
                  "end_val":0.0,
                  "start_step":0,
                  "end_step":500
                },
                "training_frequency":1,
                "normalize_inputs":true,
                "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "loss_spec":{
                  "name":"CrossEntropyLoss",
                  "reduction":"none"
                },
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.40,
                  "momentum":0.000
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            }
          ]
        }
      }
    ],
    "env":[
      {
        "name":"IteratedPrisonersDilemma-v0",
        "max_t":null,
        "max_frame":4000,
        "num_envs":1
      }
    ],
    "body":{
      "product":"outer",
      "num":1
    },
    "meta":{
      "distributed":false,
      "eval_frequency":20,
      "log_frequency":20,
      "max_session":10,
      "max_concurrent_session":10,
      "max_trial":1
    }
  },
  "ipd_ipm_le_vs_exploiter_strat_2_temp_1_0.65_0.55":{
    "world":{
      "name":"DefaultMultiAgentWorld",
      "deterministic":false
    },
    "agent":[
      {
        "name":"LE",
        "memory":null,
        "net":null,
        "welfare_function":"utilitarian_welfare",
        "observing_other_agents":{
          "name":"FullyObservable"
        },
        "algorithm":{
          "name":"LE",
          "punishement_time":1,
          "min_coop_time":0,
          "defection_detection_mode":"spl_observed_actions",
          "defection_carac_threshold":0.0,
          "average_d_carac":true,
          "average_d_carac_len":20,
          "same_init_weights":false,
          "coop_net_ent_diff_as_lr":false,
          "use_sl_for_simu_coop":false,
          "use_strat_4":false,
          "use_strat_5":false,
          "strat_5_coeff":10.0,
          "use_strat_2":true,
          "length_of_history":200,
          "block_len":4,
          "use_last_steps_for_search":true,
          "use_bolzmann_search":true,
          "PERCENTILE_FOR_LIKELIHOOD_TEST":65,
          "meta_algo_memory":{
            "name":"Replay",
            "batch_size":1,
            "max_size":-1
          },
          "meta_algo_loss":{
            "reduction":"none",
            "name":"CrossEntropyLoss"
          },
          "contained_algorithms":[
            {
              "name":"DoubleDQN",
              "algorithm":{
                "name":"DoubleDQN",
                "action_pdtype":"Categorical",
                "action_policy":"boltzmann_on_cluster",
                "explore_var_spec":{
                  "name":"linear_decay",
                  "start_val":1.0,
                  "end_val":0.1,
                  "start_step":0,
                  "end_step":3000
                },
                "gamma":0.5,
                "normalize_inputs":true,
                "training_batch_iter":1,
                "training_iter":4,
                "training_frequency":60,
                "training_start_step":60
              },
              "memory":{
                "name":"Replay",
                "batch_size":60,
                "max_size":4000,
                "use_cer":true
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "clip_grad_val":1.0,
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.04,
                  "momentum":0.9
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            },
            {
              "copy_n":0
            },
            {
              "copy_n":0
            },
            {
              "name":"SupervisedLAPolicy",
              "algorithm":{
                "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
                "entropy_coef_spec":{
                  "name":"linear_decay",
                  "start_val":0.0,
                  "end_val":0.0,
                  "start_step":0,
                  "end_step":500
                },
                "training_frequency":1,
                "normalize_inputs":true,
                "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "loss_spec":{
                  "name":"CrossEntropyLoss",
                  "reduction":"none"
                },
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.40,
                  "momentum":0.000
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            }
          ]
        }
      },
      {
        "name":"LEExploiter",
        "memory":null,
        "net":null,
        "welfare_function":"default_welfare",
        "observing_other_agents":{
          "name":"FullyObservable"
        },
        "algorithm":{
          "name":"LEExploiter",
          "punishement_time":1,
          "min_coop_time":0,
          "defection_detection_mode":"spl_observed_actions",
          "defection_carac_threshold":0.0,
          "average_d_carac":true,
          "average_d_carac_len":20,
          "same_init_weights":false,
          "coop_net_ent_diff_as_lr":false,
          "use_sl_for_simu_coop":false,
          "use_strat_4":false,
          "use_strat_5":false,
          "strat_5_coeff":10.0,
          "use_strat_2":true,
          "length_of_history":200,
          "block_len":4,
          "use_last_steps_for_search":true,
          "use_bolzmann_search":true,
          "PERCENTILE_FOR_LIKELIHOOD_TEST":55,
          "meta_algo_memory":{
            "name":"Replay",
            "batch_size":1,
            "max_size":-1
          },
          "meta_algo_loss":{
            "reduction":"none",
            "name":"CrossEntropyLoss"
          },
          "contained_algorithms":[
            {
              "name":"DoubleDQN",
              "algorithm":{
                "name":"DoubleDQN",
                "action_pdtype":"Categorical",
                "action_policy":"boltzmann_on_cluster",
                "explore_var_spec":{
                  "name":"linear_decay",
                  "start_val":1.0,
                  "end_val":0.1,
                  "start_step":0,
                  "end_step":3000
                },
                "gamma":0.5,
                "normalize_inputs":true,
                "training_batch_iter":1,
                "training_iter":4,
                "training_frequency":60,
                "training_start_step":60
              },
              "memory":{
                "name":"Replay",
                "batch_size":60,
                "max_size":4000,
                "use_cer":true
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "clip_grad_val":1.0,
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.04,
                  "momentum":0.9
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            },
            {
              "copy_n":0
            },
            {
              "copy_n":0
            },
            {
              "name":"SupervisedLAPolicy",
              "algorithm":{
                "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
                "entropy_coef_spec":{
                  "name":"linear_decay",
                  "start_val":0.0,
                  "end_val":0.0,
                  "start_step":0,
                  "end_step":500
                },
                "training_frequency":1,
                "normalize_inputs":true,
                "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "loss_spec":{
                  "name":"CrossEntropyLoss",
                  "reduction":"none"
                },
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.40,
                  "momentum":0.000
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            }
          ]
        }
      }
    ],
    "env":[
      {
        "name":"IteratedPrisonersDilemma-v0",
        "max_t":null,
        "max_frame":4000,
        "num_envs":1
      }
    ],
    "body":{
      "product":"outer",
      "num":1
    },
    "meta":{
      "distributed":false,
      "eval_frequency":20,
      "log_frequency":20,
      "max_session":10,
      "max_concurrent_session":10,
      "max_trial":1
    }
  },

  "ipd_ipm_le_vs_exploiter_strat_2_temp_1_0.55_0.95":{
    "world":{
      "name":"DefaultMultiAgentWorld",
      "deterministic":false
    },
    "agent":[
      {
        "name":"LE",
        "memory":null,
        "net":null,
        "welfare_function":"utilitarian_welfare",
        "observing_other_agents":{
          "name":"FullyObservable"
        },
        "algorithm":{
          "name":"LE",
          "punishement_time":1,
          "min_coop_time":0,
          "defection_detection_mode":"spl_observed_actions",
          "defection_carac_threshold":0.0,
          "average_d_carac":true,
          "average_d_carac_len":20,
          "same_init_weights":false,
          "coop_net_ent_diff_as_lr":false,
          "use_sl_for_simu_coop":false,
          "use_strat_4":false,
          "use_strat_5":false,
          "strat_5_coeff":10.0,
          "use_strat_2":true,
          "length_of_history":200,
          "block_len":4,
          "use_last_steps_for_search":true,
          "use_bolzmann_search":true,
          "PERCENTILE_FOR_LIKELIHOOD_TEST":55,
          "meta_algo_memory":{
            "name":"Replay",
            "batch_size":1,
            "max_size":-1
          },
          "meta_algo_loss":{
            "reduction":"none",
            "name":"CrossEntropyLoss"
          },
          "contained_algorithms":[
            {
              "name":"DoubleDQN",
              "algorithm":{
                "name":"DoubleDQN",
                "action_pdtype":"Categorical",
                "action_policy":"boltzmann_on_cluster",
                "explore_var_spec":{
                  "name":"linear_decay",
                  "start_val":1.0,
                  "end_val":0.1,
                  "start_step":0,
                  "end_step":3000
                },
                "gamma":0.5,
                "normalize_inputs":true,
                "training_batch_iter":1,
                "training_iter":4,
                "training_frequency":60,
                "training_start_step":60
              },
              "memory":{
                "name":"Replay",
                "batch_size":60,
                "max_size":4000,
                "use_cer":true
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "clip_grad_val":1.0,
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.04,
                  "momentum":0.9
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            },
            {
              "copy_n":0
            },
            {
              "copy_n":0
            },
            {
              "name":"SupervisedLAPolicy",
              "algorithm":{
                "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
                "entropy_coef_spec":{
                  "name":"linear_decay",
                  "start_val":0.0,
                  "end_val":0.0,
                  "start_step":0,
                  "end_step":500
                },
                "training_frequency":1,
                "normalize_inputs":true,
                "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "loss_spec":{
                  "name":"CrossEntropyLoss",
                  "reduction":"none"
                },
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.40,
                  "momentum":0.000
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            }
          ]
        }
      },
      {
        "name":"LEExploiter",
        "memory":null,
        "net":null,
        "welfare_function":"default_welfare",
        "observing_other_agents":{
          "name":"FullyObservable"
        },
        "algorithm":{
          "name":"LEExploiter",
          "punishement_time":1,
          "min_coop_time":0,
          "defection_detection_mode":"spl_observed_actions",
          "defection_carac_threshold":0.0,
          "average_d_carac":true,
          "average_d_carac_len":20,
          "same_init_weights":false,
          "coop_net_ent_diff_as_lr":false,
          "use_sl_for_simu_coop":false,
          "use_strat_4":false,
          "use_strat_5":false,
          "strat_5_coeff":10.0,
          "use_strat_2":true,
          "length_of_history":200,
          "block_len":4,
          "use_last_steps_for_search":true,
          "use_bolzmann_search":true,
          "PERCENTILE_FOR_LIKELIHOOD_TEST":95,
          "meta_algo_memory":{
            "name":"Replay",
            "batch_size":1,
            "max_size":-1
          },
          "meta_algo_loss":{
            "reduction":"none",
            "name":"CrossEntropyLoss"
          },
          "contained_algorithms":[
            {
              "name":"DoubleDQN",
              "algorithm":{
                "name":"DoubleDQN",
                "action_pdtype":"Categorical",
                "action_policy":"boltzmann_on_cluster",
                "explore_var_spec":{
                  "name":"linear_decay",
                  "start_val":1.0,
                  "end_val":0.1,
                  "start_step":0,
                  "end_step":3000
                },
                "gamma":0.5,
                "normalize_inputs":true,
                "training_batch_iter":1,
                "training_iter":4,
                "training_frequency":60,
                "training_start_step":60
              },
              "memory":{
                "name":"Replay",
                "batch_size":60,
                "max_size":4000,
                "use_cer":true
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "clip_grad_val":1.0,
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.04,
                  "momentum":0.9
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            },
            {
              "copy_n":0
            },
            {
              "copy_n":0
            },
            {
              "name":"SupervisedLAPolicy",
              "algorithm":{
                "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
                "entropy_coef_spec":{
                  "name":"linear_decay",
                  "start_val":0.0,
                  "end_val":0.0,
                  "start_step":0,
                  "end_step":500
                },
                "training_frequency":1,
                "normalize_inputs":true,
                "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "loss_spec":{
                  "name":"CrossEntropyLoss",
                  "reduction":"none"
                },
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.40,
                  "momentum":0.000
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            }
          ]
        }
      }
    ],
    "env":[
      {
        "name":"IteratedPrisonersDilemma-v0",
        "max_t":null,
        "max_frame":4000,
        "num_envs":1
      }
    ],
    "body":{
      "product":"outer",
      "num":1
    },
    "meta":{
      "distributed":false,
      "eval_frequency":20,
      "log_frequency":20,
      "max_session":10,
      "max_concurrent_session":10,
      "max_trial":1
    }
  },
  "ipd_ipm_le_vs_exploiter_strat_2_temp_1_0.55_0.85":{
    "world":{
      "name":"DefaultMultiAgentWorld",
      "deterministic":false
    },
    "agent":[
      {
        "name":"LE",
        "memory":null,
        "net":null,
        "welfare_function":"utilitarian_welfare",
        "observing_other_agents":{
          "name":"FullyObservable"
        },
        "algorithm":{
          "name":"LE",
          "punishement_time":1,
          "min_coop_time":0,
          "defection_detection_mode":"spl_observed_actions",
          "defection_carac_threshold":0.0,
          "average_d_carac":true,
          "average_d_carac_len":20,
          "same_init_weights":false,
          "coop_net_ent_diff_as_lr":false,
          "use_sl_for_simu_coop":false,
          "use_strat_4":false,
          "use_strat_5":false,
          "strat_5_coeff":10.0,
          "use_strat_2":true,
          "length_of_history":200,
          "block_len":4,
          "use_last_steps_for_search":true,
          "use_bolzmann_search":true,
          "PERCENTILE_FOR_LIKELIHOOD_TEST":55,
          "meta_algo_memory":{
            "name":"Replay",
            "batch_size":1,
            "max_size":-1
          },
          "meta_algo_loss":{
            "reduction":"none",
            "name":"CrossEntropyLoss"
          },
          "contained_algorithms":[
            {
              "name":"DoubleDQN",
              "algorithm":{
                "name":"DoubleDQN",
                "action_pdtype":"Categorical",
                "action_policy":"boltzmann_on_cluster",
                "explore_var_spec":{
                  "name":"linear_decay",
                  "start_val":1.0,
                  "end_val":0.1,
                  "start_step":0,
                  "end_step":3000
                },
                "gamma":0.5,
                "normalize_inputs":true,
                "training_batch_iter":1,
                "training_iter":4,
                "training_frequency":60,
                "training_start_step":60
              },
              "memory":{
                "name":"Replay",
                "batch_size":60,
                "max_size":4000,
                "use_cer":true
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "clip_grad_val":1.0,
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.04,
                  "momentum":0.9
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            },
            {
              "copy_n":0
            },
            {
              "copy_n":0
            },
            {
              "name":"SupervisedLAPolicy",
              "algorithm":{
                "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
                "entropy_coef_spec":{
                  "name":"linear_decay",
                  "start_val":0.0,
                  "end_val":0.0,
                  "start_step":0,
                  "end_step":500
                },
                "training_frequency":1,
                "normalize_inputs":true,
                "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "loss_spec":{
                  "name":"CrossEntropyLoss",
                  "reduction":"none"
                },
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.40,
                  "momentum":0.000
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            }
          ]
        }
      },
      {
        "name":"LEExploiter",
        "memory":null,
        "net":null,
        "welfare_function":"default_welfare",
        "observing_other_agents":{
          "name":"FullyObservable"
        },
        "algorithm":{
          "name":"LEExploiter",
          "punishement_time":1,
          "min_coop_time":0,
          "defection_detection_mode":"spl_observed_actions",
          "defection_carac_threshold":0.0,
          "average_d_carac":true,
          "average_d_carac_len":20,
          "same_init_weights":false,
          "coop_net_ent_diff_as_lr":false,
          "use_sl_for_simu_coop":false,
          "use_strat_4":false,
          "use_strat_5":false,
          "strat_5_coeff":10.0,
          "use_strat_2":true,
          "length_of_history":200,
          "block_len":4,
          "use_last_steps_for_search":true,
          "use_bolzmann_search":true,
          "PERCENTILE_FOR_LIKELIHOOD_TEST":85,
          "meta_algo_memory":{
            "name":"Replay",
            "batch_size":1,
            "max_size":-1
          },
          "meta_algo_loss":{
            "reduction":"none",
            "name":"CrossEntropyLoss"
          },
          "contained_algorithms":[
            {
              "name":"DoubleDQN",
              "algorithm":{
                "name":"DoubleDQN",
                "action_pdtype":"Categorical",
                "action_policy":"boltzmann_on_cluster",
                "explore_var_spec":{
                  "name":"linear_decay",
                  "start_val":1.0,
                  "end_val":0.1,
                  "start_step":0,
                  "end_step":3000
                },
                "gamma":0.5,
                "normalize_inputs":true,
                "training_batch_iter":1,
                "training_iter":4,
                "training_frequency":60,
                "training_start_step":60
              },
              "memory":{
                "name":"Replay",
                "batch_size":60,
                "max_size":4000,
                "use_cer":true
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "clip_grad_val":1.0,
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.04,
                  "momentum":0.9
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            },
            {
              "copy_n":0
            },
            {
              "copy_n":0
            },
            {
              "name":"SupervisedLAPolicy",
              "algorithm":{
                "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
                "entropy_coef_spec":{
                  "name":"linear_decay",
                  "start_val":0.0,
                  "end_val":0.0,
                  "start_step":0,
                  "end_step":500
                },
                "training_frequency":1,
                "normalize_inputs":true,
                "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "loss_spec":{
                  "name":"CrossEntropyLoss",
                  "reduction":"none"
                },
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.40,
                  "momentum":0.000
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            }
          ]
        }
      }
    ],
    "env":[
      {
        "name":"IteratedPrisonersDilemma-v0",
        "max_t":null,
        "max_frame":4000,
        "num_envs":1
      }
    ],
    "body":{
      "product":"outer",
      "num":1
    },
    "meta":{
      "distributed":false,
      "eval_frequency":20,
      "log_frequency":20,
      "max_session":10,
      "max_concurrent_session":10,
      "max_trial":1
    }
  },
  "ipd_ipm_le_vs_exploiter_strat_2_temp_1_0.55_0.75":{
    "world":{
      "name":"DefaultMultiAgentWorld",
      "deterministic":false
    },
    "agent":[
      {
        "name":"LE",
        "memory":null,
        "net":null,
        "welfare_function":"utilitarian_welfare",
        "observing_other_agents":{
          "name":"FullyObservable"
        },
        "algorithm":{
          "name":"LE",
          "punishement_time":1,
          "min_coop_time":0,
          "defection_detection_mode":"spl_observed_actions",
          "defection_carac_threshold":0.0,
          "average_d_carac":true,
          "average_d_carac_len":20,
          "same_init_weights":false,
          "coop_net_ent_diff_as_lr":false,
          "use_sl_for_simu_coop":false,
          "use_strat_4":false,
          "use_strat_5":false,
          "strat_5_coeff":10.0,
          "use_strat_2":true,
          "length_of_history":200,
          "block_len":4,
          "use_last_steps_for_search":true,
          "use_bolzmann_search":true,
          "PERCENTILE_FOR_LIKELIHOOD_TEST":55,
          "meta_algo_memory":{
            "name":"Replay",
            "batch_size":1,
            "max_size":-1
          },
          "meta_algo_loss":{
            "reduction":"none",
            "name":"CrossEntropyLoss"
          },
          "contained_algorithms":[
            {
              "name":"DoubleDQN",
              "algorithm":{
                "name":"DoubleDQN",
                "action_pdtype":"Categorical",
                "action_policy":"boltzmann_on_cluster",
                "explore_var_spec":{
                  "name":"linear_decay",
                  "start_val":1.0,
                  "end_val":0.1,
                  "start_step":0,
                  "end_step":3000
                },
                "gamma":0.5,
                "normalize_inputs":true,
                "training_batch_iter":1,
                "training_iter":4,
                "training_frequency":60,
                "training_start_step":60
              },
              "memory":{
                "name":"Replay",
                "batch_size":60,
                "max_size":4000,
                "use_cer":true
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "clip_grad_val":1.0,
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.04,
                  "momentum":0.9
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            },
            {
              "copy_n":0
            },
            {
              "copy_n":0
            },
            {
              "name":"SupervisedLAPolicy",
              "algorithm":{
                "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
                "entropy_coef_spec":{
                  "name":"linear_decay",
                  "start_val":0.0,
                  "end_val":0.0,
                  "start_step":0,
                  "end_step":500
                },
                "training_frequency":1,
                "normalize_inputs":true,
                "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "loss_spec":{
                  "name":"CrossEntropyLoss",
                  "reduction":"none"
                },
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.40,
                  "momentum":0.000
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            }
          ]
        }
      },
      {
        "name":"LEExploiter",
        "memory":null,
        "net":null,
        "welfare_function":"default_welfare",
        "observing_other_agents":{
          "name":"FullyObservable"
        },
        "algorithm":{
          "name":"LEExploiter",
          "punishement_time":1,
          "min_coop_time":0,
          "defection_detection_mode":"spl_observed_actions",
          "defection_carac_threshold":0.0,
          "average_d_carac":true,
          "average_d_carac_len":20,
          "same_init_weights":false,
          "coop_net_ent_diff_as_lr":false,
          "use_sl_for_simu_coop":false,
          "use_strat_4":false,
          "use_strat_5":false,
          "strat_5_coeff":10.0,
          "use_strat_2":true,
          "length_of_history":200,
          "block_len":4,
          "use_last_steps_for_search":true,
          "use_bolzmann_search":true,
          "PERCENTILE_FOR_LIKELIHOOD_TEST":75,
          "meta_algo_memory":{
            "name":"Replay",
            "batch_size":1,
            "max_size":-1
          },
          "meta_algo_loss":{
            "reduction":"none",
            "name":"CrossEntropyLoss"
          },
          "contained_algorithms":[
            {
              "name":"DoubleDQN",
              "algorithm":{
                "name":"DoubleDQN",
                "action_pdtype":"Categorical",
                "action_policy":"boltzmann_on_cluster",
                "explore_var_spec":{
                  "name":"linear_decay",
                  "start_val":1.0,
                  "end_val":0.1,
                  "start_step":0,
                  "end_step":3000
                },
                "gamma":0.5,
                "normalize_inputs":true,
                "training_batch_iter":1,
                "training_iter":4,
                "training_frequency":60,
                "training_start_step":60
              },
              "memory":{
                "name":"Replay",
                "batch_size":60,
                "max_size":4000,
                "use_cer":true
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "clip_grad_val":1.0,
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.04,
                  "momentum":0.9
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            },
            {
              "copy_n":0
            },
            {
              "copy_n":0
            },
            {
              "name":"SupervisedLAPolicy",
              "algorithm":{
                "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
                "entropy_coef_spec":{
                  "name":"linear_decay",
                  "start_val":0.0,
                  "end_val":0.0,
                  "start_step":0,
                  "end_step":500
                },
                "training_frequency":1,
                "normalize_inputs":true,
                "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "loss_spec":{
                  "name":"CrossEntropyLoss",
                  "reduction":"none"
                },
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.40,
                  "momentum":0.000
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            }
          ]
        }
      }
    ],
    "env":[
      {
        "name":"IteratedPrisonersDilemma-v0",
        "max_t":null,
        "max_frame":4000,
        "num_envs":1
      }
    ],
    "body":{
      "product":"outer",
      "num":1
    },
    "meta":{
      "distributed":false,
      "eval_frequency":20,
      "log_frequency":20,
      "max_session":10,
      "max_concurrent_session":10,
      "max_trial":1
    }
  },
  "ipd_ipm_le_vs_exploiter_strat_2_temp_1_0.55_0.65":{
    "world":{
      "name":"DefaultMultiAgentWorld",
      "deterministic":false
    },
    "agent":[
      {
        "name":"LE",
        "memory":null,
        "net":null,
        "welfare_function":"utilitarian_welfare",
        "observing_other_agents":{
          "name":"FullyObservable"
        },
        "algorithm":{
          "name":"LE",
          "punishement_time":1,
          "min_coop_time":0,
          "defection_detection_mode":"spl_observed_actions",
          "defection_carac_threshold":0.0,
          "average_d_carac":true,
          "average_d_carac_len":20,
          "same_init_weights":false,
          "coop_net_ent_diff_as_lr":false,
          "use_sl_for_simu_coop":false,
          "use_strat_4":false,
          "use_strat_5":false,
          "strat_5_coeff":10.0,
          "use_strat_2":true,
          "length_of_history":200,
          "block_len":4,
          "use_last_steps_for_search":true,
          "use_bolzmann_search":true,
          "PERCENTILE_FOR_LIKELIHOOD_TEST":55,
          "meta_algo_memory":{
            "name":"Replay",
            "batch_size":1,
            "max_size":-1
          },
          "meta_algo_loss":{
            "reduction":"none",
            "name":"CrossEntropyLoss"
          },
          "contained_algorithms":[
            {
              "name":"DoubleDQN",
              "algorithm":{
                "name":"DoubleDQN",
                "action_pdtype":"Categorical",
                "action_policy":"boltzmann_on_cluster",
                "explore_var_spec":{
                  "name":"linear_decay",
                  "start_val":1.0,
                  "end_val":0.1,
                  "start_step":0,
                  "end_step":3000
                },
                "gamma":0.5,
                "normalize_inputs":true,
                "training_batch_iter":1,
                "training_iter":4,
                "training_frequency":60,
                "training_start_step":60
              },
              "memory":{
                "name":"Replay",
                "batch_size":60,
                "max_size":4000,
                "use_cer":true
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "clip_grad_val":1.0,
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.04,
                  "momentum":0.9
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            },
            {
              "copy_n":0
            },
            {
              "copy_n":0
            },
            {
              "name":"SupervisedLAPolicy",
              "algorithm":{
                "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
                "entropy_coef_spec":{
                  "name":"linear_decay",
                  "start_val":0.0,
                  "end_val":0.0,
                  "start_step":0,
                  "end_step":500
                },
                "training_frequency":1,
                "normalize_inputs":true,
                "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "loss_spec":{
                  "name":"CrossEntropyLoss",
                  "reduction":"none"
                },
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.40,
                  "momentum":0.000
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            }
          ]
        }
      },
      {
        "name":"LEExploiter",
        "memory":null,
        "net":null,
        "welfare_function":"default_welfare",
        "observing_other_agents":{
          "name":"FullyObservable"
        },
        "algorithm":{
          "name":"LEExploiter",
          "punishement_time":1,
          "min_coop_time":0,
          "defection_detection_mode":"spl_observed_actions",
          "defection_carac_threshold":0.0,
          "average_d_carac":true,
          "average_d_carac_len":20,
          "same_init_weights":false,
          "coop_net_ent_diff_as_lr":false,
          "use_sl_for_simu_coop":false,
          "use_strat_4":false,
          "use_strat_5":false,
          "strat_5_coeff":10.0,
          "use_strat_2":true,
          "length_of_history":200,
          "block_len":4,
          "use_last_steps_for_search":true,
          "use_bolzmann_search":true,
          "PERCENTILE_FOR_LIKELIHOOD_TEST":65,
          "meta_algo_memory":{
            "name":"Replay",
            "batch_size":1,
            "max_size":-1
          },
          "meta_algo_loss":{
            "reduction":"none",
            "name":"CrossEntropyLoss"
          },
          "contained_algorithms":[
            {
              "name":"DoubleDQN",
              "algorithm":{
                "name":"DoubleDQN",
                "action_pdtype":"Categorical",
                "action_policy":"boltzmann_on_cluster",
                "explore_var_spec":{
                  "name":"linear_decay",
                  "start_val":1.0,
                  "end_val":0.1,
                  "start_step":0,
                  "end_step":3000
                },
                "gamma":0.5,
                "normalize_inputs":true,
                "training_batch_iter":1,
                "training_iter":4,
                "training_frequency":60,
                "training_start_step":60
              },
              "memory":{
                "name":"Replay",
                "batch_size":60,
                "max_size":4000,
                "use_cer":true
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "clip_grad_val":1.0,
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.04,
                  "momentum":0.9
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            },
            {
              "copy_n":0
            },
            {
              "copy_n":0
            },
            {
              "name":"SupervisedLAPolicy",
              "algorithm":{
                "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
                "entropy_coef_spec":{
                  "name":"linear_decay",
                  "start_val":0.0,
                  "end_val":0.0,
                  "start_step":0,
                  "end_step":500
                },
                "training_frequency":1,
                "normalize_inputs":true,
                "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "loss_spec":{
                  "name":"CrossEntropyLoss",
                  "reduction":"none"
                },
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.40,
                  "momentum":0.000
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            }
          ]
        }
      }
    ],
    "env":[
      {
        "name":"IteratedPrisonersDilemma-v0",
        "max_t":null,
        "max_frame":4000,
        "num_envs":1
      }
    ],
    "body":{
      "product":"outer",
      "num":1
    },
    "meta":{
      "distributed":false,
      "eval_frequency":20,
      "log_frequency":20,
      "max_session":10,
      "max_concurrent_session":10,
      "max_trial":1
    }
  },
  "ipd_ipm_le_vs_exploiter_strat_2_temp_1_0.55_0.55":{
    "world":{
      "name":"DefaultMultiAgentWorld",
      "deterministic":false
    },
    "agent":[
      {
        "name":"LE",
        "memory":null,
        "net":null,
        "welfare_function":"utilitarian_welfare",
        "observing_other_agents":{
          "name":"FullyObservable"
        },
        "algorithm":{
          "name":"LE",
          "punishement_time":1,
          "min_coop_time":0,
          "defection_detection_mode":"spl_observed_actions",
          "defection_carac_threshold":0.0,
          "average_d_carac":true,
          "average_d_carac_len":20,
          "same_init_weights":false,
          "coop_net_ent_diff_as_lr":false,
          "use_sl_for_simu_coop":false,
          "use_strat_4":false,
          "use_strat_5":false,
          "strat_5_coeff":10.0,
          "use_strat_2":true,
          "length_of_history":200,
          "block_len":4,
          "use_last_steps_for_search":true,
          "use_bolzmann_search":true,
          "PERCENTILE_FOR_LIKELIHOOD_TEST":55,
          "meta_algo_memory":{
            "name":"Replay",
            "batch_size":1,
            "max_size":-1
          },
          "meta_algo_loss":{
            "reduction":"none",
            "name":"CrossEntropyLoss"
          },
          "contained_algorithms":[
            {
              "name":"DoubleDQN",
              "algorithm":{
                "name":"DoubleDQN",
                "action_pdtype":"Categorical",
                "action_policy":"boltzmann_on_cluster",
                "explore_var_spec":{
                  "name":"linear_decay",
                  "start_val":1.0,
                  "end_val":0.1,
                  "start_step":0,
                  "end_step":3000
                },
                "gamma":0.5,
                "normalize_inputs":true,
                "training_batch_iter":1,
                "training_iter":4,
                "training_frequency":60,
                "training_start_step":60
              },
              "memory":{
                "name":"Replay",
                "batch_size":60,
                "max_size":4000,
                "use_cer":true
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "clip_grad_val":1.0,
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.04,
                  "momentum":0.9
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            },
            {
              "copy_n":0
            },
            {
              "copy_n":0
            },
            {
              "name":"SupervisedLAPolicy",
              "algorithm":{
                "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
                "entropy_coef_spec":{
                  "name":"linear_decay",
                  "start_val":0.0,
                  "end_val":0.0,
                  "start_step":0,
                  "end_step":500
                },
                "training_frequency":1,
                "normalize_inputs":true,
                "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "loss_spec":{
                  "name":"CrossEntropyLoss",
                  "reduction":"none"
                },
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.40,
                  "momentum":0.000
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            }
          ]
        }
      },
      {
        "name":"LEExploiter",
        "memory":null,
        "net":null,
        "welfare_function":"default_welfare",
        "observing_other_agents":{
          "name":"FullyObservable"
        },
        "algorithm":{
          "name":"LEExploiter",
          "punishement_time":1,
          "min_coop_time":0,
          "defection_detection_mode":"spl_observed_actions",
          "defection_carac_threshold":0.0,
          "average_d_carac":true,
          "average_d_carac_len":20,
          "same_init_weights":false,
          "coop_net_ent_diff_as_lr":false,
          "use_sl_for_simu_coop":false,
          "use_strat_4":false,
          "use_strat_5":false,
          "strat_5_coeff":10.0,
          "use_strat_2":true,
          "length_of_history":200,
          "block_len":4,
          "use_last_steps_for_search":true,
          "use_bolzmann_search":true,
          "PERCENTILE_FOR_LIKELIHOOD_TEST":55,
          "meta_algo_memory":{
            "name":"Replay",
            "batch_size":1,
            "max_size":-1
          },
          "meta_algo_loss":{
            "reduction":"none",
            "name":"CrossEntropyLoss"
          },
          "contained_algorithms":[
            {
              "name":"DoubleDQN",
              "algorithm":{
                "name":"DoubleDQN",
                "action_pdtype":"Categorical",
                "action_policy":"boltzmann_on_cluster",
                "explore_var_spec":{
                  "name":"linear_decay",
                  "start_val":1.0,
                  "end_val":0.1,
                  "start_step":0,
                  "end_step":3000
                },
                "gamma":0.5,
                "normalize_inputs":true,
                "training_batch_iter":1,
                "training_iter":4,
                "training_frequency":60,
                "training_start_step":60
              },
              "memory":{
                "name":"Replay",
                "batch_size":60,
                "max_size":4000,
                "use_cer":true
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "clip_grad_val":1.0,
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.04,
                  "momentum":0.9
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            },
            {
              "copy_n":0
            },
            {
              "copy_n":0
            },
            {
              "name":"SupervisedLAPolicy",
              "algorithm":{
                "name":"SupervisedLAPolicy",
                "action_pdtype":  "default",
                "action_policy":  "default",
                "explore_var_spec":null,
                "entropy_coef_spec":{
                  "name":"linear_decay",
                  "start_val":0.0,
                  "end_val":0.0,
                  "start_step":0,
                  "end_step":500
                },
                "training_frequency":1,
                "normalize_inputs":true,
                "training_batch_iter":1
              },
              "memory":{
                "name":"OnPolicyReplay"
              },
              "net":{
                "type":"MLPNet",
                "hid_layers":[4],
                "hid_layers_activation":"LeakyReLU",
                "init_fn":"normal_mu_0_std_0.1",
                "loss_spec":{
                  "name":"CrossEntropyLoss",
                  "reduction":"none"
                },
                "optim_spec":{
                  "name":"SGD",
                  "lr":0.40,
                  "momentum":0.000
                },
                "lr_scheduler_spec":{
                  "name":"LinearToZero",
                  "frame":4000
                }
              }
            }
          ]
        }
      }
    ],
    "env":[
      {
        "name":"IteratedPrisonersDilemma-v0",
        "max_t":null,
        "max_frame":4000,
        "num_envs":1
      }
    ],
    "body":{
      "product":"outer",
      "num":1
    },
    "meta":{
      "distributed":false,
      "eval_frequency":20,
      "log_frequency":20,
      "max_session":10,
      "max_concurrent_session":10,
      "max_trial":1
    }
  }


}


























